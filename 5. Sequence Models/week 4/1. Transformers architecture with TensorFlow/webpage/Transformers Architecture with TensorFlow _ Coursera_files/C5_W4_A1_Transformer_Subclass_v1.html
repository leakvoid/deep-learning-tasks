<!DOCTYPE html>
<!-- saved from url=(0089)https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb# -->
<html lang="en-us"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

    <title>C5_W4_A1_Transformer_Subclass_v1 - Jupyter Notebook</title>
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="stylesheet" href="./jquery-ui.min.css" type="text/css">
    <link rel="stylesheet" href="./jquery.typeahead.min.css" type="text/css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    


<script type="text/javascript" src="./MathJax.js" charset="utf-8"></script>

<script type="text/javascript">
// MathJax disabled, set as null to distinguish from *missing* MathJax,
// where it will be undefined, and should prompt a dialog later.
window.mathjax_url = "/static/components/MathJax/MathJax.js";
</script>

<link rel="stylesheet" href="./bootstrap-tour.min.css" type="text/css">
<link rel="stylesheet" href="./codemirror.css">


    <link rel="stylesheet" href="./style.min.css" type="text/css">
    

<link rel="stylesheet" href="./override.css" type="text/css">
<link rel="stylesheet" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb" id="kernel-css" type="text/css">


    <link rel="stylesheet" href="./custom.css" type="text/css">
    <script src="./promise.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="./react.production.min.js" type="text/javascript"></script>
    <script src="./react-dom.production.min.js" type="text/javascript"></script>
    <script src="./index.js" type="text/javascript"></script>
    <script src="./require.js" type="text/javascript" charset="utf-8"></script>
    <script>
      require.config({
          
          urlArgs: "v=20210706140437",
          
          baseUrl: '/static/',
          paths: {
            'auth/js/main': 'auth/js/main.min',
            custom : '/custom',
            nbextensions : '/nbextensions',
            kernelspecs : '/kernelspecs',
            underscore : 'components/underscore/underscore-min',
            backbone : 'components/backbone/backbone-min',
            jed: 'components/jed/jed',
            jquery: 'components/jquery/jquery.min',
            json: 'components/requirejs-plugins/src/json',
            text: 'components/requirejs-text/text',
            bootstrap: 'components/bootstrap/dist/js/bootstrap.min',
            bootstraptour: 'components/bootstrap-tour/build/js/bootstrap-tour.min',
            'jquery-ui': 'components/jquery-ui/jquery-ui.min',
            moment: 'components/moment/min/moment-with-locales',
            codemirror: 'components/codemirror',
            termjs: 'components/xterm.js/xterm',
            typeahead: 'components/jquery-typeahead/dist/jquery.typeahead.min',
          },
          map: { // for backward compatibility
              "*": {
                  "jqueryui": "jquery-ui",
              }
          },
          shim: {
            typeahead: {
              deps: ["jquery"],
              exports: "typeahead"
            },
            underscore: {
              exports: '_'
            },
            backbone: {
              deps: ["underscore", "jquery"],
              exports: "Backbone"
            },
            bootstrap: {
              deps: ["jquery"],
              exports: "bootstrap"
            },
            bootstraptour: {
              deps: ["bootstrap"],
              exports: "Tour"
            },
            "jquery-ui": {
              deps: ["jquery"],
              exports: "$"
            }
          },
          waitSeconds: 30,
      });

      require.config({
          map: {
              '*':{
                'contents': 'services/contents',
              }
          }
      });

      // error-catching custom.js shim.
      define("custom", function (require, exports, module) {
          try {
              var custom = require('custom/custom');
              console.debug('loaded custom.js');
              return custom;
          } catch (e) {
              console.error("error loading custom.js", e);
              return {};
          }
      })

    document.nbjs_translations = {"domain": "nbjs", "locale_data": {"nbjs": {"": {"domain": "nbjs"}}}};
    document.documentElement.lang = navigator.language.toLowerCase();
    </script>

    
    

<script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/contents" src="./contents.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="custom/custom" src="./custom.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="nbextensions/jupyter-matplotlib/extension" src="./extension.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="nbextensions/jupyter-js-widgets/extension" src="./extension(1).js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="nbextensions/submit-button/main" src="./main.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/* Override the correction for the prompt area in https://github.com/jupyter/notebook/blob/dd41d9fd5c4f698bd7468612d877828a7eeb0e7a/IPython/html/static/notebook/less/outputarea.less#L110 */
.jupyter-widgets-output-area div.output_subarea {
    max-width: 100%;
}

/* Work-around for the bug fixed in https://github.com/jupyter/notebook/pull/2961 */
.jupyter-widgets-output-area > .out_prompt_overlay {
    display: none;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


.p-Widget.p-mod-hidden {
  display: none !important;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


.p-CommandPalette-search {
  flex: 0 0 auto;
}


.p-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


.p-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


.p-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


.p-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


.p-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


.p-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


.p-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-DockPanel {
  z-index: 0;
}


.p-DockPanel-widget {
  z-index: 0;
}


.p-DockPanel-tabBar {
  z-index: 1;
}


.p-DockPanel-handle {
  z-index: 2;
}


.p-DockPanel-handle.p-mod-hidden {
  display: none !important;
}


.p-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


.p-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


.p-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


.p-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


.p-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


.p-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


.p-DockPanel-overlay.p-mod-hidden {
  display: none !important;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


.p-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


.p-Menu-item {
  display: table-row;
}


.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed {
  display: none !important;
}


.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


.p-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


.p-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


.p-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


.p-MenuBar-item {
  box-sizing: border-box;
}


.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel {
  display: inline-block;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


.p-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


.p-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


.p-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


.p-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


.p-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-SplitPanel-child {
  z-index: 0;
}


.p-SplitPanel-handle {
  z-index: 1;
}


.p-SplitPanel-handle.p-mod-hidden {
  display: none !important;
}


.p-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle {
  cursor: ew-resize;
}


.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle {
  cursor: ns-resize;
}


.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


.p-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


.p-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


.p-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content {
  flex-direction: row;
}


.p-TabBar[data-orientation='vertical'] > .p-TabBar-content {
  flex-direction: column;
}


.p-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


.p-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


.p-TabBar-tab.p-mod-hidden {
  display: none !important;
}


.p-TabBar.p-mod-dragging .p-TabBar-tab {
  position: relative;
}


.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging {
  transition: none;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


.p-TabPanel-tabBar {
  z-index: 1;
}


.p-TabPanel-stackedPanel {
  z-index: 0;
}
</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/
</style><style type="text/css">/* Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

 .jupyter-widgets-disconnected::before {
    content: "\f127"; /* chain-broken */
    display: inline-block;
    font: normal normal normal 14px/1 FontAwesome;
    font-size: inherit;
    text-rendering: auto;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
    color: #d9534f;
    padding: 3px;
    align-self: flex-start;
}
</style><style type="text/css">/**
 * The material design colors are adapted from google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 * https://github.com/danlevan/google-material-color/blob/f67ca5f4028b2f1b34862f64b0ca67323f91b088/dist/palette.var.css
 *
 * The license for the material design color CSS variables is as follows (see
 * https://github.com/danlevan/google-material-color/blob/f67ca5f4028b2f1b34862f64b0ca67323f91b088/LICENSE)
 *
 * The MIT License (MIT)
 *
 * Copyright (c) 2014 Dan Le Van
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
:root {
  --md-red-50: #FFEBEE;
  --md-red-100: #FFCDD2;
  --md-red-200: #EF9A9A;
  --md-red-300: #E57373;
  --md-red-400: #EF5350;
  --md-red-500: #F44336;
  --md-red-600: #E53935;
  --md-red-700: #D32F2F;
  --md-red-800: #C62828;
  --md-red-900: #B71C1C;
  --md-red-A100: #FF8A80;
  --md-red-A200: #FF5252;
  --md-red-A400: #FF1744;
  --md-red-A700: #D50000;

  --md-pink-50: #FCE4EC;
  --md-pink-100: #F8BBD0;
  --md-pink-200: #F48FB1;
  --md-pink-300: #F06292;
  --md-pink-400: #EC407A;
  --md-pink-500: #E91E63;
  --md-pink-600: #D81B60;
  --md-pink-700: #C2185B;
  --md-pink-800: #AD1457;
  --md-pink-900: #880E4F;
  --md-pink-A100: #FF80AB;
  --md-pink-A200: #FF4081;
  --md-pink-A400: #F50057;
  --md-pink-A700: #C51162;

  --md-purple-50: #F3E5F5;
  --md-purple-100: #E1BEE7;
  --md-purple-200: #CE93D8;
  --md-purple-300: #BA68C8;
  --md-purple-400: #AB47BC;
  --md-purple-500: #9C27B0;
  --md-purple-600: #8E24AA;
  --md-purple-700: #7B1FA2;
  --md-purple-800: #6A1B9A;
  --md-purple-900: #4A148C;
  --md-purple-A100: #EA80FC;
  --md-purple-A200: #E040FB;
  --md-purple-A400: #D500F9;
  --md-purple-A700: #AA00FF;

  --md-deep-purple-50: #EDE7F6;
  --md-deep-purple-100: #D1C4E9;
  --md-deep-purple-200: #B39DDB;
  --md-deep-purple-300: #9575CD;
  --md-deep-purple-400: #7E57C2;
  --md-deep-purple-500: #673AB7;
  --md-deep-purple-600: #5E35B1;
  --md-deep-purple-700: #512DA8;
  --md-deep-purple-800: #4527A0;
  --md-deep-purple-900: #311B92;
  --md-deep-purple-A100: #B388FF;
  --md-deep-purple-A200: #7C4DFF;
  --md-deep-purple-A400: #651FFF;
  --md-deep-purple-A700: #6200EA;

  --md-indigo-50: #E8EAF6;
  --md-indigo-100: #C5CAE9;
  --md-indigo-200: #9FA8DA;
  --md-indigo-300: #7986CB;
  --md-indigo-400: #5C6BC0;
  --md-indigo-500: #3F51B5;
  --md-indigo-600: #3949AB;
  --md-indigo-700: #303F9F;
  --md-indigo-800: #283593;
  --md-indigo-900: #1A237E;
  --md-indigo-A100: #8C9EFF;
  --md-indigo-A200: #536DFE;
  --md-indigo-A400: #3D5AFE;
  --md-indigo-A700: #304FFE;

  --md-blue-50: #E3F2FD;
  --md-blue-100: #BBDEFB;
  --md-blue-200: #90CAF9;
  --md-blue-300: #64B5F6;
  --md-blue-400: #42A5F5;
  --md-blue-500: #2196F3;
  --md-blue-600: #1E88E5;
  --md-blue-700: #1976D2;
  --md-blue-800: #1565C0;
  --md-blue-900: #0D47A1;
  --md-blue-A100: #82B1FF;
  --md-blue-A200: #448AFF;
  --md-blue-A400: #2979FF;
  --md-blue-A700: #2962FF;

  --md-light-blue-50: #E1F5FE;
  --md-light-blue-100: #B3E5FC;
  --md-light-blue-200: #81D4FA;
  --md-light-blue-300: #4FC3F7;
  --md-light-blue-400: #29B6F6;
  --md-light-blue-500: #03A9F4;
  --md-light-blue-600: #039BE5;
  --md-light-blue-700: #0288D1;
  --md-light-blue-800: #0277BD;
  --md-light-blue-900: #01579B;
  --md-light-blue-A100: #80D8FF;
  --md-light-blue-A200: #40C4FF;
  --md-light-blue-A400: #00B0FF;
  --md-light-blue-A700: #0091EA;

  --md-cyan-50: #E0F7FA;
  --md-cyan-100: #B2EBF2;
  --md-cyan-200: #80DEEA;
  --md-cyan-300: #4DD0E1;
  --md-cyan-400: #26C6DA;
  --md-cyan-500: #00BCD4;
  --md-cyan-600: #00ACC1;
  --md-cyan-700: #0097A7;
  --md-cyan-800: #00838F;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84FFFF;
  --md-cyan-A200: #18FFFF;
  --md-cyan-A400: #00E5FF;
  --md-cyan-A700: #00B8D4;

  --md-teal-50: #E0F2F1;
  --md-teal-100: #B2DFDB;
  --md-teal-200: #80CBC4;
  --md-teal-300: #4DB6AC;
  --md-teal-400: #26A69A;
  --md-teal-500: #009688;
  --md-teal-600: #00897B;
  --md-teal-700: #00796B;
  --md-teal-800: #00695C;
  --md-teal-900: #004D40;
  --md-teal-A100: #A7FFEB;
  --md-teal-A200: #64FFDA;
  --md-teal-A400: #1DE9B6;
  --md-teal-A700: #00BFA5;

  --md-green-50: #E8F5E9;
  --md-green-100: #C8E6C9;
  --md-green-200: #A5D6A7;
  --md-green-300: #81C784;
  --md-green-400: #66BB6A;
  --md-green-500: #4CAF50;
  --md-green-600: #43A047;
  --md-green-700: #388E3C;
  --md-green-800: #2E7D32;
  --md-green-900: #1B5E20;
  --md-green-A100: #B9F6CA;
  --md-green-A200: #69F0AE;
  --md-green-A400: #00E676;
  --md-green-A700: #00C853;

  --md-light-green-50: #F1F8E9;
  --md-light-green-100: #DCEDC8;
  --md-light-green-200: #C5E1A5;
  --md-light-green-300: #AED581;
  --md-light-green-400: #9CCC65;
  --md-light-green-500: #8BC34A;
  --md-light-green-600: #7CB342;
  --md-light-green-700: #689F38;
  --md-light-green-800: #558B2F;
  --md-light-green-900: #33691E;
  --md-light-green-A100: #CCFF90;
  --md-light-green-A200: #B2FF59;
  --md-light-green-A400: #76FF03;
  --md-light-green-A700: #64DD17;

  --md-lime-50: #F9FBE7;
  --md-lime-100: #F0F4C3;
  --md-lime-200: #E6EE9C;
  --md-lime-300: #DCE775;
  --md-lime-400: #D4E157;
  --md-lime-500: #CDDC39;
  --md-lime-600: #C0CA33;
  --md-lime-700: #AFB42B;
  --md-lime-800: #9E9D24;
  --md-lime-900: #827717;
  --md-lime-A100: #F4FF81;
  --md-lime-A200: #EEFF41;
  --md-lime-A400: #C6FF00;
  --md-lime-A700: #AEEA00;

  --md-yellow-50: #FFFDE7;
  --md-yellow-100: #FFF9C4;
  --md-yellow-200: #FFF59D;
  --md-yellow-300: #FFF176;
  --md-yellow-400: #FFEE58;
  --md-yellow-500: #FFEB3B;
  --md-yellow-600: #FDD835;
  --md-yellow-700: #FBC02D;
  --md-yellow-800: #F9A825;
  --md-yellow-900: #F57F17;
  --md-yellow-A100: #FFFF8D;
  --md-yellow-A200: #FFFF00;
  --md-yellow-A400: #FFEA00;
  --md-yellow-A700: #FFD600;

  --md-amber-50: #FFF8E1;
  --md-amber-100: #FFECB3;
  --md-amber-200: #FFE082;
  --md-amber-300: #FFD54F;
  --md-amber-400: #FFCA28;
  --md-amber-500: #FFC107;
  --md-amber-600: #FFB300;
  --md-amber-700: #FFA000;
  --md-amber-800: #FF8F00;
  --md-amber-900: #FF6F00;
  --md-amber-A100: #FFE57F;
  --md-amber-A200: #FFD740;
  --md-amber-A400: #FFC400;
  --md-amber-A700: #FFAB00;

  --md-orange-50: #FFF3E0;
  --md-orange-100: #FFE0B2;
  --md-orange-200: #FFCC80;
  --md-orange-300: #FFB74D;
  --md-orange-400: #FFA726;
  --md-orange-500: #FF9800;
  --md-orange-600: #FB8C00;
  --md-orange-700: #F57C00;
  --md-orange-800: #EF6C00;
  --md-orange-900: #E65100;
  --md-orange-A100: #FFD180;
  --md-orange-A200: #FFAB40;
  --md-orange-A400: #FF9100;
  --md-orange-A700: #FF6D00;

  --md-deep-orange-50: #FBE9E7;
  --md-deep-orange-100: #FFCCBC;
  --md-deep-orange-200: #FFAB91;
  --md-deep-orange-300: #FF8A65;
  --md-deep-orange-400: #FF7043;
  --md-deep-orange-500: #FF5722;
  --md-deep-orange-600: #F4511E;
  --md-deep-orange-700: #E64A19;
  --md-deep-orange-800: #D84315;
  --md-deep-orange-900: #BF360C;
  --md-deep-orange-A100: #FF9E80;
  --md-deep-orange-A200: #FF6E40;
  --md-deep-orange-A400: #FF3D00;
  --md-deep-orange-A700: #DD2C00;

  --md-brown-50: #EFEBE9;
  --md-brown-100: #D7CCC8;
  --md-brown-200: #BCAAA4;
  --md-brown-300: #A1887F;
  --md-brown-400: #8D6E63;
  --md-brown-500: #795548;
  --md-brown-600: #6D4C41;
  --md-brown-700: #5D4037;
  --md-brown-800: #4E342E;
  --md-brown-900: #3E2723;

  --md-grey-50: #FAFAFA;
  --md-grey-100: #F5F5F5;
  --md-grey-200: #EEEEEE;
  --md-grey-300: #E0E0E0;
  --md-grey-400: #BDBDBD;
  --md-grey-500: #9E9E9E;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #ECEFF1;
  --md-blue-grey-100: #CFD8DC;
  --md-blue-grey-200: #B0BEC5;
  --md-blue-grey-300: #90A4AE;
  --md-blue-grey-400: #78909C;
  --md-blue-grey-500: #607D8B;
  --md-blue-grey-600: #546E7A;
  --md-blue-grey-700: #455A64;
  --md-blue-grey-800: #37474F;
  --md-blue-grey-900: #263238;
}</style><style type="text/css">/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
This file is copied from the JupyterLab project to define default styling for
when the widget styling is compiled down to eliminate CSS variables. We make one
change - we comment out the font import below.
*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/


/*
 * Optional monospace font for input/output prompt.
 */
 /* Commented out in ipywidgets since we don't need it. */
/* @import url('https://fonts.googleapis.com/css?family=Roboto+Mono'); */

/*
 * Added for compabitility with output area
 */
:root {
  --jp-icon-search: none;
  --jp-ui-select-caret: none;
}


:root {

  /* Borders

  The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-700);
  --jp-border-color1: var(--md-grey-500);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-100);

  /* UI Fonts

  The UI font CSS variables are used for the typography all of the JupyterLab
  user interface elements that are not directly user generated content.
  */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: calc(var(--jp-ui-font-size1)/var(--jp-ui-font-scale-factor));
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: calc(var(--jp-ui-font-size1)*var(--jp-ui-font-scale-factor));
  --jp-ui-font-size3: calc(var(--jp-ui-font-size2)*var(--jp-ui-font-scale-factor));
  --jp-ui-icon-font-size: 14px; /* Ensures px perfect FontAwesome icons */
  --jp-ui-font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;

  /* Use these font colors against the corresponding main layout colors.
     In a light theme, these go from dark to light.
  */

  --jp-ui-font-color0: rgba(0,0,0,1.0);
  --jp-ui-font-color1: rgba(0,0,0,0.8);
  --jp-ui-font-color2: rgba(0,0,0,0.5);
  --jp-ui-font-color3: rgba(0,0,0,0.3);

  /* Use these against the brand/accent/warn/error colors.
     These will typically go from light to darker, in both a dark and light theme
   */

  --jp-inverse-ui-font-color0: rgba(255,255,255,1);
  --jp-inverse-ui-font-color1: rgba(255,255,255,1.0);
  --jp-inverse-ui-font-color2: rgba(255,255,255,0.7);
  --jp-inverse-ui-font-color3: rgba(255,255,255,0.5);

  /* Content Fonts

  Content font variables are used for typography of user generated content.
  */

  --jp-content-font-size: 13px;
  --jp-content-line-height: 1.5;
  --jp-content-font-color0: black;
  --jp-content-font-color1: black;
  --jp-content-font-color2: var(--md-grey-700);
  --jp-content-font-color3: var(--md-grey-500);

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: calc(var(--jp-ui-font-size1)/var(--jp-ui-font-scale-factor));
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: calc(var(--jp-ui-font-size1)*var(--jp-ui-font-scale-factor));
  --jp-ui-font-size3: calc(var(--jp-ui-font-size2)*var(--jp-ui-font-scale-factor));

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.307;
  --jp-code-padding: 5px;
  --jp-code-font-family: monospace;


  /* Layout

  The following are the main layout colors use in JupyterLab. In a light
  theme these would go from light to dark.
  */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-editor-background: #f7f7f7;
  --jp-cell-editor-border-color: #cfcfcf;
  --jp-cell-editor-background-edit: var(--jp-ui-layout-color1);
  --jp-cell-editor-border-color-edit: var(--jp-brand-color1);
  --jp-cell-prompt-width: 100px;
  --jp-cell-prompt-font-family: 'Roboto Mono', monospace;
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1.0;
  --jp-cell-prompt-opacity-not-active: 0.4;
  --jp-cell-prompt-font-color-not-active: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307FC1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #BF5B3D;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-scroll-padding: 100px;

  /* Console specific styles */

  --jp-console-background: var(--md-grey-100);

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--md-grey-400);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color0);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0,0,0,0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);
}
</style><style type="text/css">/* This file has code derived from PhosphorJS CSS files, as noted below. The license for this PhosphorJS code is:

Copyright (c) 2014-2017, PhosphorJS Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

* Neither the name of the copyright holder nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

*/

/*
 * The following section is derived from https://github.com/phosphorjs/phosphor/blob/23b9d075ebc5b73ab148b6ebfc20af97f85714c4/packages/widgets/style/tabbar.css 
 * We've scoped the rules so that they are consistent with exactly our code.
 */

.jupyter-widgets.widget-tab > .p-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


.jupyter-widgets.widget-tab > .p-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


.jupyter-widgets.widget-tab > .p-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


.jupyter-widgets.widget-tab > .p-TabBar > .p-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


.jupyter-widgets.widget-tab > .p-TabBar[data-orientation='horizontal'] > .p-TabBar-content {
  flex-direction: row;
}


.jupyter-widgets.widget-tab > .p-TabBar[data-orientation='vertical'] > .p-TabBar-content {
  flex-direction: column;
}


.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabIcon,
.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-hidden {
  display: none !important;
}


.jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging .p-TabBar-tab {
  position: relative;
}


.jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


.jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


.jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging {
  transition: none;
}

/* End tabbar.css */
</style><style type="text/css">/* Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * We assume that the CSS variables in
 * https://github.com/jupyterlab/jupyterlab/blob/master/src/default-theme/variables.css
 * have been defined.
 */

:root {
    --jp-widgets-color: var(--jp-content-font-color1);
    --jp-widgets-label-color: var(--jp-widgets-color);
    --jp-widgets-readout-color: var(--jp-widgets-color);
    --jp-widgets-font-size: var(--jp-ui-font-size1);
    --jp-widgets-margin: 2px;
    --jp-widgets-inline-height: 28px;
    --jp-widgets-inline-width: 300px;
    --jp-widgets-inline-width-short: calc(var(--jp-widgets-inline-width) / 2 - var(--jp-widgets-margin));
    --jp-widgets-inline-width-tiny: calc(var(--jp-widgets-inline-width-short) / 2 - var(--jp-widgets-margin));
    --jp-widgets-inline-margin: 4px; /* margin between inline elements */
    --jp-widgets-inline-label-width: 80px;
    --jp-widgets-border-width: var(--jp-border-width);
    --jp-widgets-vertical-height: 200px;
    --jp-widgets-horizontal-tab-height: 24px;
    --jp-widgets-horizontal-tab-width: 144px;
    --jp-widgets-horizontal-tab-top-border: 2px;
    --jp-widgets-progress-thickness: 20px;
    --jp-widgets-container-padding: 15px;
    --jp-widgets-input-padding: 4px;
    --jp-widgets-radio-item-height-adjustment: 8px;
    --jp-widgets-radio-item-height: calc(var(--jp-widgets-inline-height) - var(--jp-widgets-radio-item-height-adjustment));
    --jp-widgets-slider-track-thickness: 4px;
    --jp-widgets-slider-border-width: var(--jp-widgets-border-width);
    --jp-widgets-slider-handle-size: 16px;
    --jp-widgets-slider-handle-border-color: var(--jp-border-color1);
    --jp-widgets-slider-handle-background-color: var(--jp-layout-color1);
    --jp-widgets-slider-active-handle-color: var(--jp-brand-color1);
    --jp-widgets-menu-item-height: 24px;
    --jp-widgets-dropdown-arrow: url("data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjIuMSwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHZpZXdCb3g9IjAgMCAxOCAxOCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgMTggMTg7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4KCS5zdDB7ZmlsbDpub25lO30KPC9zdHlsZT4KPHBhdGggZD0iTTUuMiw1LjlMOSw5LjdsMy44LTMuOGwxLjIsMS4ybC00LjksNWwtNC45LTVMNS4yLDUuOXoiLz4KPHBhdGggY2xhc3M9InN0MCIgZD0iTTAtMC42aDE4djE4SDBWLTAuNnoiLz4KPC9zdmc+Cg");
    --jp-widgets-input-color: var(--jp-ui-font-color1);
    --jp-widgets-input-background-color: var(--jp-layout-color1);
    --jp-widgets-input-border-color: var(--jp-border-color1);
    --jp-widgets-input-focus-border-color: var(--jp-brand-color2);
    --jp-widgets-input-border-width: var(--jp-widgets-border-width);
    --jp-widgets-disabled-opacity: 0.6;

    /* From Material Design Lite */
    --md-shadow-key-umbra-opacity: 0.2;
    --md-shadow-key-penumbra-opacity: 0.14;
    --md-shadow-ambient-shadow-opacity: 0.12;
}

.jupyter-widgets {
    margin: var(--jp-widgets-margin);
    box-sizing: border-box;
    color: var(--jp-widgets-color);
    overflow: visible;
}

.jupyter-widgets.jupyter-widgets-disconnected::before {
    line-height: var(--jp-widgets-inline-height);
    height: var(--jp-widgets-inline-height);
}

.jp-Output-result > .jupyter-widgets {
    margin-left: 0;
    margin-right: 0;
}

/* vbox and hbox */

.widget-inline-hbox {
    /* Horizontal widgets */
    box-sizing: border-box;
    display: flex;
    flex-direction: row;
    align-items: baseline;
}

.widget-inline-vbox {
    /* Vertical Widgets */
    box-sizing: border-box;
    display: flex;
    flex-direction: column;
    align-items: center;
}

.widget-box {
    box-sizing: border-box;
    display: flex;
    margin: 0;
    overflow: auto;
}

.widget-gridbox {
    box-sizing: border-box;
    display: grid;
    margin: 0;
    overflow: auto;
}

.widget-hbox {
    flex-direction: row;
}

.widget-vbox {
    flex-direction: column;
}

/* General Button Styling */

.jupyter-button {
    padding-left: 10px;
    padding-right: 10px;
    padding-top: 0px;
    padding-bottom: 0px;
    display: inline-block;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    text-align: center;
    font-size: var(--jp-widgets-font-size);
    cursor: pointer;

    height: var(--jp-widgets-inline-height);
    border: 0px solid;
    line-height: var(--jp-widgets-inline-height);
    box-shadow: none;

    color: var(--jp-ui-font-color1);
    background-color: var(--jp-layout-color2);
    border-color: var(--jp-border-color2);
    border: none;
    user-select: none;
}

.jupyter-button i.fa {
    margin-right: var(--jp-widgets-inline-margin);
    pointer-events: none;
}

.jupyter-button:empty:before {
    content: "\200b"; /* zero-width space */
}

.jupyter-widgets.jupyter-button:disabled {
    opacity: var(--jp-widgets-disabled-opacity);
}

.jupyter-button i.fa.center {
    margin-right: 0;
}

.jupyter-button:hover:enabled, .jupyter-button:focus:enabled {
    /* MD Lite 2dp shadow */
    box-shadow: 0 2px 2px 0 rgba(0, 0, 0, var(--md-shadow-key-penumbra-opacity)),
                0 3px 1px -2px rgba(0, 0, 0, var(--md-shadow-key-umbra-opacity)),
                0 1px 5px 0 rgba(0, 0, 0, var(--md-shadow-ambient-shadow-opacity));
}

.jupyter-button:active, .jupyter-button.mod-active {
    /* MD Lite 4dp shadow */
    box-shadow: 0 4px 5px 0 rgba(0, 0, 0, var(--md-shadow-key-penumbra-opacity)),
                0 1px 10px 0 rgba(0, 0, 0, var(--md-shadow-ambient-shadow-opacity)),
                0 2px 4px -1px rgba(0, 0, 0, var(--md-shadow-key-umbra-opacity));
    color: var(--jp-ui-font-color1);
    background-color: var(--jp-layout-color3);
}

.jupyter-button:focus:enabled {
    outline: 1px solid var(--jp-widgets-input-focus-border-color);
}

/* Button "Primary" Styling */

.jupyter-button.mod-primary {
    color: var(--jp-inverse-ui-font-color1);
    background-color: var(--jp-brand-color1);
}

.jupyter-button.mod-primary.mod-active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-brand-color0);
}

.jupyter-button.mod-primary:active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-brand-color0);
}

/* Button "Success" Styling */

.jupyter-button.mod-success {
    color: var(--jp-inverse-ui-font-color1);
    background-color: var(--jp-success-color1);
}

.jupyter-button.mod-success.mod-active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-success-color0);
 }

.jupyter-button.mod-success:active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-success-color0);
 }

 /* Button "Info" Styling */

.jupyter-button.mod-info {
    color: var(--jp-inverse-ui-font-color1);
    background-color: var(--jp-info-color1);
}

.jupyter-button.mod-info.mod-active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-info-color0);
}

.jupyter-button.mod-info:active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-info-color0);
}

/* Button "Warning" Styling */

.jupyter-button.mod-warning {
    color: var(--jp-inverse-ui-font-color1);
    background-color: var(--jp-warn-color1);
}

.jupyter-button.mod-warning.mod-active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-warn-color0);
}

.jupyter-button.mod-warning:active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-warn-color0);
}

/* Button "Danger" Styling */

.jupyter-button.mod-danger {
    color: var(--jp-inverse-ui-font-color1);
    background-color: var(--jp-error-color1);
}

.jupyter-button.mod-danger.mod-active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-error-color0);
}

.jupyter-button.mod-danger:active {
    color: var(--jp-inverse-ui-font-color0);
    background-color: var(--jp-error-color0);
}

/* Widget Button, Widget Toggle Button, Widget Upload */

.widget-button, .widget-toggle-button, .widget-upload {
    width: var(--jp-widgets-inline-width-short);
}

/* Widget Label Styling */

/* Override Bootstrap label css */
.jupyter-widgets label {
    margin-bottom: initial;
}

.widget-label-basic {
    /* Basic Label */
    color: var(--jp-widgets-label-color);
    font-size: var(--jp-widgets-font-size);
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
    line-height: var(--jp-widgets-inline-height);
}

.widget-label {
    /* Label */
    color: var(--jp-widgets-label-color);
    font-size: var(--jp-widgets-font-size);
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
    line-height: var(--jp-widgets-inline-height);
}

.widget-inline-hbox .widget-label {
    /* Horizontal Widget Label */
    color: var(--jp-widgets-label-color);
    text-align: right;
    margin-right: calc( var(--jp-widgets-inline-margin) * 2 );
    width: var(--jp-widgets-inline-label-width);
    flex-shrink: 0;
}

.widget-inline-vbox .widget-label {
    /* Vertical Widget Label */
    color: var(--jp-widgets-label-color);
    text-align: center;
    line-height: var(--jp-widgets-inline-height);
}

/* Widget Readout Styling */

.widget-readout {
    color: var(--jp-widgets-readout-color);
    font-size: var(--jp-widgets-font-size);
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
    overflow: hidden;
    white-space: nowrap;
    text-align: center;
}

.widget-readout.overflow {
    /* Overflowing Readout */

    /* From Material Design Lite
        shadow-key-umbra-opacity: 0.2;
        shadow-key-penumbra-opacity: 0.14;
        shadow-ambient-shadow-opacity: 0.12;
     */
    -webkit-box-shadow: 0 2px 2px 0 rgba(0, 0, 0, 0.2),
                        0 3px 1px -2px rgba(0, 0, 0, 0.14),
                        0 1px 5px 0 rgba(0, 0, 0, 0.12);

    -moz-box-shadow: 0 2px 2px 0 rgba(0, 0, 0, 0.2),
                     0 3px 1px -2px rgba(0, 0, 0, 0.14),
                     0 1px 5px 0 rgba(0, 0, 0, 0.12);

    box-shadow: 0 2px 2px 0 rgba(0, 0, 0, 0.2),
                0 3px 1px -2px rgba(0, 0, 0, 0.14),
                0 1px 5px 0 rgba(0, 0, 0, 0.12);
}

.widget-inline-hbox .widget-readout {
    /* Horizontal Readout */
    text-align: center;
    max-width: var(--jp-widgets-inline-width-short);
    min-width: var(--jp-widgets-inline-width-tiny);
    margin-left: var(--jp-widgets-inline-margin);
}

.widget-inline-vbox .widget-readout {
    /* Vertical Readout */
    margin-top: var(--jp-widgets-inline-margin);
    /* as wide as the widget */
    width: inherit;
}

/* Widget Checkbox Styling */

.widget-checkbox {
    width: var(--jp-widgets-inline-width);
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
}

.widget-checkbox input[type="checkbox"] {
    margin: 0px calc( var(--jp-widgets-inline-margin) * 2 ) 0px 0px;
    line-height: var(--jp-widgets-inline-height);
    font-size: large;
    flex-grow: 1;
    flex-shrink: 0;
    align-self: center;
}

/* Widget Valid Styling */

.widget-valid {
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
    width: var(--jp-widgets-inline-width-short);
    font-size: var(--jp-widgets-font-size);
}

.widget-valid i:before {
    line-height: var(--jp-widgets-inline-height);
    margin-right: var(--jp-widgets-inline-margin);
    margin-left: var(--jp-widgets-inline-margin);

    /* from the fa class in FontAwesome: https://github.com/FortAwesome/Font-Awesome/blob/49100c7c3a7b58d50baa71efef11af41a66b03d3/css/font-awesome.css#L14 */
    display: inline-block;
    font: normal normal normal 14px/1 FontAwesome;
    font-size: inherit;
    text-rendering: auto;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
}

.widget-valid.mod-valid i:before {
    content: "\f00c";
    color: green;
}

.widget-valid.mod-invalid i:before {
    content: "\f00d";
    color: red;
}

.widget-valid.mod-valid .widget-valid-readout {
    display: none;
}

/* Widget Text and TextArea Stying */

.widget-textarea, .widget-text {
    width: var(--jp-widgets-inline-width);
}

.widget-text input[type="text"], .widget-text input[type="number"]{
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
}

.widget-text input[type="text"]:disabled, .widget-text input[type="number"]:disabled, .widget-textarea textarea:disabled {
    opacity: var(--jp-widgets-disabled-opacity);
}

.widget-text input[type="text"], .widget-text input[type="number"], .widget-textarea textarea {
    box-sizing: border-box;
    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);
    background-color: var(--jp-widgets-input-background-color);
    color: var(--jp-widgets-input-color);
    font-size: var(--jp-widgets-font-size);
    flex-grow: 1;
    min-width: 0; /* This makes it possible for the flexbox to shrink this input */
    flex-shrink: 1;
    outline: none !important;
}
    
.widget-text input[type="text"], .widget-textarea textarea {
    padding: var(--jp-widgets-input-padding) calc( var(--jp-widgets-input-padding) *  2);
}

.widget-text input[type="number"] {
    padding: var(--jp-widgets-input-padding) 0 var(--jp-widgets-input-padding) calc(var(--jp-widgets-input-padding) *  2);
}

.widget-textarea textarea {
    height: inherit;
    width: inherit;
}

.widget-text input:focus, .widget-textarea textarea:focus {
    border-color: var(--jp-widgets-input-focus-border-color);
}

/* Widget Slider */

.widget-slider .ui-slider {
    /* Slider Track */
    border: var(--jp-widgets-slider-border-width) solid var(--jp-layout-color3);
    background: var(--jp-layout-color3);
    box-sizing: border-box;
    position: relative;
    border-radius: 0px;
}

.widget-slider .ui-slider .ui-slider-handle {
    /* Slider Handle */
    outline: none !important; /* focused slider handles are colored - see below */
    position: absolute;
    background-color: var(--jp-widgets-slider-handle-background-color);
    border: var(--jp-widgets-slider-border-width) solid var(--jp-widgets-slider-handle-border-color);
    box-sizing: border-box;
    z-index: 1;
    background-image: none; /* Override jquery-ui */
}

/* Override jquery-ui */
.widget-slider .ui-slider .ui-slider-handle:hover, .widget-slider .ui-slider .ui-slider-handle:focus {
    background-color: var(--jp-widgets-slider-active-handle-color);
    border: var(--jp-widgets-slider-border-width) solid var(--jp-widgets-slider-active-handle-color);
}

.widget-slider .ui-slider .ui-slider-handle:active {
    background-color: var(--jp-widgets-slider-active-handle-color);
    border-color: var(--jp-widgets-slider-active-handle-color);
    z-index: 2;
    transform: scale(1.2);
}

.widget-slider  .ui-slider .ui-slider-range {
    /* Interval between the two specified value of a double slider */
    position: absolute;
    background: var(--jp-widgets-slider-active-handle-color);
    z-index: 0;
}

/* Shapes of Slider Handles */

.widget-hslider .ui-slider .ui-slider-handle {
    width: var(--jp-widgets-slider-handle-size);
    height: var(--jp-widgets-slider-handle-size);
    margin-top: calc((var(--jp-widgets-slider-track-thickness) - var(--jp-widgets-slider-handle-size)) / 2 - var(--jp-widgets-slider-border-width));
    margin-left: calc(var(--jp-widgets-slider-handle-size) / -2 + var(--jp-widgets-slider-border-width));
    border-radius: 50%;
    top: 0;
}

.widget-vslider .ui-slider .ui-slider-handle {
    width: var(--jp-widgets-slider-handle-size);
    height: var(--jp-widgets-slider-handle-size);
    margin-bottom: calc(var(--jp-widgets-slider-handle-size) / -2 + var(--jp-widgets-slider-border-width));
    margin-left: calc((var(--jp-widgets-slider-track-thickness) - var(--jp-widgets-slider-handle-size)) / 2 - var(--jp-widgets-slider-border-width));
    border-radius: 50%;
    left: 0;
}

.widget-hslider .ui-slider .ui-slider-range {
    height: calc( var(--jp-widgets-slider-track-thickness) * 2 );
    margin-top: calc((var(--jp-widgets-slider-track-thickness) - var(--jp-widgets-slider-track-thickness) * 2 ) / 2 - var(--jp-widgets-slider-border-width));
}

.widget-vslider .ui-slider .ui-slider-range {
    width: calc( var(--jp-widgets-slider-track-thickness) * 2 );
    margin-left: calc((var(--jp-widgets-slider-track-thickness) - var(--jp-widgets-slider-track-thickness) * 2 ) / 2 - var(--jp-widgets-slider-border-width));
}

/* Horizontal Slider */

.widget-hslider {
    width: var(--jp-widgets-inline-width);
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);

    /* Override the align-items baseline. This way, the description and readout
    still seem to align their baseline properly, and we don't have to have
    align-self: stretch in the .slider-container. */
    align-items: center;
}

.widgets-slider .slider-container {
    overflow: visible;
}

.widget-hslider .slider-container {
    height: var(--jp-widgets-inline-height);
    margin-left: calc(var(--jp-widgets-slider-handle-size) / 2 - 2 * var(--jp-widgets-slider-border-width));
    margin-right: calc(var(--jp-widgets-slider-handle-size) / 2 - 2 * var(--jp-widgets-slider-border-width));
    flex: 1 1 var(--jp-widgets-inline-width-short);
}

.widget-hslider .ui-slider {
    /* Inner, invisible slide div */
    height: var(--jp-widgets-slider-track-thickness);
    margin-top: calc((var(--jp-widgets-inline-height) - var(--jp-widgets-slider-track-thickness)) / 2);
    width: 100%;
}

/* Vertical Slider */

.widget-vbox .widget-label {
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
}

.widget-vslider {
    /* Vertical Slider */
    height: var(--jp-widgets-vertical-height);
    width: var(--jp-widgets-inline-width-tiny);
}

.widget-vslider .slider-container {
    flex: 1 1 var(--jp-widgets-inline-width-short);
    margin-left: auto;
    margin-right: auto;
    margin-bottom: calc(var(--jp-widgets-slider-handle-size) / 2 - 2 * var(--jp-widgets-slider-border-width));
    margin-top: calc(var(--jp-widgets-slider-handle-size) / 2 - 2 * var(--jp-widgets-slider-border-width));
    display: flex;
    flex-direction: column;
}

.widget-vslider .ui-slider-vertical {
    /* Inner, invisible slide div */
    width: var(--jp-widgets-slider-track-thickness);
    flex-grow: 1;
    margin-left: auto;
    margin-right: auto;
}

/* Widget Progress Styling */

.progress-bar {
    -webkit-transition: none;
    -moz-transition: none;
    -ms-transition: none;
    -o-transition: none;
    transition: none;
}

.progress-bar {
    height: var(--jp-widgets-inline-height);
}

.progress-bar {
    background-color: var(--jp-brand-color1);
}

.progress-bar-success {
    background-color: var(--jp-success-color1);
}

.progress-bar-info {
    background-color: var(--jp-info-color1);
}

.progress-bar-warning {
    background-color: var(--jp-warn-color1);
}

.progress-bar-danger {
    background-color: var(--jp-error-color1);
}

.progress {
    background-color: var(--jp-layout-color2);
    border: none;
    box-shadow: none;
}

/* Horisontal Progress */

.widget-hprogress {
    /* Progress Bar */
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
    width: var(--jp-widgets-inline-width);
    align-items: center;

}

.widget-hprogress .progress {
    flex-grow: 1;
    margin-top: var(--jp-widgets-input-padding);
    margin-bottom: var(--jp-widgets-input-padding);
    align-self: stretch;
    /* Override bootstrap style */
    height: initial;
}

/* Vertical Progress */

.widget-vprogress {
    height: var(--jp-widgets-vertical-height);
    width: var(--jp-widgets-inline-width-tiny);
}

.widget-vprogress .progress {
    flex-grow: 1;
    width: var(--jp-widgets-progress-thickness);
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 0;
}

/* Select Widget Styling */

.widget-dropdown {
    height: var(--jp-widgets-inline-height);
    width: var(--jp-widgets-inline-width);
    line-height: var(--jp-widgets-inline-height);
}

.widget-dropdown > select {
    padding-right: 20px;
    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);
    border-radius: 0;
    height: inherit;
    flex: 1 1 var(--jp-widgets-inline-width-short);
    min-width: 0; /* This makes it possible for the flexbox to shrink this input */
    box-sizing: border-box;
    outline: none !important;
    box-shadow: none;
    background-color: var(--jp-widgets-input-background-color);
    color: var(--jp-widgets-input-color);
    font-size: var(--jp-widgets-font-size);
    vertical-align: top;
    padding-left: calc( var(--jp-widgets-input-padding) * 2);
	appearance: none;
	-webkit-appearance: none;
	-moz-appearance: none;
    background-repeat: no-repeat;
	background-size: 20px;
	background-position: right center;
    background-image: var(--jp-widgets-dropdown-arrow);
}
.widget-dropdown > select:focus {
    border-color: var(--jp-widgets-input-focus-border-color);
}

.widget-dropdown > select:disabled {
    opacity: var(--jp-widgets-disabled-opacity);
}

/* To disable the dotted border in Firefox around select controls.
   See http://stackoverflow.com/a/18853002 */
.widget-dropdown > select:-moz-focusring {
    color: transparent;
    text-shadow: 0 0 0 #000;
}

/* Select and SelectMultiple */

.widget-select {
    width: var(--jp-widgets-inline-width);
    line-height: var(--jp-widgets-inline-height);

    /* Because Firefox defines the baseline of a select as the bottom of the
    control, we align the entire control to the top and add padding to the
    select to get an approximate first line baseline alignment. */
    align-items: flex-start;
}

.widget-select > select {
    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);
    background-color: var(--jp-widgets-input-background-color);
    color: var(--jp-widgets-input-color);
    font-size: var(--jp-widgets-font-size);
    flex: 1 1 var(--jp-widgets-inline-width-short);
    outline: none !important;
    overflow: auto;
    height: inherit;

    /* Because Firefox defines the baseline of a select as the bottom of the
    control, we align the entire control to the top and add padding to the
    select to get an approximate first line baseline alignment. */
    padding-top: 5px;
}

.widget-select > select:focus {
    border-color: var(--jp-widgets-input-focus-border-color);
}

.wiget-select > select > option {
    padding-left: var(--jp-widgets-input-padding);
    line-height: var(--jp-widgets-inline-height);
    /* line-height doesn't work on some browsers for select options */
    padding-top: calc(var(--jp-widgets-inline-height)-var(--jp-widgets-font-size)/2);
    padding-bottom: calc(var(--jp-widgets-inline-height)-var(--jp-widgets-font-size)/2);
}



/* Toggle Buttons Styling */

.widget-toggle-buttons {
    line-height: var(--jp-widgets-inline-height);
}

.widget-toggle-buttons .widget-toggle-button {
    margin-left: var(--jp-widgets-margin);
    margin-right: var(--jp-widgets-margin);
}

.widget-toggle-buttons .jupyter-button:disabled {
    opacity: var(--jp-widgets-disabled-opacity);
}

/* Radio Buttons Styling */

.widget-radio {
    width: var(--jp-widgets-inline-width);
    line-height: var(--jp-widgets-inline-height);
}

.widget-radio-box {
    display: flex;
    flex-direction: column;
    align-items: stretch;
    box-sizing: border-box;
    flex-grow: 1;
    margin-bottom: var(--jp-widgets-radio-item-height-adjustment);
}

.widget-radio-box label {
    height: var(--jp-widgets-radio-item-height);
    line-height: var(--jp-widgets-radio-item-height);
    font-size: var(--jp-widgets-font-size);
}

.widget-radio-box input {
    height: var(--jp-widgets-radio-item-height);
    line-height: var(--jp-widgets-radio-item-height);
    margin: 0 calc( var(--jp-widgets-input-padding) * 2 ) 0 1px;
    float: left;
}

/* Color Picker Styling */

.widget-colorpicker {
    width: var(--jp-widgets-inline-width);
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
}

.widget-colorpicker > .widget-colorpicker-input {
    flex-grow: 1;
    flex-shrink: 1;
    min-width: var(--jp-widgets-inline-width-tiny);
}

.widget-colorpicker input[type="color"] {
    width: var(--jp-widgets-inline-height);
    height: var(--jp-widgets-inline-height);
    padding: 0 2px; /* make the color square actually square on Chrome on OS X */
    background: var(--jp-widgets-input-background-color);
    color: var(--jp-widgets-input-color);
    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);
    border-left: none;
    flex-grow: 0;
    flex-shrink: 0;
    box-sizing: border-box;
    align-self: stretch;
    outline: none !important;
}

.widget-colorpicker.concise input[type="color"] {
    border-left: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);
}

.widget-colorpicker input[type="color"]:focus, .widget-colorpicker input[type="text"]:focus {
    border-color: var(--jp-widgets-input-focus-border-color);
}

.widget-colorpicker input[type="text"] {
    flex-grow: 1;
    outline: none !important;
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
    background: var(--jp-widgets-input-background-color);
    color: var(--jp-widgets-input-color);
    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);
    font-size: var(--jp-widgets-font-size);
    padding: var(--jp-widgets-input-padding) calc( var(--jp-widgets-input-padding) *  2 );
    min-width: 0; /* This makes it possible for the flexbox to shrink this input */
    flex-shrink: 1;
    box-sizing: border-box;
}

.widget-colorpicker input[type="text"]:disabled {
    opacity: var(--jp-widgets-disabled-opacity);
}

/* Date Picker Styling */

.widget-datepicker {
    width: var(--jp-widgets-inline-width);
    height: var(--jp-widgets-inline-height);
    line-height: var(--jp-widgets-inline-height);
}

.widget-datepicker input[type="date"] {
    flex-grow: 1;
    flex-shrink: 1;
    min-width: 0; /* This makes it possible for the flexbox to shrink this input */
    outline: none !important;
    height: var(--jp-widgets-inline-height);
    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);
    background-color: var(--jp-widgets-input-background-color);
    color: var(--jp-widgets-input-color);
    font-size: var(--jp-widgets-font-size);
    padding: var(--jp-widgets-input-padding) calc( var(--jp-widgets-input-padding) *  2 );
    box-sizing: border-box;
}

.widget-datepicker input[type="date"]:focus {
    border-color: var(--jp-widgets-input-focus-border-color);
}

.widget-datepicker input[type="date"]:invalid {
    border-color: var(--jp-warn-color1);
}

.widget-datepicker input[type="date"]:disabled {
    opacity: var(--jp-widgets-disabled-opacity);
}

/* Play Widget */

.widget-play {
    width: var(--jp-widgets-inline-width-short);
    display: flex;
    align-items: stretch;
}

.widget-play .jupyter-button {
    flex-grow: 1;
    height: auto;
}

.widget-play .jupyter-button:disabled {
    opacity: var(--jp-widgets-disabled-opacity);
}

/* Tab Widget */

.jupyter-widgets.widget-tab {
    display: flex;
    flex-direction: column;
}

.jupyter-widgets.widget-tab > .p-TabBar {
    /* Necessary so that a tab can be shifted down to overlay the border of the box below. */
    overflow-x: visible;
    overflow-y: visible;
}

.jupyter-widgets.widget-tab > .p-TabBar > .p-TabBar-content {
    /* Make sure that the tab grows from bottom up */
    align-items: flex-end;
    min-width: 0;
    min-height: 0;
}

.jupyter-widgets.widget-tab > .widget-tab-contents {
    width: 100%;
    box-sizing: border-box;
    margin: 0;
    background: var(--jp-layout-color1);
    color: var(--jp-ui-font-color1);
    border: var(--jp-border-width) solid var(--jp-border-color1);
    padding: var(--jp-widgets-container-padding);
    flex-grow: 1;
    overflow: auto;
}

.jupyter-widgets.widget-tab > .p-TabBar {
    font: var(--jp-widgets-font-size) Helvetica, Arial, sans-serif;
    min-height: calc(var(--jp-widgets-horizontal-tab-height) + var(--jp-border-width));
}

.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab {
    flex: 0 1 var(--jp-widgets-horizontal-tab-width);
    min-width: 35px;
    min-height: calc(var(--jp-widgets-horizontal-tab-height) + var(--jp-border-width));
    line-height: var(--jp-widgets-horizontal-tab-height);
    margin-left: calc(-1 * var(--jp-border-width));
    padding: 0px 10px;
    background: var(--jp-layout-color2);
    color: var(--jp-ui-font-color2);
    border: var(--jp-border-width) solid var(--jp-border-color1);
    border-bottom: none;
    position: relative;
}

.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-current {
    color: var(--jp-ui-font-color0);
    /* We want the background to match the tab content background */
    background: var(--jp-layout-color1);
    min-height: calc(var(--jp-widgets-horizontal-tab-height) + 2 * var(--jp-border-width));
    transform: translateY(var(--jp-border-width));
    overflow: visible;
}

.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-current:before {
    position: absolute;
    top: calc(-1 * var(--jp-border-width));
    left: calc(-1 * var(--jp-border-width));
    content: '';
    height: var(--jp-widgets-horizontal-tab-top-border);
    width: calc(100% + 2 * var(--jp-border-width));
    background: var(--jp-brand-color1);
}

.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab:first-child {
    margin-left: 0;
}

.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab:hover:not(.p-mod-current) {
    background: var(--jp-layout-color1);
    color: var(--jp-ui-font-color1);
}

.jupyter-widgets.widget-tab > .p-TabBar .p-mod-closable > .p-TabBar-tabCloseIcon {
    margin-left: 4px;
}

.jupyter-widgets.widget-tab > .p-TabBar .p-mod-closable > .p-TabBar-tabCloseIcon:before {
    font-family: FontAwesome;
    content: '\f00d'; /* close */
}

.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabIcon,
.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabLabel,
.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabCloseIcon {
    line-height: var(--jp-widgets-horizontal-tab-height);
}

/* Accordion Widget */

.p-Collapse {
    display: flex;
    flex-direction: column;
    align-items: stretch;
}

.p-Collapse-header {
    padding: var(--jp-widgets-input-padding);
    cursor: pointer;
    color: var(--jp-ui-font-color2);
    background-color: var(--jp-layout-color2);
    border: var(--jp-widgets-border-width) solid var(--jp-border-color1);
    padding: calc(var(--jp-widgets-container-padding) * 2 / 3) var(--jp-widgets-container-padding);
    font-weight: bold;
}

.p-Collapse-header:hover {
    background-color: var(--jp-layout-color1);
    color: var(--jp-ui-font-color1);
}

.p-Collapse-open > .p-Collapse-header {
    background-color: var(--jp-layout-color1);
    color: var(--jp-ui-font-color0);
    cursor: default;
    border-bottom: none;
}

.p-Collapse .p-Collapse-header::before {
    content: '\f0da\00A0';  /* caret-right, non-breaking space */
    display: inline-block;
    font: normal normal normal 14px/1 FontAwesome;
    font-size: inherit;
    text-rendering: auto;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
}

.p-Collapse-open > .p-Collapse-header::before {
    content: '\f0d7\00A0'; /* caret-down, non-breaking space */
}

.p-Collapse-contents {
    padding: var(--jp-widgets-container-padding);
    background-color: var(--jp-layout-color1);
    color: var(--jp-ui-font-color1);
    border-left: var(--jp-widgets-border-width) solid var(--jp-border-color1);
    border-right: var(--jp-widgets-border-width) solid var(--jp-border-color1);
    border-bottom: var(--jp-widgets-border-width) solid var(--jp-border-color1);
    overflow: auto;
}

.p-Accordion {
    display: flex;
    flex-direction: column;
    align-items: stretch;
}

.p-Accordion .p-Collapse {
    margin-bottom: 0;
}

.p-Accordion .p-Collapse + .p-Collapse {
    margin-top: 4px;
}



/* HTML widget */

.widget-html, .widget-htmlmath {
    font-size: var(--jp-widgets-font-size);
}

.widget-html > .widget-html-content, .widget-htmlmath > .widget-html-content {
    /* Fill out the area in the HTML widget */
    align-self: stretch;
    flex-grow: 1;
    flex-shrink: 1;
    /* Makes sure the baseline is still aligned with other elements */
    line-height: var(--jp-widgets-inline-height);
    /* Make it possible to have absolutely-positioned elements in the html */
    position: relative;
}


/* Image widget  */

.widget-image {
    max-width: 100%;
    height: auto;
}
</style><style type="text/css">/* Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */
</style><style type="text/css">div.MathJax_MathML {text-align: center; margin: .75em 0px; display: block!important}
.MathJax_MathML {font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
span.MathJax_MathML {display: inline!important}
.MathJax_mmlExBox {display: block!important; overflow: hidden; height: 1px; width: 60ex; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0}
[class="MJX-tex-oldstyle"] {font-family: MathJax_Caligraphic, MathJax_Caligraphic-WEB}
[class="MJX-tex-oldstyle-bold"] {font-family: MathJax_Caligraphic, MathJax_Caligraphic-WEB; font-weight: bold}
[class="MJX-tex-caligraphic"] {font-family: MathJax_Caligraphic, MathJax_Caligraphic-WEB}
[class="MJX-tex-caligraphic-bold"] {font-family: MathJax_Caligraphic, MathJax_Caligraphic-WEB; font-weight: bold}
@font-face /*1*/ {font-family: MathJax_Caligraphic-WEB; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf')}
@font-face /*2*/ {font-family: MathJax_Caligraphic-WEB; font-weight: bold; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf')}
[mathvariant="double-struck"] {font-family: MathJax_AMS, MathJax_AMS-WEB}
[mathvariant="script"] {font-family: MathJax_Script, MathJax_Script-WEB}
[mathvariant="fraktur"] {font-family: MathJax_Fraktur, MathJax_Fraktur-WEB}
[mathvariant="bold-script"] {font-family: MathJax_Script, MathJax_Caligraphic-WEB; font-weight: bold}
[mathvariant="bold-fraktur"] {font-family: MathJax_Fraktur, MathJax_Fraktur-WEB; font-weight: bold}
[mathvariant="monospace"] {font-family: monospace}
[mathvariant="sans-serif"] {font-family: sans-serif}
[mathvariant="bold-sans-serif"] {font-family: sans-serif; font-weight: bold}
[mathvariant="sans-serif-italic"] {font-family: sans-serif; font-style: italic}
[mathvariant="sans-serif-bold-italic"] {font-family: sans-serif; font-style: italic; font-weight: bold}
@font-face /*3*/ {font-family: MathJax_AMS-WEB; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf')}
@font-face /*4*/ {font-family: MathJax_Script-WEB; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf')}
@font-face /*5*/ {font-family: MathJax_Fraktur-WEB; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf')}
@font-face /*6*/ {font-family: MathJax_Fraktur-WEB; font-weight: bold; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf')}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 0; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none; box-sizing: content-box}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_test.mjx-test-display {display: table!important}
.MathJax_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_test.mjx-test-default {display: block!important; clear: both}
.MathJax_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.MathJax_em_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60em}
.mjx-test-inline .MathJax_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">@font-face {font-family: STIXMathJax_Main; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/woff/STIXMathJax_Main-Regular.woff?V=2.7.7') format('woff'), url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/otf/STIXMathJax_Main-Regular.otf?V=2.7.7') format('opentype')}
</style><style type="text/css">@font-face {font-family: STIXMathJax_Main-italic; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/woff/STIXMathJax_Main-Italic.woff?V=2.7.7') format('woff'), url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/otf/STIXMathJax_Main-Italic.otf?V=2.7.7') format('opentype')}
</style><style type="text/css">@font-face {font-family: STIXMathJax_Normal-italic; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/woff/STIXMathJax_Normal-Italic.woff?V=2.7.7') format('woff'), url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/otf/STIXMathJax_Normal-Italic.otf?V=2.7.7') format('opentype')}
</style><link id="favicon" type="image/x-icon" rel="shortcut icon" href="https://biwnsxwo.labs.coursera.org/static/base/images/favicon-notebook.ico"><style type="text/css">@font-face {font-family: STIXMathJax_Size4; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/woff/STIXMathJax_Size4-Regular.woff?V=2.7.7') format('woff'), url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/otf/STIXMathJax_Size4-Regular.otf?V=2.7.7') format('opentype')}
</style><style type="text/css">@font-face {font-family: STIXMathJax_Symbols; src: url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/woff/STIXMathJax_Symbols-Regular.woff?V=2.7.7') format('woff'), url('https://biwnsxwo.labs.coursera.org/static/components/MathJax/fonts/HTML-CSS/STIX-Web/otf/STIXMathJax_Symbols-Regular.otf?V=2.7.7') format('opentype')}
</style></head>

<body class="notebook_app command_mode" data-base-url="/" data-ws-url="" data-notebook-name="C5_W4_A1_Transformer_Subclass_v1.ipynb" data-notebook-path="W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb" dir="ltr"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

<noscript>
    <div id='noscript'>
      Jupyter Notebook requires JavaScript.<br>
      Please enable it to proceed. 
  </div>
</noscript>

<div id="header" role="navigation" aria-label="Top Menu" style="display: block;">
  <div id="header-container" class="container">
  <div id="ipython_notebook" class="nav navbar-brand"><a href="https://biwnsxwo.labs.coursera.org/tree" title="dashboard">
      <img src="./logo.png" alt="Jupyter Notebook">
  </a></div>

  


<span id="save_widget" class="save_widget">
    <span id="notebook_name" class="filename">C5_W4_A1_Transformer_Subclass_v1</span>
    <span class="checkpoint_status" title="Tue, Jul 6, 2021 9:27 PM">Last Checkpoint: a minute ago</span>
    <span class="autosave_status">(autosaved)</span>
</span>


  

<span id="kernel_logo_widget">
  
  <img class="current_kernel_logo" alt="Current Kernel Logo" src="./logo-64x64.png" title="Python 3" style="display: inline;">
  
</span>


  
  
  
  

    <span id="login_widget">
      
    </span>

  

  
  
  </div>
  <div class="header-bar"></div>

  
<div id="menubar-container" class="container">
<div id="menubar">
    <div id="menus" class="navbar navbar-default" role="navigation">
        <div class="container-fluid">
            <button type="button" class="btn btn-default navbar-btn navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <i class="fa fa-bars"></i>
              <span class="navbar-text">Menu</span>
            </button>
            <p id="kernel_indicator" class="navbar-text indicator_area">
              <span class="kernel_indicator_name">Python 3</span>
              <i id="kernel_indicator_icon" class="kernel_idle_icon" title="Kernel Idle"></i>
            </p>
            <i id="readonly-indicator" class="navbar-text" title="This notebook is read-only" style="display: none;">
                <span class="fa-stack">
                    <i class="fa fa-save fa-stack-1x"></i>
                    <i class="fa fa-ban fa-stack-2x text-danger"></i>
                </span>
            </i>
            <i id="modal_indicator" class="navbar-text modal_indicator" title="Command Mode"></i>
            <span id="notification_area"><div id="notification_kernel" class="notification_widget btn btn-xs navbar-btn undefined info" style="display: none;"><span></span></div><div id="notification_notebook" class="notification_widget btn btn-xs navbar-btn" style="display: none;"><span></span></div><div id="notification_trusted" class="notification_widget btn btn-xs navbar-btn" disabled="disabled" style="cursor: help;"><span title="Javascript enabled for notebook display">Trusted</span></div><div id="notification_widgets" class="notification_widget btn btn-xs navbar-btn" style="display: none;"><span></span></div></span>
            <div class="navbar-collapse collapse">
              <ul class="nav navbar-nav">
                <li class="dropdown"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" id="filelink" aria-haspopup="true" aria-controls="file_menu class=" dropdown-toggle"="" data-toggle="dropdown" aria-expanded="false">File</a>
                    <ul id="file_menu" class="dropdown-menu" role="menu" aria-labelledby="filelink">
                        <li id="new_notebook" class="dropdown-submenu" role="none">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">New Notebook<span class="sr-only">Toggle Dropdown</span></a>
                            <ul class="dropdown-menu" id="menu-new-notebook-submenu"><li id="new-notebook-submenu-python3"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Python 3</a></li></ul>
                        </li>
                        <li id="open_notebook" role="none" title="Opens a new window with the Dashboard view">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Open...</a></li>
                        <!-- <hr/> -->
                        <li class="divider" role="none"></li>
                        <li id="copy_notebook" role="none" title="Open a copy of this notebook&#39;s contents and start a new kernel">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Make a Copy...</a></li>
                        <li id="save_notebook_as" role="none" title="Save a copy of the notebook&#39;s contents and start a new kernel">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Save as...</a></li>
                        <li id="rename_notebook" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Rename...</a></li>
                        <li id="save_checkpoint" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Save and Checkpoint</a></li>
                        <!-- <hr/> -->
                        <li class="divider" role="none"></li>
                        <li id="restore_checkpoint" class="dropdown-submenu" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Revert to Checkpoint<span class="sr-only">Toggle Dropdown</span></a>
                          <ul class="dropdown-menu"><li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Tuesday, July 6, 2021 9:27 PM</a></li></ul>
                        </li>
                        <li class="divider" role="none"></li>
                        <li id="print_preview" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Print Preview</a></li>
                        <li class="dropdown-submenu" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Download as<span class="sr-only">Toggle Dropdown</span></a>
                            <ul id="download_menu" class="dropdown-menu">
                                
                                <li id="download_asciidoc">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">AsciiDoc (.asciidoc)</a>
                                </li>
                                
                                <li id="download_html">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">HTML (.html)</a>
                                </li>
                                
                                <li id="download_latex">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">LaTeX (.tex)</a>
                                </li>
                                
                                <li id="download_markdown">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Markdown (.md)</a>
                                </li>
                                
                                <li id="download_notebook">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Notebook (.ipynb)</a>
                                </li>
                                
                                <li id="download_pdf">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">PDF via LaTeX (.pdf)</a>
                                </li>
                                
                                <li id="download_rst">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">reST (.rst)</a>
                                </li>
                                
                                <li id="download_script">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Python (.py)</a>
                                </li>
                                
                                <li id="download_slides">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Reveal.js slides (.slides.html)</a>
                                </li>
                                
                            </ul>
                        </li>
                        <li class="dropdown-submenu hidden" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Deploy as</a>
                            <ul id="deploy_menu" class="dropdown-menu"></ul>
                        </li>
                        <li class="divider" role="none"></li>
                        <li id="trust_notebook" role="none" title="Trust the output of this notebook" class="disabled">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Trusted Notebook</a></li>
                        <li class="divider" role="none"></li>
                        <li id="close_and_halt" role="none" title="Shutdown this notebook&#39;s kernel, and close this window">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Close and Halt</a></li>
                    </ul>
                </li>

                <li class="dropdown"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" class="dropdown-toggle" id="editlink" data-toggle="dropdown" aria-haspopup="true" aria-controls="edit_menu">Edit</a>
                    <ul id="edit_menu" class="dropdown-menu" role="menu" aria-labelledby="editlink">
                        <li id="cut_cell" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Cut Cells</a></li>
                        <li id="copy_cell" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Copy Cells</a></li>
                        <li id="paste_cell_above" class="disabled" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem" aria-disabled="true">Paste Cells Above</a></li>
                        <li id="paste_cell_below" class="disabled" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem" aria-disabled="true">Paste Cells Below</a></li>
                        <li id="paste_cell_replace" class="disabled" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem" aria-disabled="true">Paste Cells &amp; Replace</a></li>
                        <li id="delete_cell" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Delete Cells</a></li>
                        <li id="undelete_cell" class="disabled" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem" aria-disabled="true">Undo Delete Cells</a></li>
                        <li class="divider" role="none"></li>
                        <li id="split_cell" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Split Cell</a></li>
                        <li id="merge_cell_above" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Merge Cell Above</a></li>
                        <li id="merge_cell_below" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Merge Cell Below</a></li>
                        <li class="divider" role="none"></li>
                        <li id="move_cell_up" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Move Cell Up</a></li>
                        <li id="move_cell_down" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Move Cell Down</a></li>
                        <li class="divider" role="none"></li>
                        <li id="edit_nb_metadata" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Edit Notebook Metadata</a></li>
                        <li class="divider" role="none"></li>
                        <li id="find_and_replace" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem"> Find and Replace </a></li>
                        <li class="divider" role="none"></li>
                        <li id="cut_cell_attachments" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Cut Cell Attachments</a></li>
                        <li id="copy_cell_attachments" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Copy Cell Attachments</a></li>
                        <li id="paste_cell_attachments" class="disabled" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem" aria-disabled="true">Paste Cell Attachments</a></li>
                        <li class="divider" role="none"></li>
                        <li id="insert_image" class="disabled" role="none"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem" aria-disabled="true">  Insert Image </a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" class="dropdown-toggle" id="viewlink" data-toggle="dropdown" aria-haspopup="true" aria-controls="view_menu">View</a>
                    <ul id="view_menu" class="dropdown-menu" role="menu" aria-labelledby="viewlink">
                        <li id="toggle_header" role="none" title="Show/Hide the logo and notebook title (above menu bar)">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Toggle Header</a>
                        </li>
                        <li id="toggle_toolbar" role="none" title="Show/Hide the action icons (below menu bar)">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Toggle Toolbar</a>
                        </li>
                        <li id="toggle_line_numbers" role="none" title="Show/Hide line numbers in cells">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Toggle Line Numbers</a>
                        </li>
                        <li id="menu-cell-toolbar" class="dropdown-submenu" role="none">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Cell Toolbar</a>
                            <ul class="dropdown-menu" id="menu-cell-toolbar-submenu"><li data-name="None"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">None</a></li><li data-name="Edit%20Metadata"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Edit Metadata</a></li><li data-name="Raw%20Cell%20Format"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Raw Cell Format</a></li><li data-name="Slideshow"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Slideshow</a></li><li data-name="Attachments"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Attachments</a></li><li data-name="Tags"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Tags</a></li></ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" class="dropdown-toggle" id="insertlink" data-toggle="dropdown" aria-haspopup="true" aria-controls="insert_menu">Insert</a>
                    <ul id="insert_menu" class="dropdown-menu" role="menu" aria-labelledby="insertlink">
                        <li id="insert_cell_above" role="none" title="Insert an empty Code cell above the currently active cell">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Insert Cell Above</a></li>
                        <li id="insert_cell_below" role="none" title="Insert an empty Code cell below the currently active cell">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="menuitem">Insert Cell Below</a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Cell</a>
                    <ul id="cell_menu" class="dropdown-menu">
                        <li id="run_cell" title="Run this cell, and move cursor to the next one">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Run Cells</a></li>
                        <li id="run_cell_select_below" title="Run this cell, select below">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Run Cells and Select Below</a></li>
                        <li id="run_cell_insert_below" title="Run this cell, insert below">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Run Cells and Insert Below</a></li>
                        <li id="run_all_cells" title="Run all cells in the notebook">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Run All</a></li>
                        <li id="run_all_cells_above" title="Run all cells above (but not including) this cell">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Run All Above</a></li>
                        <li id="run_all_cells_below" title="Run this cell and all cells below it">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Run All Below</a></li>
                        <li class="divider"></li>
                        <li id="change_cell_type" class="dropdown-submenu" title="All cells in the notebook have a cell type. By default, new cells are created as &#39;Code&#39; cells">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Cell Type</a>
                            <ul class="dropdown-menu">
                              <li id="to_code" title="Contents will be sent to the kernel for execution, and output will display in the footer of cell">
                                  <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Code</a></li>
                              <li id="to_markdown" title="Contents will be rendered as HTML and serve as explanatory text">
                                  <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Markdown</a></li>
                              <li id="to_raw" title="Contents will pass through nbconvert unmodified">
                                  <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Raw NBConvert</a></li>
                            </ul>
                        </li>
                        <li class="divider"></li>
                        <li id="current_outputs" class="dropdown-submenu"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Current Outputs</a>
                            <ul class="dropdown-menu">
                                <li id="toggle_current_output" title="Hide/Show the output of the current cell">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Toggle</a>
                                </li>
                                <li id="toggle_current_output_scroll" title="Scroll the output of the current cell">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Toggle Scrolling</a>
                                </li>
                                <li id="clear_current_output" title="Clear the output of the current cell">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Clear</a>
                                </li>
                            </ul>
                        </li>
                        <li id="all_outputs" class="dropdown-submenu"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">All Output</a>
                            <ul class="dropdown-menu">
                                <li id="toggle_all_output" title="Hide/Show the output of all cells">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Toggle</a>
                                </li>
                                <li id="toggle_all_output_scroll" title="Scroll the output of all cells">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Toggle Scrolling</a>
                                </li>
                                <li id="clear_all_output" title="Clear the output of all cells">
                                    <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Clear</a>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" class="dropdown-toggle" data-toggle="dropdown" id="kernellink">Kernel</a>
                    <ul id="kernel_menu" class="dropdown-menu" aria-labelledby="kernellink">
                        <li id="int_kernel" title="Send Keyboard Interrupt (CTRL-C) to the Kernel">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Interrupt</a>
                        </li>
                        <li id="restart_kernel" title="Restart the Kernel">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Restart</a>
                        </li>
                        <li id="restart_clear_output" title="Restart the Kernel and clear all output">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Restart &amp; Clear Output</a>
                        </li>
                        <li id="restart_run_all" title="Restart the Kernel and re-run the notebook">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Restart &amp; Run All</a>
                        </li>
                        <li id="reconnect_kernel" title="Reconnect to the Kernel">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Reconnect</a>
                        </li>
                        <li id="shutdown_kernel" title="Shutdown the Kernel">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Shutdown</a>
                        </li>
                        <li class="divider"></li>
                        <li id="menu-change-kernel" class="dropdown-submenu">
                            <a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Change kernel</a>
                            <ul class="dropdown-menu" id="menu-change-kernel-submenu"><li id="kernel-submenu-python3"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Python 3</a></li></ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" data-toggle="dropdown" class="dropdown-toggle">Widgets</a><ul id="widget-submenu" class="dropdown-menu"><li title="Save the notebook with the widget state information for static rendering"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Save Notebook Widget State</a></li><li title="Clear the widget state information from the notebook"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Clear Notebook Widget State</a></li><ul class="divider"></ul><li title="Download the widget state as a JSON file"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Download Widget State</a></li><li title="Embed interactive widgets"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Embed Widgets</a></li></ul></li><li class="dropdown"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Help</a>
                    <ul id="help_menu" class="dropdown-menu">
                        
                        <li id="notebook_tour" title="A quick tour of the notebook user interface"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">User Interface Tour</a></li>
                        <li id="keyboard_shortcuts" title="Opens a tooltip with all keyboard shortcuts"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Keyboard Shortcuts</a></li>
                        <li id="edit_keyboard_shortcuts" title="Opens a dialog allowing you to edit Keyboard shortcuts"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">Edit Keyboard Shortcuts</a></li>
                        <li class="divider"></li>
                        

						
                        
                            
                                <li><a rel="noreferrer" href="http://nbviewer.jupyter.org/github/ipython/ipython/blob/3.x/examples/Notebook/Index.ipynb" target="_blank" title="Opens in a new window">
                                
                                    <i class="fa fa-external-link menu-icon pull-right"></i>
                                

                                Notebook Help
                                </a></li>
                            
                                <li><a rel="noreferrer" href="https://help.github.com/articles/markdown-basics/" target="_blank" title="Opens in a new window">
                                
                                    <i class="fa fa-external-link menu-icon pull-right"></i>
                                

                                Markdown
                                </a></li>
                            
                            
                        
                        <li id="kernel-help-links" class="divider"></li><li><a target="_blank" title="Opens in a new window" href="https://docs.python.org/3.7?v=20210706140437"><i class="fa fa-external-link menu-icon pull-right"></i><span>Python Reference</span></a></li><li><a target="_blank" title="Opens in a new window" href="https://ipython.org/documentation.html?v=20210706140437"><i class="fa fa-external-link menu-icon pull-right"></i><span>IPython Reference</span></a></li><li><a target="_blank" title="Opens in a new window" href="https://docs.scipy.org/doc/numpy/reference/?v=20210706140437"><i class="fa fa-external-link menu-icon pull-right"></i><span>NumPy Reference</span></a></li><li><a target="_blank" title="Opens in a new window" href="https://docs.scipy.org/doc/scipy/reference/?v=20210706140437"><i class="fa fa-external-link menu-icon pull-right"></i><span>SciPy Reference</span></a></li><li><a target="_blank" title="Opens in a new window" href="https://matplotlib.org/contents.html?v=20210706140437"><i class="fa fa-external-link menu-icon pull-right"></i><span>Matplotlib Reference</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.sympy.org/latest/index.html?v=20210706140437"><i class="fa fa-external-link menu-icon pull-right"></i><span>SymPy Reference</span></a></li><li><a target="_blank" title="Opens in a new window" href="https://pandas.pydata.org/pandas-docs/stable/?v=20210706140437"><i class="fa fa-external-link menu-icon pull-right"></i><span>pandas Reference</span></a></li><li class="divider"></li>
                        <li title="About Jupyter Notebook"><a id="notebook_about" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#">About</a></li>
                        
                    </ul>
                </li>
              </ul>
            </div>
        </div>
    </div>
</div>

<div id="maintoolbar" class="navbar">
  <div class="toolbar-inner navbar-inner navbar-nobg">
    <div id="maintoolbar-container" class="container toolbar"><div class="btn-group" id="save-notbook"><button class="btn btn-default" title="Save and Checkpoint" data-jupyter-action="jupyter-notebook:save-notebook"><i class="fa-save fa"></i></button></div><div class="btn-group" id="insert_above_below"><button class="btn btn-default" title="insert cell below" data-jupyter-action="jupyter-notebook:insert-cell-below"><i class="fa-plus fa"></i></button></div><div class="btn-group" id="cut_copy_paste"><button class="btn btn-default" title="cut selected cells" data-jupyter-action="jupyter-notebook:cut-cell"><i class="fa-cut fa"></i></button><button class="btn btn-default" title="copy selected cells" data-jupyter-action="jupyter-notebook:copy-cell"><i class="fa-copy fa"></i></button><button class="btn btn-default" title="paste cells below" data-jupyter-action="jupyter-notebook:paste-cell-below"><i class="fa-paste fa"></i></button></div><div class="btn-group" id="move_up_down"><button class="btn btn-default" title="move selected cells up" data-jupyter-action="jupyter-notebook:move-cell-up"><i class="fa-arrow-up fa"></i></button><button class="btn btn-default" title="move selected cells down" data-jupyter-action="jupyter-notebook:move-cell-down"><i class="fa-arrow-down fa"></i></button></div><div class="btn-group" id="run_int"><button class="btn btn-default" title="Run" data-jupyter-action="jupyter-notebook:run-cell-and-select-next"><i class="fa-step-forward fa"></i><span class="toolbar-btn-label">Run</span></button><button class="btn btn-default" title="interrupt the kernel" data-jupyter-action="jupyter-notebook:interrupt-kernel"><i class="fa-stop fa"></i></button><button class="btn btn-default" title="restart the kernel (with dialog)" data-jupyter-action="jupyter-notebook:confirm-restart-kernel"><i class="fa-repeat fa"></i></button><button class="btn btn-default" title="restart the kernel, then re-run the whole notebook (with dialog)" data-jupyter-action="jupyter-notebook:confirm-restart-kernel-and-run-all-cells"><i class="fa-forward fa"></i></button></div><select id="cell_type" aria-label="combobox, select cell type" role="combobox" class="form-control select-xs"><option value="code">Code</option><option value="markdown">Markdown</option><option value="raw">Raw NBConvert</option><option value="heading">Heading</option><option value="multiselect" disabled="disabled" style="display: none;">-</option></select><div class="btn-group" id="cmd_palette"><button class="btn btn-default" title="open the command palette" data-jupyter-action="jupyter-notebook:show-command-palette"><i class="fa-keyboard-o fa"></i></button></div><div class="btn-group" id="submit-notebook-button-group" style="float:right"><button class="btn btn-default" title="Submit this notebook for grading." id="submit-notebook-button" style="background-color:rgb(42, 115, 204); color:white; padding:4px 8px">Submit Assignment</button></div></div>
  </div>
</div>
</div>

<div class="lower-header-bar"></div>

</div>

<div id="site" style="display: block; height: 754px;">


<div id="ipython-main-app">
    <div id="notebook_panel">
        <div id="notebook" tabindex="-1"><div class="container" id="notebook-container"><div class="cell text_cell rendered unselected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 321px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 21px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-1"># Transformer Network</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Welcome to Week 4's assignment, the last assignment of Course 5 of the Deep Learning Specialization! And congratulations on making it to the last assignment of the entire Deep Learning Specialization - you're almost done!</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Ealier in the course, you've implemented sequential neural networks such as RNNs, GRUs, and LSTMs. In this notebook you'll explore the Transformer architecture, a neural network that takes advantage of parallel processing and allows you to substantially speed up the training process. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-strong">**After this assignment you'll be able to**</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* Create positional encodings to capture sequential relationships in data</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* Calculate scaled dot-product self-attention with word embeddings</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* Implement masked multi-head attention</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* Build and train a Transformer model</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">For the last time, let's get started!</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 321px;"></div><div class="CodeMirror-gutters" style="display: none; height: 336px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h1 id="Transformer-Network">Transformer Network<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Transformer-Network"></a></h1>
<p>Welcome to Week 4's assignment, the last assignment of Course 5 of the Deep Learning Specialization! And congratulations on making it to the last assignment of the entire Deep Learning Specialization - you're almost done!</p>
<p>Ealier in the course, you've implemented sequential neural networks such as RNNs, GRUs, and LSTMs. In this notebook you'll explore the Transformer architecture, a neural network that takes advantage of parallel processing and allows you to substantially speed up the training process. </p>
<p><strong>After this assignment you'll be able to</strong>:</p>
<ul>
<li>Create positional encodings to capture sequential relationships in data</li>
<li>Calculate scaled dot-product self-attention with word embeddings</li>
<li>Implement masked multi-head attention</li>
<li>Build and train a Transformer model</li>
</ul>
<p>For the last time, let's get started!</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 456px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Table of Contents</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-link cm-variable-2">[Packages]</span><span class="cm-string cm-url cm-variable-2">(#0)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-link cm-variable-2">[1 - Positional Encoding]</span><span class="cm-string cm-url cm-variable-2">(#1)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[1.1 - Sine and Cosine Angles]</span><span class="cm-string cm-url cm-variable-3">(#1-1)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">- </span><span class="cm-link cm-keyword">[Exercise 1 - get_angles]</span><span class="cm-string cm-url cm-keyword">(#ex-1)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[1.2 - Sine and Cosine Positional Encodings]</span><span class="cm-string cm-url cm-variable-3">(#1-2)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">- </span><span class="cm-link cm-keyword">[Exercise 2 - positional_encoding]</span><span class="cm-string cm-url cm-keyword">(#ex-2)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-link cm-variable-2">[2 - Masking]</span><span class="cm-string cm-url cm-variable-2">(#2)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[2.1 - Padding Mask]</span><span class="cm-string cm-url cm-variable-3">(#2-1)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[2.2 - Look-ahead Mask]</span><span class="cm-string cm-url cm-variable-3">(#2-2)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-link cm-variable-2">[3 - Self-Attention]</span><span class="cm-string cm-url cm-variable-2">(#3)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[Exercise 3 - scaled_dot_product_attention]</span><span class="cm-string cm-url cm-variable-3">(#ex-3)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-link cm-variable-2">[4 - Encoder]</span><span class="cm-string cm-url cm-variable-2">(#4)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[4.1 Encoder Layer]</span><span class="cm-string cm-url cm-variable-3">(#4-1)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">- </span><span class="cm-link cm-keyword">[Exercise 4 - EncoderLayer]</span><span class="cm-string cm-url cm-keyword">(#ex-4)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[4.2 - Full Encoder]</span><span class="cm-string cm-url cm-variable-3">(#4-2)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">- </span><span class="cm-link cm-keyword">[Exercise 5 - Encoder]</span><span class="cm-string cm-url cm-keyword">(#ex-5)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-link cm-variable-2">[5 - Decoder]</span><span class="cm-string cm-url cm-variable-2">(#5)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[5.1 - Decoder Layer]</span><span class="cm-string cm-url cm-variable-3">(#5-1)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">- </span><span class="cm-link cm-keyword">[Exercise 6 - DecoderLayer]</span><span class="cm-string cm-url cm-keyword">(#ex-6)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[5.2 - Full Decoder]</span><span class="cm-string cm-url cm-variable-3">(#5-2)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">- </span><span class="cm-link cm-keyword">[Exercise 7 - Decoder]</span><span class="cm-string cm-url cm-keyword">(#ex-7)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-link cm-variable-2">[6 - Transformer]</span><span class="cm-string cm-url cm-variable-2">(#6)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable-3">- </span><span class="cm-link cm-variable-3">[Exercise 8 - Transformer]</span><span class="cm-string cm-url cm-variable-3">(#ex-8)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-link cm-variable-2">[7 - References]</span><span class="cm-string cm-url cm-variable-2">(#7)</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 456px;"></div><div class="CodeMirror-gutters" style="display: none; height: 471px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Table-of-Contents">Table of Contents<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Table-of-Contents"></a></h2>
<ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#0">Packages</a></li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#1">1 - Positional Encoding</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#1-1">1.1 - Sine and Cosine Angles</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#ex-1">Exercise 1 - get_angles</a></li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#1-2">1.2 - Sine and Cosine Positional Encodings</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#ex-2">Exercise 2 - positional_encoding</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#2">2 - Masking</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#2-1">2.1 - Padding Mask</a></li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#2-2">2.2 - Look-ahead Mask</a></li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#3">3 - Self-Attention</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#ex-3">Exercise 3 - scaled_dot_product_attention</a></li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#4">4 - Encoder</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#4-1">4.1 Encoder Layer</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#ex-4">Exercise 4 - EncoderLayer</a></li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#4-2">4.2 - Full Encoder</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#ex-5">Exercise 5 - Encoder</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#5">5 - Decoder</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#5-1">5.1 - Decoder Layer</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#ex-6">Exercise 6 - DecoderLayer</a></li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#5-2">5.2 - Full Decoder</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#ex-7">Exercise 7 - Decoder</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#6">6 - Transformer</a><ul>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#ex-8">Exercise 8 - Transformer</a></li>
</ul>
</li>
<li><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#7">7 - References</a></li>
</ul>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 82px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'0'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Packages</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Run the following cell to load the packages you'll need.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 82px;"></div><div class="CodeMirror-gutters" style="display: none; height: 97px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="0"></a></p>
<h2 id="Packages">Packages<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Packages"></a></h2>
<p>Run the following cell to load the packages you'll need.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[1]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 917.438px; margin-bottom: -15px; border-right-width: 15px; min-height: 181px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">tensorflow</span> <span class="cm-keyword">as</span> <span class="cm-variable">tf</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">pandas</span> <span class="cm-keyword">as</span> <span class="cm-variable">pd</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">time</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">matplotlib</span>.<span class="cm-property">pyplot</span> <span class="cm-keyword">as</span> <span class="cm-variable">plt</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">tensorflow</span>.<span class="cm-property">keras</span>.<span class="cm-property">layers</span> <span class="cm-keyword">import</span> <span class="cm-variable">Embedding</span>, <span class="cm-variable">MultiHeadAttention</span>, <span class="cm-variable">Dense</span>, <span class="cm-variable">Input</span>, <span class="cm-variable">Dropout</span>, <span class="cm-variable">LayerNormalization</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">transformers</span> <span class="cm-keyword">import</span> <span class="cm-variable">DistilBertTokenizerFast</span> <span class="cm-comment">#, TFDistilBertModel</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">transformers</span> <span class="cm-keyword">import</span> <span class="cm-variable">TFDistilBertForTokenClassification</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">tqdm</span> <span class="cm-keyword">import</span> <span class="cm-variable">tqdm_notebook</span> <span class="cm-keyword">as</span> <span class="cm-variable">tqdm</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 181px;"></div><div class="CodeMirror-gutters" style="display: none; height: 196px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 730px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## 1 - Positional Encoding</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">In sequence to sequence tasks, the relative order of your data is extremely important to its meaning. When you were training sequential neural networks such as RNNs, you fed your inputs into the network in order. Information about the order of your data was automatically fed into your model.  However, when you train a Transformer network, you feed your data into the model all at once. While this dramatically reduces training time, there is no information about the order of your data. This is where positional encoding is useful - you can specifically encode the positions of your inputs and pass them into the network using these sine and cosine formulas:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-open">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">PE_<span class="cm-bracket">{</span>(pos, 2i)<span class="cm-bracket">}</span>= sin<span class="cm-tag">\left</span>(<span class="cm-tag">\frac</span><span class="cm-bracket">{</span>pos<span class="cm-bracket">}{{</span><span class="cm-atom">10000</span><span class="cm-bracket">}</span>^<span class="cm-bracket">{</span><span class="cm-tag">\frac</span><span class="cm-bracket">{</span><span class="cm-atom">2i</span><span class="cm-bracket">}{</span>d<span class="cm-bracket">}}}</span><span class="cm-tag">\right</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag">\tag</span><span class="cm-bracket">{</span><span class="cm-atom">1</span><span class="cm-bracket">}</span><span class="cm-delimit cm-delimit-close">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">br</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-open">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">PE_<span class="cm-bracket">{</span>(pos, 2i+1)<span class="cm-bracket">}</span>= cos<span class="cm-tag">\left</span>(<span class="cm-tag">\frac</span><span class="cm-bracket">{</span>pos<span class="cm-bracket">}{{</span><span class="cm-atom">10000</span><span class="cm-bracket">}</span>^<span class="cm-bracket">{</span><span class="cm-tag">\frac</span><span class="cm-bracket">{</span><span class="cm-atom">2i</span><span class="cm-bracket">}{</span>d<span class="cm-bracket">}}}</span><span class="cm-tag">\right</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag">\tag</span><span class="cm-bracket">{</span><span class="cm-atom">2</span><span class="cm-bracket">}</span><span class="cm-delimit cm-delimit-close">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* </span><span class="cm-delimit cm-delimit-open">$</span>d<span class="cm-delimit cm-delimit-close">$</span><span class="cm-variable-2"> is the dimension of the word embedding and positional encoding</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* </span><span class="cm-delimit cm-delimit-open">$</span>pos<span class="cm-delimit cm-delimit-close">$</span><span class="cm-variable-2"> is the position of the word.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* </span><span class="cm-delimit cm-delimit-open">$</span>i<span class="cm-delimit cm-delimit-close">$</span><span class="cm-variable-2"> refers to each of the different dimensions of the positional encoding.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">The values of the sine and cosine equations are small enough (between -1 and 1) that when you add the positional encoding to a word embedding, the word embedding is not significantly distorted. The sum of the positional encoding and word embeding is ultimately what is fed into the model. Using a combination of these two equations helps your Transformer network attend to the relative positions of your input data. Note that while in the lectures Andrew uses vertical vectors but in this assignment, all vectors are horizontal. All matrix multiplications should be adjusted accordingly.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'1-1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### 1.1 - Sine and Cosine Angles</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Get the possible angles used to compute the positional encodings by calculating the inner term of the sine and cosine equations: </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-open">$$</span><span class="cm-tag">\frac</span><span class="cm-bracket">{</span>pos<span class="cm-bracket">}{</span><span class="cm-atom">10000</span>^<span class="cm-bracket">{</span><span class="cm-tag">\frac</span><span class="cm-bracket">{</span><span class="cm-atom">2i</span><span class="cm-bracket">}{</span>d<span class="cm-bracket">}}}</span> <span class="cm-tag">\tag</span><span class="cm-bracket">{</span><span class="cm-atom">3</span><span class="cm-bracket">}</span><span class="cm-delimit cm-delimit-close">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'ex-1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Exercise 1 - get_angles</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Implement the function <span class="cm-comment">`get_angles()`</span> to calculate the possible angles for the sine and cosine  positional encodings</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 730px;"></div><div class="CodeMirror-gutters" style="display: none; height: 745px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="1"></a></p>
<h2 id="1---Positional-Encoding">1 - Positional Encoding<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#1---Positional-Encoding"></a></h2>
<p>In sequence to sequence tasks, the relative order of your data is extremely important to its meaning. When you were training sequential neural networks such as RNNs, you fed your inputs into the network in order. Information about the order of your data was automatically fed into your model.  However, when you train a Transformer network, you feed your data into the model all at once. While this dramatically reduces training time, there is no information about the order of your data. This is where positional encoding is useful - you can specifically encode the positions of your inputs and pass them into the network using these sine and cosine formulas:</p>
<p><span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_Display"><span class="MathJax MathJax_FullWidth" id="MathJax-Element-1-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtable displaystyle=&quot;true&quot;&gt;&lt;mlabeledtr&gt;&lt;mtd id=&quot;mjx-eqn-1&quot;&gt;&lt;mtext&gt;(1)&lt;/mtext&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;10000&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mlabeledtr&gt;&lt;/mtable&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 100%; display: inline-block; min-width: 15.869em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; font-size: 122%; min-width: 15.869em;"><span style="position: absolute; clip: rect(2.111em, 1011.6em, 5.565em, -999.997em); top: -4.095em; left: 0em; width: 100%;"><span class="mrow" id="MathJax-Span-2"><span class="mtable" id="MathJax-Span-3" style="min-width: 15.869em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; min-width: 15.869em;"><span style="display: inline-block; position: absolute; width: 11.713em; height: 0px; clip: rect(-1.988em, 1011.6em, 1.467em, -999.997em); top: 0em; left: 50%; margin-left: -5.852em;"><span style="position: absolute; clip: rect(2.111em, 1011.6em, 5.565em, -999.997em); top: -4.095em; left: 0em;"><span style="display: inline-block; position: relative; width: 11.713em; height: 0px;"><span style="position: absolute; clip: rect(2.111em, 1011.6em, 5.565em, -999.997em); top: -4.095em; left: 50%; margin-left: -5.852em;"><span class="mtd" id="MathJax-Span-7"><span class="mrow" id="MathJax-Span-8"><span class="mi" id="MathJax-Span-9" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.12em;"></span></span><span class="msubsup" id="MathJax-Span-10"><span style="display: inline-block; position: relative; width: 2.989em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.76em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-11" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.706em;"><span class="texatom" id="MathJax-Span-12"><span class="mrow" id="MathJax-Span-13"><span class="mo" id="MathJax-Span-14" style="font-size: 70.7%; font-family: STIXMathJax_Main;">(</span><span class="mi" id="MathJax-Span-15" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-16" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-17" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-18" style="font-size: 70.7%; font-family: STIXMathJax_Main;">,</span><span class="mn" id="MathJax-Span-19" style="font-size: 70.7%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-20" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-21" style="font-size: 70.7%; font-family: STIXMathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span class="mo" id="MathJax-Span-22" style="font-family: STIXMathJax_Main; padding-left: 0.296em;">=</span><span class="mi" id="MathJax-Span-23" style="font-family: STIXMathJax_Normal-italic; padding-left: 0.296em;"></span><span class="mi" id="MathJax-Span-24" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-25" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mrow" id="MathJax-Span-26" style="padding-left: 0.179em;"><span class="mo" id="MathJax-Span-27" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">(</span></span><span class="mfrac" id="MathJax-Span-28"><span style="display: inline-block; position: relative; width: 3.457em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.34em, 1001.35em, 4.335em, -999.997em); top: -4.681em; left: 50%; margin-left: -0.7em;"><span class="mrow" id="MathJax-Span-29"><span class="mi" id="MathJax-Span-30" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-31" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-32" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(2.696em, 1003.34em, 4.16em, -999.997em); top: -2.866em; left: 50%; margin-left: -1.695em;"><span class="msubsup" id="MathJax-Span-33"><span style="display: inline-block; position: relative; width: 3.34em; height: 0px;"><span style="position: absolute; clip: rect(3.106em, 1002.46em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="texatom" id="MathJax-Span-34"><span class="mrow" id="MathJax-Span-35"><span class="mn" id="MathJax-Span-36" style="font-family: STIXMathJax_Main;">10000</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -4.447em; left: 2.52em;"><span class="texatom" id="MathJax-Span-37"><span class="mrow" id="MathJax-Span-38"><span class="mfrac" id="MathJax-Span-39"><span style="display: inline-block; position: relative; width: 0.53em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.457em, 1000.35em, 4.16em, -999.997em); top: -4.33em; left: 50%; margin-left: -0.173em;"><span class="mrow" id="MathJax-Span-40"><span class="mn" id="MathJax-Span-41" style="font-size: 50%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-42" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(3.457em, 1000.3em, 4.16em, -999.997em); top: -3.627em; left: 50%; margin-left: -0.114em;"><span class="mi" id="MathJax-Span-43" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1000.53em, 1.232em, -999.997em); top: -1.227em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.53em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1003.46em, 1.232em, -999.997em); top: -1.285em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 3.457em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span><span class="mo" id="MathJax-Span-44" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">)</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; position: absolute; width: 1.174em; height: 0px; clip: rect(-0.875em, 1001.12em, 0.354em, -999.997em); top: 0em; right: 0em; margin-right: 0em;"><span style="position: absolute; clip: rect(3.106em, 1001.12em, 4.335em, -999.997em); top: -3.978em; right: 0em;"><span class="mtd" id="mjx-eqn-1"><span class="mrow" id="MathJax-Span-5"><span class="mtext" id="MathJax-Span-6" style="font-family: STIXMathJax_Main;">(1)</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.639em; border-left: 0px solid; width: 0px; height: 3.932em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd id="mjx-eqn-1"><mtext>(1)</mtext></mtd><mtd><mi>P</mi><msub><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo>,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mrow><mo>(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><msup><mrow class="MJX-TeXAtom-ORD"><mn>10000</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></mrow></msup></mfrac><mo>)</mo></mrow></mtd></mlabeledtr></mtable></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-1">
PE_{(pos, 2i)}= sin\left(\frac{pos}{{10000}^{\frac{2i}{d}}}\right)
\tag{1}</script>
<br>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_Display"><span class="MathJax MathJax_FullWidth" id="MathJax-Element-2-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtable displaystyle=&quot;true&quot;&gt;&lt;mlabeledtr&gt;&lt;mtd id=&quot;mjx-eqn-2&quot;&gt;&lt;mtext&gt;(2)&lt;/mtext&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;10000&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mlabeledtr&gt;&lt;/mtable&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-45" style="width: 100%; display: inline-block; min-width: 16.748em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; font-size: 122%; min-width: 16.748em;"><span style="position: absolute; clip: rect(2.111em, 1012.47em, 5.565em, -999.997em); top: -4.095em; left: 0em; width: 100%;"><span class="mrow" id="MathJax-Span-46"><span class="mtable" id="MathJax-Span-47" style="min-width: 16.748em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; min-width: 16.748em;"><span style="display: inline-block; position: absolute; width: 12.649em; height: 0px; clip: rect(-1.988em, 1012.47em, 1.467em, -999.997em); top: 0em; left: 50%; margin-left: -6.32em;"><span style="position: absolute; clip: rect(2.111em, 1012.47em, 5.565em, -999.997em); top: -4.095em; left: 0em;"><span style="display: inline-block; position: relative; width: 12.649em; height: 0px;"><span style="position: absolute; clip: rect(2.111em, 1012.47em, 5.565em, -999.997em); top: -4.095em; left: 50%; margin-left: -6.32em;"><span class="mtd" id="MathJax-Span-51"><span class="mrow" id="MathJax-Span-52"><span class="mi" id="MathJax-Span-53" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.12em;"></span></span><span class="msubsup" id="MathJax-Span-54"><span style="display: inline-block; position: relative; width: 3.809em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.76em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-55" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.706em;"><span class="texatom" id="MathJax-Span-56"><span class="mrow" id="MathJax-Span-57"><span class="mo" id="MathJax-Span-58" style="font-size: 70.7%; font-family: STIXMathJax_Main;">(</span><span class="mi" id="MathJax-Span-59" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-60" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-61" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-62" style="font-size: 70.7%; font-family: STIXMathJax_Main;">,</span><span class="mn" id="MathJax-Span-63" style="font-size: 70.7%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-64" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-65" style="font-size: 70.7%; font-family: STIXMathJax_Main;">+</span><span class="mn" id="MathJax-Span-66" style="font-size: 70.7%; font-family: STIXMathJax_Main;">1</span><span class="mo" id="MathJax-Span-67" style="font-size: 70.7%; font-family: STIXMathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span class="mo" id="MathJax-Span-68" style="font-family: STIXMathJax_Main; padding-left: 0.296em;">=</span><span class="mi" id="MathJax-Span-69" style="font-family: STIXMathJax_Normal-italic; padding-left: 0.296em;"></span><span class="mi" id="MathJax-Span-70" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-71" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mrow" id="MathJax-Span-72" style="padding-left: 0.179em;"><span class="mo" id="MathJax-Span-73" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">(</span></span><span class="mfrac" id="MathJax-Span-74"><span style="display: inline-block; position: relative; width: 3.457em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.34em, 1001.35em, 4.335em, -999.997em); top: -4.681em; left: 50%; margin-left: -0.7em;"><span class="mrow" id="MathJax-Span-75"><span class="mi" id="MathJax-Span-76" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-77" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-78" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(2.696em, 1003.34em, 4.16em, -999.997em); top: -2.866em; left: 50%; margin-left: -1.695em;"><span class="msubsup" id="MathJax-Span-79"><span style="display: inline-block; position: relative; width: 3.34em; height: 0px;"><span style="position: absolute; clip: rect(3.106em, 1002.46em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="texatom" id="MathJax-Span-80"><span class="mrow" id="MathJax-Span-81"><span class="mn" id="MathJax-Span-82" style="font-family: STIXMathJax_Main;">10000</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -4.447em; left: 2.52em;"><span class="texatom" id="MathJax-Span-83"><span class="mrow" id="MathJax-Span-84"><span class="mfrac" id="MathJax-Span-85"><span style="display: inline-block; position: relative; width: 0.53em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.457em, 1000.35em, 4.16em, -999.997em); top: -4.33em; left: 50%; margin-left: -0.173em;"><span class="mrow" id="MathJax-Span-86"><span class="mn" id="MathJax-Span-87" style="font-size: 50%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-88" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(3.457em, 1000.3em, 4.16em, -999.997em); top: -3.627em; left: 50%; margin-left: -0.114em;"><span class="mi" id="MathJax-Span-89" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1000.53em, 1.232em, -999.997em); top: -1.227em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.53em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1003.46em, 1.232em, -999.997em); top: -1.285em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 3.457em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span><span class="mo" id="MathJax-Span-90" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">)</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; position: absolute; width: 1.174em; height: 0px; clip: rect(-0.875em, 1001.12em, 0.354em, -999.997em); top: 0em; right: 0em; margin-right: 0em;"><span style="position: absolute; clip: rect(3.106em, 1001.12em, 4.335em, -999.997em); top: -3.978em; right: 0em;"><span class="mtd" id="mjx-eqn-2"><span class="mrow" id="MathJax-Span-49"><span class="mtext" id="MathJax-Span-50" style="font-family: STIXMathJax_Main;">(2)</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.639em; border-left: 0px solid; width: 0px; height: 3.932em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd id="mjx-eqn-2"><mtext>(2)</mtext></mtd><mtd><mi>P</mi><msub><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo>,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mrow><mo>(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><msup><mrow class="MJX-TeXAtom-ORD"><mn>10000</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></mrow></msup></mfrac><mo>)</mo></mrow></mtd></mlabeledtr></mtable></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-2">
PE_{(pos, 2i+1)}= cos\left(\frac{pos}{{10000}^{\frac{2i}{d}}}\right)
\tag{2}</script></p>
<ul>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-91" style="width: 0.647em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.53em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.467em, 1000.53em, 2.462em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-92"><span class="mi" id="MathJax-Span-93" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></span></span><script type="math/tex" id="MathJax-Element-3">d</script> is the dimension of the word embedding and positional encoding</li>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-94" style="width: 1.759em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.408em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.642em, 1001.35em, 2.638em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-95"><span class="mi" id="MathJax-Span-96" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-97" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-98" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left: 0px solid; width: 0px; height: 0.932em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mi>o</mi><mi>s</mi></math></span></span><script type="math/tex" id="MathJax-Element-4">pos</script> is the position of the word.</li>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-99" style="width: 0.354em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.296em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.467em, 1000.24em, 2.462em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-100"><span class="mi" id="MathJax-Span-101" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 0.932em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></span></span><script type="math/tex" id="MathJax-Element-5">i</script> refers to each of the different dimensions of the positional encoding.</li>
</ul>
<p>The values of the sine and cosine equations are small enough (between -1 and 1) that when you add the positional encoding to a word embedding, the word embedding is not significantly distorted. The sum of the positional encoding and word embeding is ultimately what is fed into the model. Using a combination of these two equations helps your Transformer network attend to the relative positions of your input data. Note that while in the lectures Andrew uses vertical vectors but in this assignment, all vectors are horizontal. All matrix multiplications should be adjusted accordingly.</p>
<p><a name="1-1"></a></p>
<h3 id="1.1---Sine-and-Cosine-Angles">1.1 - Sine and Cosine Angles<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#1.1---Sine-and-Cosine-Angles"></a></h3>
<p>Get the possible angles used to compute the positional encodings by calculating the inner term of the sine and cosine equations: </p>
<p><span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_Display"><span class="MathJax MathJax_FullWidth" id="MathJax-Element-6-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtable displaystyle=&quot;true&quot;&gt;&lt;mlabeledtr&gt;&lt;mtd id=&quot;mjx-eqn-3&quot;&gt;&lt;mtext&gt;(3)&lt;/mtext&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mn&gt;10000&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;/mtd&gt;&lt;/mlabeledtr&gt;&lt;/mtable&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-102" style="width: 100%; display: inline-block; min-width: 7.848em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; font-size: 122%; min-width: 7.848em;"><span style="position: absolute; clip: rect(2.462em, 1003.69em, 5.038em, -999.997em); top: -3.978em; left: 0em; width: 100%;"><span class="mrow" id="MathJax-Span-103"><span class="mtable" id="MathJax-Span-104" style="min-width: 7.848em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; min-width: 7.848em;"><span style="display: inline-block; position: absolute; width: 3.691em; height: 0px; clip: rect(-1.519em, 1003.69em, 1.057em, -999.997em); top: 0em; left: 50%; margin-left: -1.871em;"><span style="position: absolute; clip: rect(2.462em, 1003.69em, 5.038em, -999.997em); top: -3.978em; left: 0em;"><span style="display: inline-block; position: relative; width: 3.691em; height: 0px;"><span style="position: absolute; clip: rect(2.696em, 1003.69em, 5.272em, -999.997em); top: -4.213em; left: 50%; margin-left: -1.871em;"><span class="mtd" id="MathJax-Span-108"><span class="mrow" id="MathJax-Span-109"><span class="mfrac" id="MathJax-Span-110"><span style="display: inline-block; position: relative; width: 3.457em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.34em, 1001.35em, 4.335em, -999.997em); top: -4.681em; left: 50%; margin-left: -0.7em;"><span class="mrow" id="MathJax-Span-111"><span class="mi" id="MathJax-Span-112" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-113" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-114" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(2.696em, 1003.34em, 4.16em, -999.997em); top: -2.866em; left: 50%; margin-left: -1.695em;"><span class="msubsup" id="MathJax-Span-115"><span style="display: inline-block; position: relative; width: 3.34em; height: 0px;"><span style="position: absolute; clip: rect(3.106em, 1002.46em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="mn" id="MathJax-Span-116" style="font-family: STIXMathJax_Main;">10000</span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -4.447em; left: 2.52em;"><span class="texatom" id="MathJax-Span-117"><span class="mrow" id="MathJax-Span-118"><span class="mfrac" id="MathJax-Span-119"><span style="display: inline-block; position: relative; width: 0.53em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.457em, 1000.35em, 4.16em, -999.997em); top: -4.33em; left: 50%; margin-left: -0.173em;"><span class="mrow" id="MathJax-Span-120"><span class="mn" id="MathJax-Span-121" style="font-size: 50%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-122" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(3.457em, 1000.3em, 4.16em, -999.997em); top: -3.627em; left: 50%; margin-left: -0.114em;"><span class="mi" id="MathJax-Span-123" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1000.53em, 1.232em, -999.997em); top: -1.227em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.53em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1003.46em, 1.232em, -999.997em); top: -1.285em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 3.457em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span><span style="display: inline-block; position: absolute; width: 1.174em; height: 0px; clip: rect(-1.109em, 1001.12em, 0.12em, -999.997em); top: 0em; right: 0em; margin-right: 0em;"><span style="position: absolute; clip: rect(3.106em, 1001.12em, 4.335em, -999.997em); top: -4.213em; right: 0em;"><span class="mtd" id="mjx-eqn-3"><span class="mrow" id="MathJax-Span-106"><span class="mtext" id="MathJax-Span-107" style="font-family: STIXMathJax_Main;">(3)</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.139em; border-left: 0px solid; width: 0px; height: 2.861em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd id="mjx-eqn-3"><mtext>(3)</mtext></mtd><mtd><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><msup><mn>10000</mn><mrow class="MJX-TeXAtom-ORD"><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></mrow></msup></mfrac></mtd></mlabeledtr></mtable></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-6">\frac{pos}{10000^{\frac{2i}{d}}} \tag{3}</script></p>
<p><a name="ex-1"></a></p>
<h3 id="Exercise-1---get_angles">Exercise 1 - get_angles<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Exercise-1---get_angles"></a></h3>
<p>Implement the function <code>get_angles()</code> to calculate the possible angles for the sine and cosine  positional encodings</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[77]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 656.016px; margin-bottom: -15px; border-right-width: 15px; min-height: 334px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># GRADED FUNCTION get_angles</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">get_angles</span>(<span class="cm-variable">pos</span>, <span class="cm-variable">i</span>, <span class="cm-variable">d</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Get the angles for the positional encoding</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        pos -- Column vector containing the positions [[0], [1], ...,[N-1]]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        i --   Row vector containing the dimension span [[0, 1, 2, ..., M-1]]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        d(integer) -- Encoding size</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        angles -- (pos, d) numpy array </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">angles</span> <span class="cm-operator">=</span> <span class="cm-variable">pos</span> <span class="cm-operator">/</span> <span class="cm-variable">np</span>.<span class="cm-property">power</span>(<span class="cm-number">10000</span>, (<span class="cm-number">2</span> <span class="cm-operator">*</span> (<span class="cm-variable">i</span> <span class="cm-operator">//</span> <span class="cm-number">2</span>)) <span class="cm-operator">/</span> <span class="cm-variable">d</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># END CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">angles</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 334px;"></div><div class="CodeMirror-gutters" style="display: none; height: 349px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[78]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 850.031px; margin-bottom: -15px; border-right-width: 15px; min-height: 504px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNIT TEST</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">get_angles_test</span>(<span class="cm-variable">target</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">position</span> <span class="cm-operator">=</span> <span class="cm-number">4</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">d_model</span> <span class="cm-operator">=</span> <span class="cm-number">16</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">pos_m</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">arange</span>(<span class="cm-variable">position</span>)[:, <span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">dims</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">arange</span>(<span class="cm-variable">d_model</span>)[<span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>, :]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">result</span> <span class="cm-operator">=</span> <span class="cm-variable">target</span>(<span class="cm-variable">pos_m</span>, <span class="cm-variable">dims</span>, <span class="cm-variable">d_model</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">type</span>(<span class="cm-variable">result</span>) <span class="cm-operator">==</span> <span class="cm-variable">np</span>.<span class="cm-property">ndarray</span>, <span class="cm-string">"You must return a numpy ndarray"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">result</span>.<span class="cm-property">shape</span> <span class="cm-operator">==</span> (<span class="cm-variable">position</span>, <span class="cm-variable">d_model</span>), <span class="cm-string">f"Wrong shape. We expected: (</span>{<span class="cm-variable">position</span>}<span class="cm-string">, </span>{<span class="cm-variable">d_model</span>}<span class="cm-string">)"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">sum</span>(<span class="cm-variable">result</span>[<span class="cm-number">0</span>, :]) <span class="cm-operator">==</span> <span class="cm-number">0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">isclose</span>(<span class="cm-variable">np</span>.<span class="cm-property">sum</span>(<span class="cm-variable">result</span>[:, <span class="cm-number">0</span>]), <span class="cm-variable">position</span> <span class="cm-operator">*</span> (<span class="cm-variable">position</span> <span class="cm-operator">-</span> <span class="cm-number">1</span>) <span class="cm-operator">/</span> <span class="cm-number">2</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">even_cols</span> <span class="cm-operator">=</span>  <span class="cm-variable">result</span>[:, <span class="cm-number">0</span>::<span class="cm-number">2</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">odd_cols</span> <span class="cm-operator">=</span> <span class="cm-variable">result</span>[:,  <span class="cm-number">1</span>::<span class="cm-number">2</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">all</span>(<span class="cm-variable">even_cols</span> <span class="cm-operator">==</span> <span class="cm-variable">odd_cols</span>), <span class="cm-string">"Submatrices of odd and even columns must be equal"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">limit</span> <span class="cm-operator">=</span> (<span class="cm-variable">position</span> <span class="cm-operator">-</span> <span class="cm-number">1</span>) <span class="cm-operator">/</span> <span class="cm-variable">np</span>.<span class="cm-property">power</span>(<span class="cm-number">10000</span>,<span class="cm-number">14.0</span><span class="cm-operator">/</span><span class="cm-number">16.0</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">isclose</span>(<span class="cm-variable">result</span>[<span class="cm-variable">position</span> <span class="cm-operator">-</span> <span class="cm-number">1</span>, <span class="cm-variable">d_model</span> <span class="cm-operator">-</span><span class="cm-number">1</span>], <span class="cm-variable">limit</span> ), <span class="cm-string">f"Last value must be </span>{<span class="cm-variable">limit</span>}<span class="cm-string">"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">"\033[92mAll tests passed"</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">get_angles_test</span>(<span class="cm-variable">get_angles</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Example</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">position</span> <span class="cm-operator">=</span> <span class="cm-number">4</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">d_model</span> <span class="cm-operator">=</span> <span class="cm-number">8</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pos_m</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">arange</span>(<span class="cm-variable">position</span>)[:, <span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">dims</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">arange</span>(<span class="cm-variable">d_model</span>)[<span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>, :]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">get_angles</span>(<span class="cm-variable">pos_m</span>, <span class="cm-variable">dims</span>, <span class="cm-variable">d_model</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 504px;"></div><div class="CodeMirror-gutters" style="display: none; height: 519px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre><span class="ansi-green-intense-fg">All tests passed
</span></pre></div></div><div class="output_area"><div class="run_this_cell"></div><div class="prompt output_prompt"><bdi>Out[78]:</bdi></div><div class="output_subarea output_text output_result"><pre>array([[0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00],
       [1.e+00, 1.e+00, 1.e-01, 1.e-01, 1.e-02, 1.e-02, 1.e-03, 1.e-03],
       [2.e+00, 2.e+00, 2.e-01, 2.e-01, 2.e-02, 2.e-02, 2.e-03, 2.e-03],
       [3.e+00, 3.e+00, 3.e-01, 3.e-01, 3.e-02, 3.e-02, 3.e-03, 3.e-03]])</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 422px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'1-2'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### 1.2 - Sine and Cosine Positional Encodings</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Now you can use the angles you computed to calculate the sine and cosine positional encodings.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-open">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">PE_<span class="cm-bracket">{</span>(pos, 2i)<span class="cm-bracket">}</span>= sin<span class="cm-tag">\left</span>(<span class="cm-tag">\frac</span><span class="cm-bracket">{</span>pos<span class="cm-bracket">}{{</span><span class="cm-atom">10000</span><span class="cm-bracket">}</span>^<span class="cm-bracket">{</span><span class="cm-tag">\frac</span><span class="cm-bracket">{</span><span class="cm-atom">2i</span><span class="cm-bracket">}{</span>d<span class="cm-bracket">}}}</span><span class="cm-tag">\right</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-close">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">br</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-open">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">PE_<span class="cm-bracket">{</span>(pos, 2i+1)<span class="cm-bracket">}</span>= cos<span class="cm-tag">\left</span>(<span class="cm-tag">\frac</span><span class="cm-bracket">{</span>pos<span class="cm-bracket">}{{</span><span class="cm-atom">10000</span><span class="cm-bracket">}</span>^<span class="cm-bracket">{</span><span class="cm-tag">\frac</span><span class="cm-bracket">{</span><span class="cm-atom">2i</span><span class="cm-bracket">}{</span>d<span class="cm-bracket">}}}</span><span class="cm-tag">\right</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-close">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'ex-2'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Exercise 2 - positional_encoding</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Implement the function <span class="cm-comment">`positional_encoding()`</span> to calculate the sine and cosine  positional encodings</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-strong">**Reminder:**</span> Use the sine equation when <span class="cm-delimit cm-delimit-open">$</span>i<span class="cm-delimit cm-delimit-close">$</span> is an even number and the cosine equation when <span class="cm-delimit cm-delimit-open">$</span>i<span class="cm-delimit cm-delimit-close">$</span> is an odd number.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-4">#### Additional Hints</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* You may find </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-link">[np.newaxis]</span><span class="cm-string cm-url">(https://numpy.org/doc/stable/reference/arrays.indexing.html)</span> useful depending on the implementation you choose. </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 422px;"></div><div class="CodeMirror-gutters" style="display: none; height: 437px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="1-2"></a></p>
<h3 id="1.2---Sine-and-Cosine-Positional-Encodings">1.2 - Sine and Cosine Positional Encodings<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#1.2---Sine-and-Cosine-Positional-Encodings"></a></h3>
<p>Now you can use the angles you computed to calculate the sine and cosine positional encodings.</p>
<p><span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;10000&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-124" style="width: 14.289em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.713em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(2.111em, 1011.6em, 5.565em, -999.997em); top: -4.095em; left: 0em;"><span class="mrow" id="MathJax-Span-125"><span class="mi" id="MathJax-Span-126" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.12em;"></span></span><span class="msubsup" id="MathJax-Span-127"><span style="display: inline-block; position: relative; width: 2.989em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.76em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-128" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.706em;"><span class="texatom" id="MathJax-Span-129"><span class="mrow" id="MathJax-Span-130"><span class="mo" id="MathJax-Span-131" style="font-size: 70.7%; font-family: STIXMathJax_Main;">(</span><span class="mi" id="MathJax-Span-132" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-133" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-134" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-135" style="font-size: 70.7%; font-family: STIXMathJax_Main;">,</span><span class="mn" id="MathJax-Span-136" style="font-size: 70.7%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-137" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-138" style="font-size: 70.7%; font-family: STIXMathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span class="mo" id="MathJax-Span-139" style="font-family: STIXMathJax_Main; padding-left: 0.296em;">=</span><span class="mi" id="MathJax-Span-140" style="font-family: STIXMathJax_Normal-italic; padding-left: 0.296em;"></span><span class="mi" id="MathJax-Span-141" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-142" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mrow" id="MathJax-Span-143" style="padding-left: 0.179em;"><span class="mo" id="MathJax-Span-144" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">(</span></span><span class="mfrac" id="MathJax-Span-145"><span style="display: inline-block; position: relative; width: 3.457em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.34em, 1001.35em, 4.335em, -999.997em); top: -4.681em; left: 50%; margin-left: -0.7em;"><span class="mrow" id="MathJax-Span-146"><span class="mi" id="MathJax-Span-147" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-148" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-149" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(2.696em, 1003.34em, 4.16em, -999.997em); top: -2.866em; left: 50%; margin-left: -1.695em;"><span class="msubsup" id="MathJax-Span-150"><span style="display: inline-block; position: relative; width: 3.34em; height: 0px;"><span style="position: absolute; clip: rect(3.106em, 1002.46em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="texatom" id="MathJax-Span-151"><span class="mrow" id="MathJax-Span-152"><span class="mn" id="MathJax-Span-153" style="font-family: STIXMathJax_Main;">10000</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -4.447em; left: 2.52em;"><span class="texatom" id="MathJax-Span-154"><span class="mrow" id="MathJax-Span-155"><span class="mfrac" id="MathJax-Span-156"><span style="display: inline-block; position: relative; width: 0.53em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.457em, 1000.35em, 4.16em, -999.997em); top: -4.33em; left: 50%; margin-left: -0.173em;"><span class="mrow" id="MathJax-Span-157"><span class="mn" id="MathJax-Span-158" style="font-size: 50%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-159" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(3.457em, 1000.3em, 4.16em, -999.997em); top: -3.627em; left: 50%; margin-left: -0.114em;"><span class="mi" id="MathJax-Span-160" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1000.53em, 1.232em, -999.997em); top: -1.227em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.53em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1003.46em, 1.232em, -999.997em); top: -1.285em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 3.457em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span><span class="mo" id="MathJax-Span-161" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.639em; border-left: 0px solid; width: 0px; height: 3.932em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><msub><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo>,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mrow><mo>(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><msup><mrow class="MJX-TeXAtom-ORD"><mn>10000</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></mrow></msup></mfrac><mo>)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-7">
PE_{(pos, 2i)}= sin\left(\frac{pos}{{10000}^{\frac{2i}{d}}}\right)
</script>
<br>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;10000&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-162" style="width: 15.401em; display: inline-block;"><span style="display: inline-block; position: relative; width: 12.591em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(2.111em, 1012.47em, 5.565em, -999.997em); top: -4.095em; left: 0em;"><span class="mrow" id="MathJax-Span-163"><span class="mi" id="MathJax-Span-164" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.12em;"></span></span><span class="msubsup" id="MathJax-Span-165"><span style="display: inline-block; position: relative; width: 3.809em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.76em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-166" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.706em;"><span class="texatom" id="MathJax-Span-167"><span class="mrow" id="MathJax-Span-168"><span class="mo" id="MathJax-Span-169" style="font-size: 70.7%; font-family: STIXMathJax_Main;">(</span><span class="mi" id="MathJax-Span-170" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-171" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-172" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-173" style="font-size: 70.7%; font-family: STIXMathJax_Main;">,</span><span class="mn" id="MathJax-Span-174" style="font-size: 70.7%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-175" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-176" style="font-size: 70.7%; font-family: STIXMathJax_Main;">+</span><span class="mn" id="MathJax-Span-177" style="font-size: 70.7%; font-family: STIXMathJax_Main;">1</span><span class="mo" id="MathJax-Span-178" style="font-size: 70.7%; font-family: STIXMathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span class="mo" id="MathJax-Span-179" style="font-family: STIXMathJax_Main; padding-left: 0.296em;">=</span><span class="mi" id="MathJax-Span-180" style="font-family: STIXMathJax_Normal-italic; padding-left: 0.296em;"></span><span class="mi" id="MathJax-Span-181" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-182" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mrow" id="MathJax-Span-183" style="padding-left: 0.179em;"><span class="mo" id="MathJax-Span-184" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">(</span></span><span class="mfrac" id="MathJax-Span-185"><span style="display: inline-block; position: relative; width: 3.457em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.34em, 1001.35em, 4.335em, -999.997em); top: -4.681em; left: 50%; margin-left: -0.7em;"><span class="mrow" id="MathJax-Span-186"><span class="mi" id="MathJax-Span-187" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-188" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mi" id="MathJax-Span-189" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(2.696em, 1003.34em, 4.16em, -999.997em); top: -2.866em; left: 50%; margin-left: -1.695em;"><span class="msubsup" id="MathJax-Span-190"><span style="display: inline-block; position: relative; width: 3.34em; height: 0px;"><span style="position: absolute; clip: rect(3.106em, 1002.46em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="texatom" id="MathJax-Span-191"><span class="mrow" id="MathJax-Span-192"><span class="mn" id="MathJax-Span-193" style="font-family: STIXMathJax_Main;">10000</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -4.447em; left: 2.52em;"><span class="texatom" id="MathJax-Span-194"><span class="mrow" id="MathJax-Span-195"><span class="mfrac" id="MathJax-Span-196"><span style="display: inline-block; position: relative; width: 0.53em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.457em, 1000.35em, 4.16em, -999.997em); top: -4.33em; left: 50%; margin-left: -0.173em;"><span class="mrow" id="MathJax-Span-197"><span class="mn" id="MathJax-Span-198" style="font-size: 50%; font-family: STIXMathJax_Main;">2</span><span class="mi" id="MathJax-Span-199" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(3.457em, 1000.3em, 4.16em, -999.997em); top: -3.627em; left: 50%; margin-left: -0.114em;"><span class="mi" id="MathJax-Span-200" style="font-size: 50%; font-family: STIXMathJax_Normal-italic;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1000.53em, 1.232em, -999.997em); top: -1.227em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.53em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1003.46em, 1.232em, -999.997em); top: -1.285em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 3.457em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span><span class="mo" id="MathJax-Span-201" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.639em; border-left: 0px solid; width: 0px; height: 3.932em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><msub><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo>,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mrow><mo>(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><msup><mrow class="MJX-TeXAtom-ORD"><mn>10000</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></mrow></msup></mfrac><mo>)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-8">
PE_{(pos, 2i+1)}= cos\left(\frac{pos}{{10000}^{\frac{2i}{d}}}\right)
</script></p>
<p><a name="ex-2"></a></p>
<h3 id="Exercise-2---positional_encoding">Exercise 2 - positional_encoding<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Exercise-2---positional_encoding"></a></h3>
<p>Implement the function <code>positional_encoding()</code> to calculate the sine and cosine  positional encodings</p>
<p><strong>Reminder:</strong> Use the sine equation when <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-202" style="width: 0.354em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.296em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.467em, 1000.24em, 2.462em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-203"><span class="mi" id="MathJax-Span-204" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 0.932em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></span></span><script type="math/tex" id="MathJax-Element-9">i</script> is an even number and the cosine equation when <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-205" style="width: 0.354em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.296em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.467em, 1000.24em, 2.462em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-206"><span class="mi" id="MathJax-Span-207" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 0.932em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></span></span><script type="math/tex" id="MathJax-Element-10">i</script> is an odd number.</p>
<h4 id="Additional-Hints">Additional Hints<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Additional-Hints"></a></h4>
<ul>
<li>You may find 
<a href="https://numpy.org/doc/stable/reference/arrays.indexing.html" target="_blank">np.newaxis</a> useful depending on the implementation you choose. </li>
</ul>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[79]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 723.453px; margin-bottom: -15px; border-right-width: 15px; min-height: 504px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># GRADED FUNCTION positional_encoding</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">positional_encoding</span>(<span class="cm-variable">positions</span>, <span class="cm-variable">d</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Precomputes a matrix with all the positional encodings </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        positions (int) -- Maximum number of positions to be encoded </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        d (int) -- Encoding size </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        pos_encoding -- (1, position, d_model) A matrix with the positional encodings</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># initialize a matrix angle_rads of all the angles </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">angle_rads</span> <span class="cm-operator">=</span> <span class="cm-variable">get_angles</span>(<span class="cm-variable">np</span>.<span class="cm-property">arange</span>(<span class="cm-variable">positions</span>)[:, <span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                            <span class="cm-variable">np</span>.<span class="cm-property">arange</span>(<span class="cm-variable">d</span>)[<span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>, :],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                            <span class="cm-variable">d</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-null cm-error">    </span><span class="cm-comment"># apply sin to even indices in the array; 2i</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">angle_rads</span>[:, <span class="cm-number">0</span>::<span class="cm-number">2</span>] <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">sin</span>(<span class="cm-variable">angle_rads</span>[:, <span class="cm-number">0</span>::<span class="cm-number">2</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-null cm-error">    </span><span class="cm-comment"># apply cos to odd indices in the array; 2i+1</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">angle_rads</span>[:, <span class="cm-number">1</span>::<span class="cm-number">2</span>] <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">cos</span>(<span class="cm-variable">angle_rads</span>[:, <span class="cm-number">1</span>::<span class="cm-number">2</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># END CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">pos_encoding</span> <span class="cm-operator">=</span> <span class="cm-variable">angle_rads</span>[<span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>, <span class="cm-operator">...</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">tf</span>.<span class="cm-property">cast</span>(<span class="cm-variable">pos_encoding</span>, <span class="cm-variable">dtype</span><span class="cm-operator">=</span><span class="cm-variable">tf</span>.<span class="cm-property">float32</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 504px;"></div><div class="CodeMirror-gutters" style="display: none; height: 519px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[80]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1044px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1043.89px; margin-bottom: -15px; border-right-width: 15px; min-height: 555px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNIT TEST</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">positional_encoding_test</span>(<span class="cm-variable">target</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">position</span> <span class="cm-operator">=</span> <span class="cm-number">8</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">d_model</span> <span class="cm-operator">=</span> <span class="cm-number">16</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">pos_encoding</span> <span class="cm-operator">=</span> <span class="cm-variable">target</span>(<span class="cm-variable">position</span>, <span class="cm-variable">d_model</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">sin_part</span> <span class="cm-operator">=</span> <span class="cm-variable">pos_encoding</span>[:, :, <span class="cm-number">0</span>::<span class="cm-number">2</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">cos_part</span> <span class="cm-operator">=</span> <span class="cm-variable">pos_encoding</span>[:, :, <span class="cm-number">1</span>::<span class="cm-number">2</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">pos_encoding</span>), <span class="cm-string">"Output is not a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">pos_encoding</span>.<span class="cm-property">shape</span> <span class="cm-operator">==</span> (<span class="cm-number">1</span>, <span class="cm-variable">position</span>, <span class="cm-variable">d_model</span>), <span class="cm-string">f"Wrong shape. We expected: (1, </span>{<span class="cm-variable">position</span>}<span class="cm-string">, </span>{<span class="cm-variable">d_model</span>}<span class="cm-string">)"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">ones</span> <span class="cm-operator">=</span> <span class="cm-variable">sin_part</span> <span class="cm-operator">**</span> <span class="cm-number">2</span>  <span class="cm-operator">+</span>  <span class="cm-variable">cos_part</span> <span class="cm-operator">**</span> <span class="cm-number">2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">ones</span>, <span class="cm-variable">np</span>.<span class="cm-property">ones</span>((<span class="cm-number">1</span>, <span class="cm-variable">position</span>, <span class="cm-variable">d_model</span> <span class="cm-operator">//</span> <span class="cm-number">2</span>))), <span class="cm-string">"Sum of square pairs must be 1 = sin(a)**2 + cos(a)**2"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">angs</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">arctan</span>(<span class="cm-variable">sin_part</span> <span class="cm-operator">/</span> <span class="cm-variable">cos_part</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">angs</span>[<span class="cm-variable">angs</span> <span class="cm-operator">&lt;</span> <span class="cm-number">0</span>] <span class="cm-operator">+=</span> <span class="cm-variable">np</span>.<span class="cm-property">pi</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">angs</span>[<span class="cm-variable">sin_part</span>.<span class="cm-property">numpy</span>() <span class="cm-operator">&lt;</span> <span class="cm-number">0</span>] <span class="cm-operator">+=</span> <span class="cm-variable">np</span>.<span class="cm-property">pi</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">angs</span> <span class="cm-operator">=</span> <span class="cm-variable">angs</span> <span class="cm-operator">%</span> (<span class="cm-number">2</span> <span class="cm-operator">*</span> <span class="cm-variable">np</span>.<span class="cm-property">pi</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">pos_m</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">arange</span>(<span class="cm-variable">position</span>)[:, <span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">dims</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">arange</span>(<span class="cm-variable">d_model</span>)[<span class="cm-variable">np</span>.<span class="cm-property">newaxis</span>, :]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">trueAngs</span> <span class="cm-operator">=</span> <span class="cm-variable">get_angles</span>(<span class="cm-variable">pos_m</span>, <span class="cm-variable">dims</span>, <span class="cm-variable">d_model</span>)[:, <span class="cm-number">0</span>::<span class="cm-number">2</span>] <span class="cm-operator">%</span> (<span class="cm-number">2</span> <span class="cm-operator">*</span> <span class="cm-variable">np</span>.<span class="cm-property">pi</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">angs</span>[<span class="cm-number">0</span>], <span class="cm-variable">trueAngs</span>), <span class="cm-string">"Did you apply sin and cos to even and odd parts respectively?"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-null cm-error">    </span><span class="cm-builtin">print</span>(<span class="cm-string">"\033[92mAll tests passed"</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">positional_encoding_test</span>(<span class="cm-variable">positional_encoding</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 555px;"></div><div class="CodeMirror-gutters" style="display: none; height: 585px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre><span class="ansi-green-intense-fg">All tests passed
</span></pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Nice work calculating the positional encodings! Now you can visualize them.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>Nice work calculating the positional encodings! Now you can visualize them.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[81]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 377.969px; margin-bottom: -15px; border-right-width: 15px; min-height: 181px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pos_encoding</span> <span class="cm-operator">=</span> <span class="cm-variable">positional_encoding</span>(<span class="cm-number">50</span>, <span class="cm-number">512</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span> (<span class="cm-variable">pos_encoding</span>.<span class="cm-property">shape</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">pcolormesh</span>(<span class="cm-variable">pos_encoding</span>[<span class="cm-number">0</span>], <span class="cm-variable">cmap</span><span class="cm-operator">=</span><span class="cm-string">'RdBu'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">xlabel</span>(<span class="cm-string">'d'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">xlim</span>((<span class="cm-number">0</span>, <span class="cm-number">512</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">ylabel</span>(<span class="cm-string">'Position'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">colorbar</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">show</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 181px;"></div><div class="CodeMirror-gutters" style="display: none; height: 196px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>(1, 50, 512)
</pre></div></div><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_png"><img src="data:image/png;base64,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"></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 45px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 16.5px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Each row represents a positional encoding - notice how none of the rows are identical! You have created a unique positional encoding for each of the words.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 45px;"></div><div class="CodeMirror-gutters" style="display: none; height: 60px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>Each row represents a positional encoding - notice how none of the rows are identical! You have created a unique positional encoding for each of the words.</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 814px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'2'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## 2 - Masking</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">There are two types of masks that are useful when building your Transformer network: the <span class="cm-em">*padding mask*</span> and the <span class="cm-em">*look-ahead mask*</span>. Both help the softmax computation give the appropriate weights to the words in your input sentence. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'2-1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### 2.1 - Padding Mask</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Oftentimes your input sequence will exceed the maximum length of a sequence your network can process. Let's say the maximum length of your model is five, it is fed the following sequences:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment">[["Do", "you", "know", "when", "Jane", "is", "going", "to", "visit", "Africa"], </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; <span class="cm-comment">["Jane", "visits", "Africa", "in", "September" ],</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; <span class="cm-comment">["Exciting", "!"]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment">]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">which might get vectorized as:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment">[[ 71, 121, 4, 56, 99, 2344, 345, 1284, 15],</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; <span class="cm-comment">[ 56, 1285, 15, 181, 545],</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; <span class="cm-comment">[ 87, 600]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment">]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">When passing sequences into a transformer model, it is important that they are of uniform length. You can achieve this by padding the sequence with zeros, and truncating sentences that exceed the maximum length of your model:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment">[[ 71, 121, 4, 56, 99],</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; <span class="cm-comment">[ 2344, 345, 1284, 15, 0],</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; <span class="cm-comment">[ 56, 1285, 15, 181, 545],</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; <span class="cm-comment">[ 87, 600, 0, 0, 0],</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment">]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Sequences longer than the maximum length of five will be truncated, and zeros will be added to the truncated sequence to achieve uniform length. Similarly, for sequences shorter than the maximum length, they zeros will also be added for padding. However, these zeros will affect the softmax calculation - this is when a padding mask comes in handy! You will need to define a boolean mask that specifies which elements you must attend(1) and which elements you must ignore(0). Later you will use that mask to set all the zeros in the sequence to a value close to negative infinity (-1e9). We'll implement this for you so you can get to the fun of building the Transformer network!  Just make sure you go through the code so you can correctly implement padding when building your model. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">After masking, your input should go from <span class="cm-comment">`[87, 600, 0, 0, 0]`</span> to <span class="cm-comment">`[87, 600, -1e9, -1e9, -1e9]`</span>, so that when you take the softmax, the zeros don't affect the score.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">The <span class="cm-link">[MultiheadAttention]</span><span class="cm-string cm-url">(https://keras.io/api/layers/attention_layers/multi_head_attention/)</span> layer implemented in Keras, use this masking logic.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 814px;"></div><div class="CodeMirror-gutters" style="display: none; height: 829px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="2"></a></p>
<h2 id="2---Masking">2 - Masking<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#2---Masking"></a></h2>
<p>There are two types of masks that are useful when building your Transformer network: the <em>padding mask</em> and the <em>look-ahead mask</em>. Both help the softmax computation give the appropriate weights to the words in your input sentence. </p>
<p><a name="2-1"></a></p>
<h3 id="2.1---Padding-Mask">2.1 - Padding Mask<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#2.1---Padding-Mask"></a></h3>
<p>Oftentimes your input sequence will exceed the maximum length of a sequence your network can process. Let's say the maximum length of your model is five, it is fed the following sequences:</p>
<pre><code>[["Do", "you", "know", "when", "Jane", "is", "going", "to", "visit", "Africa"], 
 ["Jane", "visits", "Africa", "in", "September" ],
 ["Exciting", "!"]
]</code></pre><p>which might get vectorized as:</p>
<pre><code>[[ 71, 121, 4, 56, 99, 2344, 345, 1284, 15],
 [ 56, 1285, 15, 181, 545],
 [ 87, 600]
]</code></pre><p>When passing sequences into a transformer model, it is important that they are of uniform length. You can achieve this by padding the sequence with zeros, and truncating sentences that exceed the maximum length of your model:</p>
<pre><code>[[ 71, 121, 4, 56, 99],
 [ 2344, 345, 1284, 15, 0],
 [ 56, 1285, 15, 181, 545],
 [ 87, 600, 0, 0, 0],
]</code></pre><p>Sequences longer than the maximum length of five will be truncated, and zeros will be added to the truncated sequence to achieve uniform length. Similarly, for sequences shorter than the maximum length, they zeros will also be added for padding. However, these zeros will affect the softmax calculation - this is when a padding mask comes in handy! You will need to define a boolean mask that specifies which elements you must attend(1) and which elements you must ignore(0). Later you will use that mask to set all the zeros in the sequence to a value close to negative infinity (-1e9). We'll implement this for you so you can get to the fun of building the Transformer network!  Just make sure you go through the code so you can correctly implement padding when building your model. </p>
<p>After masking, your input should go from <code>[87, 600, 0, 0, 0]</code> to <code>[87, 600, -1e9, -1e9, -1e9]</code>, so that when you take the softmax, the zeros don't affect the score.</p>
<p>The <a href="https://keras.io/api/layers/attention_layers/multi_head_attention/" target="_blank">MultiheadAttention</a> layer implemented in Keras, use this masking logic.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[82]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 479.219px; margin-bottom: -15px; border-right-width: 15px; min-height: 266px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">create_padding_mask</span>(<span class="cm-variable">seq</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Creates a matrix mask for the padding cells</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        seq -- (n, m) matrix</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        mask -- (n, 1, 1, m) binary tensor</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">seq</span> <span class="cm-operator">=</span> <span class="cm-number">1</span> <span class="cm-operator">-</span> <span class="cm-variable">tf</span>.<span class="cm-property">cast</span>(<span class="cm-variable">tf</span>.<span class="cm-property">math</span>.<span class="cm-property">equal</span>(<span class="cm-variable">seq</span>, <span class="cm-number">0</span>), <span class="cm-variable">tf</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-null cm-error">    </span><span class="cm-comment"># add extra dimensions to add the padding</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># to the attention logits.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">seq</span>[:, <span class="cm-variable">tf</span>.<span class="cm-property">newaxis</span>, <span class="cm-variable">tf</span>.<span class="cm-property">newaxis</span>, :] </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 266px;"></div><div class="CodeMirror-gutters" style="display: none; height: 281px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[83]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 706.719px; margin-bottom: -15px; border-right-width: 15px; min-height: 45px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>([[<span class="cm-number">7.</span>, <span class="cm-number">6.</span>, <span class="cm-number">0.</span>, <span class="cm-number">0.</span>, <span class="cm-number">1.</span>], [<span class="cm-number">1.</span>, <span class="cm-number">2.</span>, <span class="cm-number">3.</span>, <span class="cm-number">0.</span>, <span class="cm-number">0.</span>], [<span class="cm-number">0.</span>, <span class="cm-number">0.</span>, <span class="cm-number">0.</span>, <span class="cm-number">4.</span>, <span class="cm-number">5.</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-variable">create_padding_mask</span>(<span class="cm-variable">x</span>))</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 45px;"></div><div class="CodeMirror-gutters" style="display: none; height: 60px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>tf.Tensor(
[[[[1. 1. 0. 0. 1.]]]


 [[[1. 1. 1. 0. 0.]]]


 [[[0. 0. 0. 1. 1.]]]], shape=(3, 1, 1, 5), dtype=float32)
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 45px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 16.5px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">If we multiply (1 - mask) by -1e9 and add it to the sample input sequences, the zeros are essentially set to negative infinity. Notice the difference when taking the softmax of the original sequence and the masked sequence:</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 45px;"></div><div class="CodeMirror-gutters" style="display: none; height: 60px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>If we multiply (1 - mask) by -1e9 and add it to the sample input sequences, the zeros are essentially set to negative infinity. Notice the difference when taking the softmax of the original sequence and the masked sequence:</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[84]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 664.672px; margin-bottom: -15px; border-right-width: 15px; min-height: 45px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">activations</span>.<span class="cm-property">softmax</span>(<span class="cm-variable">x</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">activations</span>.<span class="cm-property">softmax</span>(<span class="cm-variable">x</span> <span class="cm-operator">+</span> (<span class="cm-number">1</span> <span class="cm-operator">-</span> <span class="cm-variable">create_padding_mask</span>(<span class="cm-variable">x</span>)) <span class="cm-operator">*</span> <span class="cm-operator">-</span><span class="cm-number">1.0e9</span>))</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 45px;"></div><div class="CodeMirror-gutters" style="display: none; height: 60px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>tf.Tensor(
[[7.2876644e-01 2.6809821e-01 6.6454901e-04 6.6454901e-04 1.8064314e-03]
 [8.4437378e-02 2.2952460e-01 6.2391251e-01 3.1062774e-02 3.1062774e-02]
 [4.8541026e-03 4.8541026e-03 4.8541026e-03 2.6502505e-01 7.2041273e-01]], shape=(3, 5), dtype=float32)
tf.Tensor(
[[[[7.2973627e-01 2.6845497e-01 0.0000000e+00 0.0000000e+00
    1.8088354e-03]
   [2.4472848e-01 6.6524094e-01 0.0000000e+00 0.0000000e+00
    9.0030573e-02]
   [6.6483547e-03 6.6483547e-03 0.0000000e+00 0.0000000e+00
    9.8670328e-01]]]


 [[[7.3057163e-01 2.6876229e-01 6.6619506e-04 0.0000000e+00
    0.0000000e+00]
   [9.0030573e-02 2.4472848e-01 6.6524094e-01 0.0000000e+00
    0.0000000e+00]
   [3.3333334e-01 3.3333334e-01 3.3333334e-01 0.0000000e+00
    0.0000000e+00]]]


 [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6894143e-01
    7.3105860e-01]
   [0.0000000e+00 0.0000000e+00 0.0000000e+00 5.0000000e-01
    5.0000000e-01]
   [0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6894143e-01
    7.3105860e-01]]]], shape=(3, 1, 3, 5), dtype=float32)
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 233px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'2-2'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### 2.2 - Look-ahead Mask</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">The look-ahead mask follows similar intuition. In training, you will have access to the complete correct output of your training example. The look-ahead mask helps your model pretend that it correctly predicted a part of the output and see if, <span class="cm-em">*without looking ahead*</span>, it can correctly predict the next output. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">For example, if the expected correct output is <span class="cm-comment">`[1, 2, 3]`</span> and you wanted to see if given that the model correctly predicted the first value it could predict the second value, you would mask out the second and third values. So you would input the masked sequence <span class="cm-comment">`[1, -1e9, -1e9]`</span> and see if it could generate <span class="cm-comment">`[1, 2, -1e9]`</span>.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Just because you've worked so hard, we'll also implement this mask for you . Again, take a close look at the code so you can effictively implement it later.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 233px;"></div><div class="CodeMirror-gutters" style="display: none; height: 248px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="2-2"></a></p>
<h3 id="2.2---Look-ahead-Mask">2.2 - Look-ahead Mask<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#2.2---Look-ahead-Mask"></a></h3>
<p>The look-ahead mask follows similar intuition. In training, you will have access to the complete correct output of your training example. The look-ahead mask helps your model pretend that it correctly predicted a part of the output and see if, <em>without looking ahead</em>, it can correctly predict the next output. </p>
<p>For example, if the expected correct output is <code>[1, 2, 3]</code> and you wanted to see if given that the model correctly predicted the first value it could predict the second value, you would mask out the second and third values. So you would input the masked sequence <code>[1, -1e9, -1e9]</code> and see if it could generate <code>[1, 2, -1e9]</code>.</p>
<p>Just because you've worked so hard, we'll also implement this mask for you . Again, take a close look at the code so you can effictively implement it later.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[85]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 512.859px; margin-bottom: -15px; border-right-width: 15px; min-height: 215px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">create_look_ahead_mask</span>(<span class="cm-variable">size</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Returns an upper triangular matrix filled with ones</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        size -- matrix size</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        mask -- (size, size) tensor</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">mask</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">linalg</span>.<span class="cm-property">band_part</span>(<span class="cm-variable">tf</span>.<span class="cm-property">ones</span>((<span class="cm-variable">size</span>, <span class="cm-variable">size</span>)), <span class="cm-operator">-</span><span class="cm-number">1</span>, <span class="cm-number">0</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">mask</span> </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 215px;"></div><div class="CodeMirror-gutters" style="display: none; height: 230px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[86]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 352.672px; margin-bottom: -15px; border-right-width: 15px; min-height: 62px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">random</span>.<span class="cm-property">uniform</span>((<span class="cm-number">1</span>, <span class="cm-number">3</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">temp</span> <span class="cm-operator">=</span> <span class="cm-variable">create_look_ahead_mask</span>(<span class="cm-variable">x</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">temp</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 62px;"></div><div class="CodeMirror-gutters" style="display: none; height: 77px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt output_prompt"><bdi>Out[86]:</bdi></div><div class="output_subarea output_text output_result"><pre>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 0., 0.],
       [1., 1., 0.],
       [1., 1., 1.]], dtype=float32)&gt;</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 575px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'3'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## 3 - Self-Attention</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">As the authors of the Transformers paper state, "Attention is All You Need". </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"self-attention.png"</span> <span class="cm-attribute">alt</span>=<span class="cm-string">"Encoder"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"600"</span><span class="cm-tag cm-bracket">/&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">caption</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">center</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">font</span> <span class="cm-attribute">color</span>=<span class="cm-string">'purple'</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">b</span><span class="cm-tag cm-bracket">&gt;</span>Figure 1: Self-Attention calculation visualization<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">font</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">center</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">caption</span><span class="cm-tag cm-bracket cm-error">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">The use of self-attention paired with traditional convolutional networks allows for the parallization which speeds up training. You will implement **scaled dot product attention** which takes in a query, key, value, and a mask as inputs to returns rich, attention-based vector representations of the words in your sequence. This type of self-attention can be mathematically expressed as:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-open">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag">\text</span> <span class="cm-bracket">{</span> Attention <span class="cm-bracket">}</span>(Q, K, V)=<span class="cm-tag">\operatorname</span><span class="cm-bracket">{</span>softmax<span class="cm-bracket">}</span><span class="cm-tag">\left</span>(<span class="cm-tag">\frac</span><span class="cm-bracket">{</span>Q K^<span class="cm-bracket">{</span>T<span class="cm-bracket">}}{</span><span class="cm-tag">\sqrt</span><span class="cm-bracket">{</span>d_<span class="cm-bracket">{</span>k<span class="cm-bracket">}}}</span>+<span class="cm-bracket">{</span>M<span class="cm-bracket">}</span><span class="cm-tag">\right</span>) V<span class="cm-tag">\tag</span><span class="cm-bracket">{</span><span class="cm-atom">4</span><span class="cm-bracket">}</span>\</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-delimit cm-delimit-close">$$</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* <span class="cm-delimit cm-delimit-open">$</span>Q<span class="cm-delimit cm-delimit-close">$</span> is the matrix of queries </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* <span class="cm-delimit cm-delimit-open">$</span>K<span class="cm-delimit cm-delimit-close">$</span> is the matrix of keys</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* <span class="cm-delimit cm-delimit-open">$</span>V<span class="cm-delimit cm-delimit-close">$</span> is the matrix of values</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* <span class="cm-delimit cm-delimit-open">$</span>M<span class="cm-delimit cm-delimit-close">$</span> is the optional mask you choose to apply </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* <span class="cm-delimit cm-delimit-open">$</span><span class="cm-bracket">{</span>d_k<span class="cm-bracket">}</span><span class="cm-delimit cm-delimit-close">$</span> is the dimension of the keys, which is used to scale everything down so the softmax doesn't explode</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'ex-3'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">### Exercise 3 - scaled_dot_product_attention </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  Implement the function `scaled_dot_product_attention()` to create attention-based representations</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">**Reminder**: The boolean mask parameter can be passed in as `none` or as either padding or look-ahead. Multiply (1. - mask) by -1e9 before applying the softmax. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">**Additional Hints**</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* You may find [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul) useful for matrix multiplication.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 575px;"></div><div class="CodeMirror-gutters" style="display: none; height: 590px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="3"></a></p>
<h2 id="3---Self-Attention">3 - Self-Attention<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#3---Self-Attention"></a></h2>
<p>As the authors of the Transformers paper state, "Attention is All You Need". </p>
<img src="./self-attention.png" alt="Encoder" width="600">
<center><font color="purple"><b>Figure 1: Self-Attention calculation visualization</b></font></center>

<p>The use of self-attention paired with traditional convolutional networks allows for the parallization which speeds up training. You will implement <strong>scaled dot product attention</strong> which takes in a query, key, value, and a mask as inputs to returns rich, attention-based vector representations of the words in your sequence. This type of self-attention can be mathematically expressed as:
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_Display"><span class="MathJax MathJax_FullWidth" id="MathJax-Element-11-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtable displaystyle=&quot;true&quot;&gt;&lt;mlabeledtr&gt;&lt;mtd id=&quot;mjx-eqn-4&quot;&gt;&lt;mtext&gt;(4)&lt;/mtext&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mtext&gt;&amp;#xA0;Attention&amp;#xA0;&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;softmax&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;msqrt&gt;&lt;msub&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mtext&gt;&amp;#xA0;&lt;/mtext&gt;&lt;/mtd&gt;&lt;/mlabeledtr&gt;&lt;/mtable&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-208" style="width: 100%; display: inline-block; min-width: 24.183em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; font-size: 122%; min-width: 24.183em;"><span style="position: absolute; clip: rect(2.111em, 1019.79em, 5.565em, -999.997em); top: -4.095em; left: 0em; width: 100%;"><span class="mrow" id="MathJax-Span-209"><span class="mtable" id="MathJax-Span-210" style="min-width: 24.183em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; min-width: 24.183em;"><span style="display: inline-block; position: absolute; width: 20.026em; height: 0px; clip: rect(-1.988em, 1019.79em, 1.467em, -999.997em); top: 0em; left: 50%; margin-left: -10.009em;"><span style="position: absolute; clip: rect(2.111em, 1019.79em, 5.565em, -999.997em); top: -4.095em; left: 0em;"><span style="display: inline-block; position: relative; width: 20.026em; height: 0px;"><span style="position: absolute; clip: rect(2.111em, 1019.79em, 5.565em, -999.997em); top: -4.095em; left: 50%; margin-left: -10.009em;"><span class="mtd" id="MathJax-Span-214"><span class="mrow" id="MathJax-Span-215"><span class="mtext" id="MathJax-Span-216" style="font-family: STIXMathJax_Main;">&nbsp;Attention&nbsp;</span><span class="mo" id="MathJax-Span-217" style="font-family: STIXMathJax_Main;">(</span><span class="mi" id="MathJax-Span-218" style="font-family: STIXMathJax_Normal-italic;"></span><span class="mo" id="MathJax-Span-219" style="font-family: STIXMathJax_Main;">,</span><span class="mi" id="MathJax-Span-220" style="font-family: STIXMathJax_Normal-italic; padding-left: 0.179em;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span class="mo" id="MathJax-Span-221" style="font-family: STIXMathJax_Main;">,</span><span class="mi" id="MathJax-Span-222" style="font-family: STIXMathJax_Normal-italic; padding-left: 0.179em;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.179em;"></span></span><span class="mo" id="MathJax-Span-223" style="font-family: STIXMathJax_Main;">)</span><span class="mo" id="MathJax-Span-224" style="font-family: STIXMathJax_Main; padding-left: 0.296em;">=</span><span class="mi" id="MathJax-Span-225" style="font-family: STIXMathJax_Main; padding-left: 0.296em;">softmax</span><span class="mo" id="MathJax-Span-226"></span><span class="mrow" id="MathJax-Span-227"><span class="mo" id="MathJax-Span-228" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">(</span></span><span class="mfrac" id="MathJax-Span-229"><span style="display: inline-block; position: relative; width: 2.345em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(2.989em, 1002.17em, 4.335em, -999.997em); top: -4.681em; left: 50%; margin-left: -1.109em;"><span class="mrow" id="MathJax-Span-230"><span class="mi" id="MathJax-Span-231" style="font-family: STIXMathJax_Normal-italic;"></span><span class="msubsup" id="MathJax-Span-232"><span style="display: inline-block; position: relative; width: 1.408em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.82em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-233" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -4.33em; left: 0.881em;"><span class="texatom" id="MathJax-Span-234"><span class="mrow" id="MathJax-Span-235"><span class="mi" id="MathJax-Span-236" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(2.93em, 1001.93em, 4.511em, -999.997em); top: -3.1em; left: 50%; margin-left: -0.992em;"><span class="msqrt" id="MathJax-Span-237"><span style="display: inline-block; position: relative; width: 1.935em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001em, 4.335em, -999.997em); top: -3.978em; left: 0.94em;"><span class="mrow" id="MathJax-Span-238"><span class="msubsup" id="MathJax-Span-239"><span style="display: inline-block; position: relative; width: 0.998em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.53em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-240" style="font-family: STIXMathJax_Normal-italic;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.53em;"><span class="texatom" id="MathJax-Span-241"><span class="mrow" id="MathJax-Span-242"><span class="mi" id="MathJax-Span-243" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(3.516em, 1001em, 3.926em, -999.997em); top: -4.564em; left: 0.94em;"><span style="display: inline-block; position: relative; width: 0.998em; height: 0px;"><span style="position: absolute; font-family: STIXMathJax_Symbols; top: -3.978em; left: 0em;"><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; font-family: STIXMathJax_Symbols; top: -3.978em; left: 0.706em;"><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="font-family: STIXMathJax_Symbols; position: absolute; top: -3.978em; left: 0.237em;"><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="font-family: STIXMathJax_Symbols; position: absolute; top: -3.978em; left: 0.471em;"><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(2.813em, 1000.94em, 4.394em, -999.997em); top: -3.861em; left: 0em;"><span style="font-family: STIXMathJax_Main;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; clip: rect(0.823em, 1002.35em, 1.232em, -999.997em); top: -1.285em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.345em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.057em;"></span></span></span></span><span class="mo" id="MathJax-Span-244" style="font-family: STIXMathJax_Main; padding-left: 0.237em;">+</span><span class="texatom" id="MathJax-Span-245" style="padding-left: 0.237em;"><span class="mrow" id="MathJax-Span-246"><span class="mi" id="MathJax-Span-247" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span></span><span class="mo" id="MathJax-Span-248" style="vertical-align: -0.758em;"><span style="font-family: STIXMathJax_Size4;">)</span></span></span><span class="mi" id="MathJax-Span-249" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.179em;"></span></span><span class="mtext" id="MathJax-Span-250" style="font-family: STIXMathJax_Main;">&nbsp;</span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; position: absolute; width: 1.174em; height: 0px; clip: rect(-0.875em, 1001.12em, 0.354em, -999.997em); top: 0em; right: 0em; margin-right: 0em;"><span style="position: absolute; clip: rect(3.106em, 1001.12em, 4.335em, -999.997em); top: -3.978em; right: 0em;"><span class="mtd" id="mjx-eqn-4"><span class="mrow" id="MathJax-Span-212"><span class="mtext" id="MathJax-Span-213" style="font-family: STIXMathJax_Main;">(4)</span></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.101em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.639em; border-left: 0px solid; width: 0px; height: 3.932em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd id="mjx-eqn-4"><mtext>(4)</mtext></mtd><mtd><mtext>&nbsp;Attention&nbsp;</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo>,</mo><mi>K</mi><mo>,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>softmax</mi><mo></mo><mrow><mo>(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mrow class="MJX-TeXAtom-ORD"><mi>T</mi></mrow></msup></mrow><msqrt><msub><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mi>k</mi></mrow></msub></msqrt></mfrac><mo>+</mo><mrow class="MJX-TeXAtom-ORD"><mi>M</mi></mrow><mo>)</mo></mrow><mi>V</mi><mtext>&nbsp;</mtext></mtd></mlabeledtr></mtable></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-11">
\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}+{M}\right) V\tag{4}\
</script></p>
<ul>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-251" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.764em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.467em, 1000.71em, 2.638em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-252"><span class="mi" id="MathJax-Span-253" style="font-family: STIXMathJax_Normal-italic;"></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left: 0px solid; width: 0px; height: 1.146em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Q</mi></math></span></span><script type="math/tex" id="MathJax-Element-12">Q</script> is the matrix of queries </li>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-254" style="width: 0.998em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.823em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.467em, 1000.82em, 2.462em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-255"><span class="mi" id="MathJax-Span-256" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 0.932em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-13">K</script> is the matrix of keys</li>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-257" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.764em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.467em, 1000.76em, 2.462em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-258"><span class="mi" id="MathJax-Span-259" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.179em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 0.932em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>V</mi></math></span></span><script type="math/tex" id="MathJax-Element-14">V</script> is the matrix of values</li>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-260" style="width: 1.291em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.057em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.467em, 1001.06em, 2.462em, -999.997em); top: -2.28em; left: 0em;"><span class="mrow" id="MathJax-Span-261"><span class="mi" id="MathJax-Span-262" style="font-family: STIXMathJax_Normal-italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.286em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 0.932em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi></math></span></span><script type="math/tex" id="MathJax-Element-15">M</script> is the optional mask you choose to apply </li>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-263" style="width: 1.232em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.998em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.35em, 1001em, 2.52em, -999.997em); top: -2.163em; left: 0em;"><span class="mrow" id="MathJax-Span-264"><span class="texatom" id="MathJax-Span-265"><span class="mrow" id="MathJax-Span-266"><span class="msubsup" id="MathJax-Span-267"><span style="display: inline-block; position: relative; width: 0.998em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.53em, 4.16em, -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-268" style="font-family: STIXMathJax_Normal-italic;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.53em;"><span class="mi" id="MathJax-Span-269" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;"></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.169em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left: 0px solid; width: 0px; height: 1.146em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><msub><mi>d</mi><mi>k</mi></msub></mrow></math></span></span><script type="math/tex" id="MathJax-Element-16">{d_k}</script> is the dimension of the keys, which is used to scale everything down so the softmax doesn't explode</li>
</ul>
<p><a name="ex-3"></a></p>
<h3 id="Exercise-3---scaled_dot_product_attention">Exercise 3 - scaled_dot_product_attention<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Exercise-3---scaled_dot_product_attention"></a></h3>
<pre><code>Implement the function `scaled_dot_product_attention()` to create attention-based representations</code></pre><p><strong>Reminder</strong>: The boolean mask parameter can be passed in as <code>none</code> or as either padding or look-ahead. Multiply (1. - mask) by -1e9 before applying the softmax. </p>
<p><strong>Additional Hints</strong></p>
<ul>
<li>You may find <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/matmul" target="_blank">tf.matmul</a> useful for matrix multiplication.</li>
</ul>
</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[154]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 311.594px; left: 299.016px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 917.438px; margin-bottom: -15px; border-right-width: 15px; min-height: 725px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors" style="visibility: hidden;"><div class="CodeMirror-cursor" style="left: 299.016px; top: 306px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># GRADED FUNCTION scaled_dot_product_attention</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">scaled_dot_product_attention</span>(<span class="cm-variable">q</span>, <span class="cm-variable">k</span>, <span class="cm-variable">v</span>, <span class="cm-variable">mask</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Calculate the attention weights.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">      q, k, v must have matching leading dimensions.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">      The mask has different shapes depending on its type(padding or look ahead) </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">      but it must be broadcastable for addition.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        q -- query shape == (..., seq_len_q, depth)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        k -- key shape == (..., seq_len_k, depth)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        v -- value shape == (..., seq_len_v, depth_v)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        mask: Float tensor with shape broadcastable </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">              to (..., seq_len_q, seq_len_k). Defaults to None.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        output -- attention_weights</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># Q*K'</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">matmul_qk</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">linalg</span>.<span class="cm-property">matmul</span>(<span class="cm-variable">q</span>, <span class="cm-variable">tf</span>.<span class="cm-property">linalg</span>.<span class="cm-property">matrix_transpose</span>(<span class="cm-variable">k</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># scale matmul_qk</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">dk</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">sqrt</span>(<span class="cm-variable">k</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">scaled_attention_logits</span> <span class="cm-operator">=</span> <span class="cm-variable">matmul_qk</span> <span class="cm-operator">/</span> <span class="cm-variable">dk</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># add the mask to the scaled tensor.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">if</span> <span class="cm-variable">mask</span> <span class="cm-keyword">is</span> <span class="cm-keyword">not</span> <span class="cm-keyword">None</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">scaled_attention_logits</span> <span class="cm-operator">+=</span> (<span class="cm-number">1.</span> <span class="cm-operator">-</span> <span class="cm-variable">mask</span>) <span class="cm-operator">*</span> <span class="cm-operator">-</span><span class="cm-number">1e9</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># softmax is normalized on the last axis (seq_len_k) so that the scores</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># add up to 1.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">attention_weights</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">activations</span>.<span class="cm-property">softmax</span>(<span class="cm-variable">scaled_attention_logits</span>)  <span class="cm-comment"># (..., seq_len_q, seq_len_k)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># attention_weights * V</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">output</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">linalg</span>.<span class="cm-property">matmul</span>(<span class="cm-variable">attention_weights</span>, <span class="cm-variable">v</span>) <span class="cm-comment"># (..., seq_len_q, depth_v)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># END CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">output</span>, <span class="cm-variable">attention_weights</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 725px;"></div><div class="CodeMirror-gutters" style="display: none; height: 740px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[155]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1112px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1111.5px; margin-bottom: -15px; border-right-width: 15px; min-height: 572px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNIT TEST</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">scaled_dot_product_attention_test</span>(<span class="cm-variable">target</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">q</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>], [<span class="cm-number">0</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>], [<span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>]]).<span class="cm-property">astype</span>(<span class="cm-variable">np</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">k</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>], [<span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span> ], [<span class="cm-number">0</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>], [<span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>]]).<span class="cm-property">astype</span>(<span class="cm-variable">np</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">v</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">0</span>, <span class="cm-number">0</span>], [<span class="cm-number">1</span>, <span class="cm-number">0</span>], [<span class="cm-number">1</span>, <span class="cm-number">0</span>], [<span class="cm-number">1</span>, <span class="cm-number">1</span>]]).<span class="cm-property">astype</span>(<span class="cm-variable">np</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">attention</span>, <span class="cm-variable">weights</span> <span class="cm-operator">=</span> <span class="cm-variable">target</span>(<span class="cm-variable">q</span>, <span class="cm-variable">k</span>, <span class="cm-variable">v</span>, <span class="cm-keyword">None</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">weights</span>), <span class="cm-string">"Weights must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">weights</span>).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> (<span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">k</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]), <span class="cm-string">f"Wrong shape. We expected (</span>{<span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>]}<span class="cm-string">, </span>{<span class="cm-variable">k</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]}<span class="cm-string">)"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">weights</span>, [[<span class="cm-number">0.2589478</span>,  <span class="cm-number">0.42693272</span>, <span class="cm-number">0.15705977</span>, <span class="cm-number">0.15705977</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                   [<span class="cm-number">0.2772748</span>,  <span class="cm-number">0.2772748</span>,  <span class="cm-number">0.2772748</span>,  <span class="cm-number">0.16817567</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                   [<span class="cm-number">0.33620113</span>, <span class="cm-number">0.33620113</span>, <span class="cm-number">0.12368149</span>, <span class="cm-number">0.2039163</span> ]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">attention</span>), <span class="cm-string">"Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">attention</span>).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> (<span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">v</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]), <span class="cm-string">f"Wrong shape. We expected (</span>{<span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>]}<span class="cm-string">, </span>{<span class="cm-variable">v</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]}<span class="cm-string">)"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">attention</span>, [[<span class="cm-number">0.74105227</span>, <span class="cm-number">0.15705977</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                   [<span class="cm-number">0.7227253</span>,  <span class="cm-number">0.16817567</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                   [<span class="cm-number">0.6637989</span>,  <span class="cm-number">0.2039163</span> ]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">mask</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>], [<span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>], [<span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">attention</span>, <span class="cm-variable">weights</span> <span class="cm-operator">=</span> <span class="cm-variable">target</span>(<span class="cm-variable">q</span>, <span class="cm-variable">k</span>, <span class="cm-variable">v</span>, <span class="cm-variable">mask</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">weights</span>, [[<span class="cm-number">0.30719590187072754</span>, <span class="cm-number">0.5064803957939148</span>, <span class="cm-number">0.0</span>, <span class="cm-number">0.18632373213768005</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                 [<span class="cm-number">0.3836517333984375</span>, <span class="cm-number">0.3836517333984375</span>, <span class="cm-number">0.0</span>, <span class="cm-number">0.2326965481042862</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                 [<span class="cm-number">0.3836517333984375</span>, <span class="cm-number">0.3836517333984375</span>, <span class="cm-number">0.0</span>, <span class="cm-number">0.2326965481042862</span>]]), <span class="cm-string">"Wrong masked weights"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">attention</span>, [[<span class="cm-number">0.6928040981292725</span>, <span class="cm-number">0.18632373213768005</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                   [<span class="cm-number">0.6163482666015625</span>, <span class="cm-number">0.2326965481042862</span>], </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                   [<span class="cm-number">0.6163482666015625</span>, <span class="cm-number">0.2326965481042862</span>]]), <span class="cm-string">"Wrong masked attention"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">"\033[92mAll tests passed"</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">scaled_dot_product_attention_test</span>(<span class="cm-variable">scaled_dot_product_attention</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 572px;"></div><div class="CodeMirror-gutters" style="display: none; height: 602px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre><span class="ansi-green-intense-fg">All tests passed
</span></pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell rendered unselected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Excellent work! You can now implement self-attention. With that, you can start building the encoder block! </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>Excellent work! You can now implement self-attention. With that, you can start building the encoder block! </p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 422px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'4'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## 4 - Encoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">The Transformer Encoder layer pairs self-attention and convolutional neural network style of processing to improve the speed of training and passes K and V matrices to the Decoder, which you'll build later in the assignment. In this section of the assignment, you will implement the Encoder by pairing multi-head attention and a feed forward neural network (Figure 2a). </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"encoder_layer.png"</span> <span class="cm-attribute">alt</span>=<span class="cm-string">"Encoder"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"250"</span><span class="cm-tag cm-bracket">/&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">caption</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">center</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">font</span> <span class="cm-attribute">color</span>=<span class="cm-string">'purple'</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">b</span><span class="cm-tag cm-bracket">&gt;</span>Figure 2a: Transformer encoder layer<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">font</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">center</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">caption</span><span class="cm-tag cm-bracket cm-error">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* `MultiHeadAttention` you can think of as computing the self-attention several times to detect different features. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* Feed forward neural network contains two Dense layers which we'll implement as the function `FullyConnected`</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Your input sentence first passes through a *multi-head attention layer*, where the encoder looks at other words in the input sentence as it encodes a specific word. The outputs of the multi-head attention layer are then fed to a *feed forward neural network*. The exact same feed forward network is independently applied to each position.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* For the `MultiHeadAttention` layer, you will use the [Keras implementation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention). If you're curious about how to split the query matrix Q, key matrix K, and value matrix V into different heads, you can look through the implementation. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* You will also use the [Sequential API](https://keras.io/api/models/sequential/) with two dense layers to built the feed forward neural network layers.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 422px;"></div><div class="CodeMirror-gutters" style="display: none; height: 437px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="4"></a></p>
<h2 id="4---Encoder">4 - Encoder<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#4---Encoder"></a></h2>
<p>The Transformer Encoder layer pairs self-attention and convolutional neural network style of processing to improve the speed of training and passes K and V matrices to the Decoder, which you'll build later in the assignment. In this section of the assignment, you will implement the Encoder by pairing multi-head attention and a feed forward neural network (Figure 2a). 
<img src="./encoder_layer.png" alt="Encoder" width="250"></p>
<center><font color="purple"><b>Figure 2a: Transformer encoder layer</b></font></center>

<ul>
<li><code>MultiHeadAttention</code> you can think of as computing the self-attention several times to detect different features. </li>
<li>Feed forward neural network contains two Dense layers which we'll implement as the function <code>FullyConnected</code></li>
</ul>
<p>Your input sentence first passes through a <em>multi-head attention layer</em>, where the encoder looks at other words in the input sentence as it encodes a specific word. The outputs of the multi-head attention layer are then fed to a <em>feed forward neural network</em>. The exact same feed forward network is independently applied to each position.</p>
<ul>
<li>For the <code>MultiHeadAttention</code> layer, you will use the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention" target="_blank">Keras implementation</a>. If you're curious about how to split the query matrix Q, key matrix K, and value matrix V into different heads, you can look through the implementation. </li>
<li>You will also use the <a href="https://keras.io/api/models/sequential/" target="_blank">Sequential API</a> with two dense layers to built the feed forward neural network layers.</li>
</ul>
</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[156]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 73.5938px; left: 54.5938px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 850px; margin-bottom: -15px; border-right-width: 15px; min-height: 96px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors" style="visibility: hidden;"><div class="CodeMirror-cursor" style="left: 54.5938px; top: 68px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">FullyConnected</span>(<span class="cm-variable">embedding_dim</span>, <span class="cm-variable">fully_connected_dim</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">Sequential</span><span class=" CodeMirror-matchingbracket">(</span>[</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">layers</span>.<span class="cm-property">Dense</span>(<span class="cm-variable">fully_connected_dim</span>, <span class="cm-variable">activation</span><span class="cm-operator">=</span><span class="cm-string">'relu'</span>),  <span class="cm-comment"># (batch_size, seq_len, dff)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">layers</span>.<span class="cm-property">Dense</span>(<span class="cm-variable">embedding_dim</span>)  <span class="cm-comment"># (batch_size, seq_len, d_model)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    ]<span class=" CodeMirror-matchingbracket">)</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 96px;"></div><div class="CodeMirror-gutters" style="display: none; height: 111px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell rendered unselected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 472px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'4-1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### 4.1 Encoder Layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Now you can pair multi-head attention and feed forward neural network together in an encoder layer! You will also use residual connections and layer normalization to help speed up training (Figure 2a).</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'ex-4'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Exercise 4 - EncoderLayer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Implement <span class="cm-comment">`EncoderLayer()`</span> using the <span class="cm-comment">`call()`</span> method</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">In this exercise, you will implement one encoder block (Figure 2) using the <span class="cm-comment">`call()`</span> method. The function should perform the following steps: </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">1. You will pass the Q, V, K matrices and a boolean mask to a multi-head attention layer. Remember that to compute </span><span class="cm-em cm-variable-2">*self*</span><span class="cm-variable-2">-attention Q, V and K should be the same.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">2. Next, you will pass the output of the multi-head attention layer to a dropout layer. Don't forget to use the </span><span class="cm-comment cm-variable-2">`training`</span><span class="cm-variable-2"> parameter to set the mode of your model. </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">3. Now add a skip connection by adding your original input </span><span class="cm-comment cm-variable-2">`x`</span><span class="cm-variable-2"> and the output of the dropout layer. </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">4. After adding the skip connection, pass the output through the first layer normalization.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">5. Finally, repeat steps 1-4 but with the feed forward neural network instead of the multi-head attention layer.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-strong">**Additional Hints**</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* The </span><span class="cm-comment cm-variable-2">`__init__`</span><span class="cm-variable-2"> method creates all the layers that will be accesed by the the </span><span class="cm-comment cm-variable-2">`call`</span><span class="cm-variable-2"> method. Wherever you want to use a layer defined inside  the </span><span class="cm-comment cm-variable-2">`__init__`</span><span class="cm-variable-2">  method you will have to use the syntax </span><span class="cm-comment cm-variable-2">`self.[insert layer name]`</span><span class="cm-variable-2">. </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* You will find the documentation of </span><span class="cm-link cm-variable-2">[MultiHeadAttention]</span><span class="cm-string cm-url cm-variable-2">(https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention)</span><span class="cm-variable-2"> helpful. </span><span class="cm-em cm-variable-2">*Note that if query, key and value are the same, then this function performs self-attention.*</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 472px;"></div><div class="CodeMirror-gutters" style="display: none; height: 487px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="4-1"></a></p>
<h3 id="4.1-Encoder-Layer">4.1 Encoder Layer<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#4.1-Encoder-Layer"></a></h3>
<p>Now you can pair multi-head attention and feed forward neural network together in an encoder layer! You will also use residual connections and layer normalization to help speed up training (Figure 2a).</p>
<p><a name="ex-4"></a></p>
<h3 id="Exercise-4---EncoderLayer">Exercise 4 - EncoderLayer<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Exercise-4---EncoderLayer"></a></h3>
<p>Implement <code>EncoderLayer()</code> using the <code>call()</code> method</p>
<p>In this exercise, you will implement one encoder block (Figure 2) using the <code>call()</code> method. The function should perform the following steps: </p>
<ol>
<li>You will pass the Q, V, K matrices and a boolean mask to a multi-head attention layer. Remember that to compute <em>self</em>-attention Q, V and K should be the same.</li>
<li>Next, you will pass the output of the multi-head attention layer to a dropout layer. Don't forget to use the <code>training</code> parameter to set the mode of your model. </li>
<li>Now add a skip connection by adding your original input <code>x</code> and the output of the dropout layer. </li>
<li>After adding the skip connection, pass the output through the first layer normalization.</li>
<li>Finally, repeat steps 1-4 but with the feed forward neural network instead of the multi-head attention layer.</li>
</ol>
<p><strong>Additional Hints</strong>:</p>
<ul>
<li>The <code>__init__</code> method creates all the layers that will be accesed by the the <code>call</code> method. Wherever you want to use a layer defined inside  the <code>__init__</code>  method you will have to use the syntax <code>self.[insert layer name]</code>. </li>
<li>You will find the documentation of <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention" target="_blank">MultiHeadAttention</a> helpful. <em>Note that if query, key and value are the same, then this function performs self-attention.</em></li>
</ul>
</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[157]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 787.594px; left: 358.094px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1044px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1" draggable="false"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1043.86px; margin-bottom: -15px; border-right-width: 15px; min-height: 1031px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors" style=""><div class="CodeMirror-cursor" style="left: 358.094px; top: 782px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># GRADED FUNCTION EncoderLayer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">class</span> <span class="cm-def">EncoderLayer</span>(<span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">layers</span>.<span class="cm-property">Layer</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    The encoder layer is composed by a multi-head self-attention mechanism,</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    followed by a simple, positionwise fully connected feed-forward network. </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    This archirecture includes a residual connection around each of the two </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    sub-layers, followed by layer normalization.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">__init__</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">embedding_dim</span>, <span class="cm-variable">num_heads</span>, <span class="cm-variable">fully_connected_dim</span>, <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-number">1e-6</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-builtin">super</span>(<span class="cm-variable">EncoderLayer</span>, <span class="cm-variable-2">self</span>).<span class="cm-property">__init__</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">mha</span> <span class="cm-operator">=</span> <span class="cm-variable">MultiHeadAttention</span>(<span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-variable">num_heads</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                      <span class="cm-variable">key_dim</span><span class="cm-operator">=</span><span class="cm-variable">embedding_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">ffn</span> <span class="cm-operator">=</span> <span class="cm-variable">FullyConnected</span>(<span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-variable">embedding_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                  <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-variable">fully_connected_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm1</span> <span class="cm-operator">=</span> <span class="cm-variable">LayerNormalization</span>(<span class="cm-variable">epsilon</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm2</span> <span class="cm-operator">=</span> <span class="cm-variable">LayerNormalization</span>(<span class="cm-variable">epsilon</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">dropout1</span> <span class="cm-operator">=</span> <span class="cm-variable">Dropout</span>(<span class="cm-variable">dropout_rate</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">dropout2</span> <span class="cm-operator">=</span> <span class="cm-variable">Dropout</span>(<span class="cm-variable">dropout_rate</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">call</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">x</span>, <span class="cm-variable">training</span>, <span class="cm-variable">mask</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Forward pass for the Encoder Layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            x -- Tensor of shape (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            training -- Boolean, set to true to activate</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                        the training mode for dropout layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            mask -- Boolean mask to ensure that the padding is not </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                    treated as part of the input</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            out2 -- Tensor of shape (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># calculate self-attention using mha(~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">self_attn_output</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">mha</span>(<span class="cm-variable">x</span>, <span class="cm-variable">x</span>, <span class="cm-variable">attention_mask</span><span class="cm-operator">=</span><span class="cm-variable">mask</span>)  <span class="cm-comment"># Self attention (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply dropout layer to the self-attention output (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">self_attn_output</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">dropout1</span>(<span class="cm-variable">self_attn_output</span>, <span class="cm-variable">training</span><span class="cm-operator">=</span><span class="cm-variable">training</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply layer normalization on sum of the input and the attention output to get the  </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># output of the multi-head attention layer (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">mult_attn_out</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm1</span>(<span class="cm-variable">x</span> <span class="cm-operator">+</span> <span class="cm-variable">self_attn_output</span>)  <span class="cm-comment"># (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># pass the output of the multi-head attention layer through a ffn (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">ffn_output</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">ffn</span>(<span class="cm-variable">mult_attn_out</span>)  <span class="cm-comment"># (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply dropout layer to ffn output (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">ffn_output</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">dropout2</span>(<span class="cm-variable">ffn_output</span>, <span class="cm-variable">training</span><span class="cm-operator">=</span><span class="cm-variable">training</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply layer normalization on sum of the output from multi-head attention and ffn output to get the</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># output of the encoder layer (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">encoder_layer_out</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm2</span>(<span class="cm-variable">mult_attn_out</span> <span class="cm-operator">+</span> <span class="cm-variable">ffn_output</span>)  <span class="cm-comment"># (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># END CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-keyword">return</span> <span class="cm-variable">encoder_layer_out</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 1031px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1061px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[158]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1162px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1162.09px; margin-bottom: -15px; border-right-width: 15px; min-height: 334px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNIT TEST</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">EncoderLayer_test</span>(<span class="cm-variable">target</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">q</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[[<span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>], [<span class="cm-number">0</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>], [<span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>]]]).<span class="cm-property">astype</span>(<span class="cm-variable">np</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">encoder_layer1</span> <span class="cm-operator">=</span> <span class="cm-variable">target</span>(<span class="cm-number">4</span>, <span class="cm-number">2</span>, <span class="cm-number">8</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">tf</span>.<span class="cm-property">random</span>.<span class="cm-property">set_seed</span>(<span class="cm-number">10</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">encoded</span> <span class="cm-operator">=</span> <span class="cm-variable">encoder_layer1</span>(<span class="cm-variable">q</span>, <span class="cm-keyword">True</span>, <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>]]))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">encoded</span>), <span class="cm-string">"Wrong type. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">encoded</span>).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> (<span class="cm-number">1</span>, <span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>], <span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">2</span>]), <span class="cm-string">f"Wrong shape. We expected ((1, </span>{<span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]}<span class="cm-string">, </span>{<span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">2</span>]}<span class="cm-string">))"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">encoded</span>.<span class="cm-property">numpy</span>(), </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [[<span class="cm-operator">-</span><span class="cm-number">0.5214877</span> , <span class="cm-operator">-</span><span class="cm-number">1.001476</span>  , <span class="cm-operator">-</span><span class="cm-number">0.12321664</span>,  <span class="cm-number">1.6461804</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [<span class="cm-operator">-</span><span class="cm-number">1.3114998</span> ,  <span class="cm-number">1.2167752</span> , <span class="cm-operator">-</span><span class="cm-number">0.5830886</span> ,  <span class="cm-number">0.6778133</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [ <span class="cm-number">0.25485858</span>,  <span class="cm-number">0.3776546</span> , <span class="cm-operator">-</span><span class="cm-number">1.6564771</span> ,  <span class="cm-number">1.023964</span>  ]],), <span class="cm-string">"Wrong values"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">"\033[92mAll tests passed"</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">EncoderLayer_test</span>(<span class="cm-variable">EncoderLayer</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 334px;"></div><div class="CodeMirror-gutters" style="display: none; height: 364px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre><span class="ansi-green-intense-fg">All tests passed
</span></pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell rendered unselected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 471px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'4-2'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### 4.2 - Full Encoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Awesome job! You have now successfully implemented positional encoding, self-attention, and an encoder layer - give yourself a pat on the back. Now you're ready to build the full Transformer Encoder (Figure 2b), where you will embedd your input and add the positional encodings you calculated. You will then feed your encoded embeddings to a stack of Encoder layers. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"encoder.png"</span> <span class="cm-attribute">alt</span>=<span class="cm-string">"Encoder"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"330"</span><span class="cm-tag cm-bracket">/&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">caption</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">center</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">font</span> <span class="cm-attribute">color</span>=<span class="cm-string">'purple'</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">b</span><span class="cm-tag cm-bracket">&gt;</span>Figure 2b: Transformer Encoder<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">font</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">center</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">caption</span><span class="cm-tag cm-bracket cm-error">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'ex-5'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">### Exercise 5 - Encoder</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Complete the `Encoder()` function using the `call()` method to embed your input, add positional encoding, and implement multiple encoder layers </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">In this exercise, you will initialize your Encoder with an Embedding layer, positional encoding, and multiple EncoderLayers. Your `call()` method will perform the following steps: </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">1. Pass your input through the Embedding layer.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">2. Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type `tf.float32` before computing the square root.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">3. Add the position encoding: self.pos_encoding `[:, :seq_len, :]` to your embedding.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">4. Pass the encoded embedding through a dropout layer, remembering to use the `training` parameter to set the model training mode. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">5. Pass the output of the dropout layer through the stack of encoding layers using a for loop.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 471px;"></div><div class="CodeMirror-gutters" style="display: none; height: 486px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="4-2"></a></p>
<h3 id="4.2---Full-Encoder">4.2 - Full Encoder<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#4.2---Full-Encoder"></a></h3>
<p>Awesome job! You have now successfully implemented positional encoding, self-attention, and an encoder layer - give yourself a pat on the back. Now you're ready to build the full Transformer Encoder (Figure 2b), where you will embedd your input and add the positional encodings you calculated. You will then feed your encoded embeddings to a stack of Encoder layers. </p>
<img src="./encoder.png" alt="Encoder" width="330">
<center><font color="purple"><b>Figure 2b: Transformer Encoder</b></font></center>


<p><a name="ex-5"></a></p>
<h3 id="Exercise-5---Encoder">Exercise 5 - Encoder<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Exercise-5---Encoder"></a></h3>
<p>Complete the <code>Encoder()</code> function using the <code>call()</code> method to embed your input, add positional encoding, and implement multiple encoder layers </p>
<p>In this exercise, you will initialize your Encoder with an Embedding layer, positional encoding, and multiple EncoderLayers. Your <code>call()</code> method will perform the following steps: </p>
<ol>
<li>Pass your input through the Embedding layer.</li>
<li>Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type <code>tf.float32</code> before computing the square root.</li>
<li>Add the position encoding: self.pos_encoding <code>[:, :seq_len, :]</code> to your embedding.</li>
<li>Pass the encoded embedding through a dropout layer, remembering to use the <code>training</code> parameter to set the model training mode. </li>
<li>Pass the output of the dropout layer through the stack of encoding layers using a for loop.</li>
</ol>
</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[198]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 515.594px; left: 164.188px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 841.531px; margin-bottom: -15px; border-right-width: 15px; min-height: 1048px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like">x</pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"><div class="CodeMirror-selected" style="position: absolute; left: 164.188px; top: 510px; width: 143.312px; height: 17px;"></div></div><div class="CodeMirror-cursors" style=""></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> <span class="cm-comment"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># GRADED FUNCTION</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">class</span> <span class="cm-def">Encoder</span>(<span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">layers</span>.<span class="cm-property">Layer</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    The entire Encoder starts by passing the input to an embedding layer </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    and using positional encoding to then pass the output through a stack of</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    encoder Layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span>   </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">__init__</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">num_layers</span>, <span class="cm-variable">embedding_dim</span>, <span class="cm-variable">num_heads</span>, <span class="cm-variable">fully_connected_dim</span>, <span class="cm-variable">input_vocab_size</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">               <span class="cm-variable">maximum_position_encoding</span>, <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-number">1e-6</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-builtin">super</span>(<span class="cm-variable">Encoder</span>, <span class="cm-variable-2">self</span>).<span class="cm-property">__init__</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span> <span class="cm-operator">=</span> <span class="cm-variable">embedding_dim</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">num_layers</span> <span class="cm-operator">=</span> <span class="cm-variable">num_layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">embedding</span> <span class="cm-operator">=</span> <span class="cm-variable">Embedding</span>(<span class="cm-variable">input_vocab_size</span>, <span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">pos_encoding</span> <span class="cm-operator">=</span> <span class="cm-variable">positional_encoding</span>(<span class="cm-variable">maximum_position_encoding</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                                <span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">enc_layers</span> <span class="cm-operator">=</span> [<span class="cm-variable">EncoderLayer</span>(<span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                        <span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-variable">num_heads</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                        <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-variable">fully_connected_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                        <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-variable">dropout_rate</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                        <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>) </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                           <span class="cm-keyword">for</span> <span class="cm-variable">_</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-variable-2">self</span>.<span class="cm-property">num_layers</span>)]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">dropout</span> <span class="cm-operator">=</span> <span class="cm-variable">Dropout</span>(<span class="cm-variable">dropout_rate</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">call</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">x</span>, <span class="cm-variable">training</span>, <span class="cm-variable">mask</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Forward pass for the Encoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            x -- Tensor of shape (batch_size, input_seq_len)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            training -- Boolean, set to true to activate</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                        the training mode for dropout layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            mask -- Boolean mask to ensure that the padding is not </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                    treated as part of the input</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            out2 -- Tensor of shape (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">seq_len</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">x</span>)[<span class="cm-number">1</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># Pass input through the Embedding layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">embedding</span>(<span class="cm-variable">x</span>)  <span class="cm-comment"># (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># Scale embedding by multiplying it by the square root of the embedding dimension</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">x</span> <span class="cm-operator">*=</span> <span class="cm-variable">tf</span>.<span class="cm-property">math</span>.<span class="cm-property">sqrt</span>( <span class="cm-variable">tf</span>.<span class="cm-property">cast</span>(<span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span>, <span class="cm-variable">dtype</span><span class="cm-operator">=</span><span class="cm-variable">tf</span>.<span class="cm-property">float32</span>) )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># Add the position encoding to embedding</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">x</span> <span class="cm-operator">+=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">pos_encoding</span>[:, :<span class="cm-variable">seq_len</span>, :]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># Pass the encoded embedding through a dropout layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">dropout</span>(<span class="cm-variable">x</span>, <span class="cm-variable">training</span><span class="cm-operator">=</span><span class="cm-variable">training</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># Pass the output through the stack of encoding layers </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-variable-2">self</span>.<span class="cm-property">num_layers</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">            <span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">enc_layers</span>[<span class="cm-variable">i</span>](<span class="cm-variable">x</span>, <span class="cm-variable">training</span>, <span class="cm-variable">mask</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># END CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-keyword">return</span> <span class="cm-variable">x</span>  <span class="cm-comment"># (batch_size, input_seq_len, embedding_dim)</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 1048px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1063px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[199]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1415px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1414.94px; margin-bottom: -15px; border-right-width: 15px; min-height: 691px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNIT TEST</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">Encoder_test</span>(<span class="cm-variable">target</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">tf</span>.<span class="cm-property">random</span>.<span class="cm-property">set_seed</span>(<span class="cm-number">10</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-number">4</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">encoderq</span> <span class="cm-operator">=</span> <span class="cm-variable">target</span>(<span class="cm-variable">num_layers</span><span class="cm-operator">=</span><span class="cm-number">2</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                      <span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-variable">embedding_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                      <span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-number">2</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                      <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-number">8</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                      <span class="cm-variable">input_vocab_size</span><span class="cm-operator">=</span><span class="cm-number">32</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                      <span class="cm-variable">maximum_position_encoding</span><span class="cm-operator">=</span><span class="cm-number">5</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">2</span>, <span class="cm-number">1</span>, <span class="cm-number">3</span>], [<span class="cm-number">1</span>, <span class="cm-number">2</span>, <span class="cm-number">0</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">encoderq_output</span> <span class="cm-operator">=</span> <span class="cm-variable">encoderq</span>(<span class="cm-variable">x</span>, <span class="cm-keyword">True</span>, <span class="cm-keyword">None</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">encoderq_output</span>), <span class="cm-string">"Wrong type. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">encoderq_output</span>).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> (<span class="cm-variable">x</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">x</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>], <span class="cm-variable">embedding_dim</span>), <span class="cm-string">f"Wrong shape. We expected (</span>{<span class="cm-variable">eshape</span>[<span class="cm-number">0</span>]}<span class="cm-string">, </span>{<span class="cm-variable">eshape</span>[<span class="cm-number">1</span>]}<span class="cm-string">, </span>{<span class="cm-variable">embedding_dim</span>}<span class="cm-string">)"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">encoderq_output</span>.<span class="cm-property">numpy</span>(), </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [[[<span class="cm-operator">-</span><span class="cm-number">0.40172306</span>,  <span class="cm-number">0.11519244</span>, <span class="cm-operator">-</span><span class="cm-number">1.2322885</span>,   <span class="cm-number">1.5188192</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [ <span class="cm-number">0.4017268</span>,   <span class="cm-number">0.33922842</span>, <span class="cm-operator">-</span><span class="cm-number">1.6836855</span>,   <span class="cm-number">0.9427304</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [ <span class="cm-number">0.4685002</span>,  <span class="cm-operator">-</span><span class="cm-number">1.6252842</span>,   <span class="cm-number">0.09368491</span>,  <span class="cm-number">1.063099</span>  ]],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        [[<span class="cm-operator">-</span><span class="cm-number">0.3489219</span>,   <span class="cm-number">0.31335592</span>, <span class="cm-operator">-</span><span class="cm-number">1.3568854</span>,   <span class="cm-number">1.3924513</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [<span class="cm-operator">-</span><span class="cm-number">0.08761203</span>, <span class="cm-operator">-</span><span class="cm-number">0.1680029</span>,  <span class="cm-operator">-</span><span class="cm-number">1.2742313</span>,   <span class="cm-number">1.5298463</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [ <span class="cm-number">0.2627198</span>,  <span class="cm-operator">-</span><span class="cm-number">1.6140151</span>,   <span class="cm-number">0.2212624</span> ,  <span class="cm-number">1.130033</span>  ]]]), <span class="cm-string">"Wrong values"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">encoderq_output</span> <span class="cm-operator">=</span> <span class="cm-variable">encoderq</span>(<span class="cm-variable">x</span>, <span class="cm-keyword">True</span>, <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[[<span class="cm-number">1</span>], [<span class="cm-number">1</span>], [<span class="cm-number">1</span>]], [[<span class="cm-number">1</span>], [<span class="cm-number">1</span>], [<span class="cm-number">0</span>]]]))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">encoderq_output</span>.<span class="cm-property">numpy</span>(), </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [[[ <span class="cm-number">0.06066498</span>,  <span class="cm-number">0.76212525</span>, <span class="cm-operator">-</span><span class="cm-number">1.6517558</span>,   <span class="cm-number">0.82896566</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                          [ <span class="cm-number">0.2810525</span>,  <span class="cm-operator">-</span><span class="cm-number">0.05622205</span>, <span class="cm-operator">-</span><span class="cm-number">1.5075088</span>,   <span class="cm-number">1.2826782</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                          [ <span class="cm-number">0.50037545</span>, <span class="cm-operator">-</span><span class="cm-number">1.6685743</span>,   <span class="cm-number">0.20784463</span>,  <span class="cm-number">0.96035427</span>]],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [[<span class="cm-operator">-</span><span class="cm-number">0.27214777</span>,  <span class="cm-number">0.8617839</span>,  <span class="cm-operator">-</span><span class="cm-number">1.5214845</span>,   <span class="cm-number">0.9318483</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                          [ <span class="cm-number">0.21778868</span>,  <span class="cm-number">0.02491891</span>, <span class="cm-operator">-</span><span class="cm-number">1.5217986</span>,   <span class="cm-number">1.279091</span>  ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                          [ <span class="cm-number">0.2364921</span>,  <span class="cm-operator">-</span><span class="cm-number">1.5986431</span>,   <span class="cm-number">0.20113775</span>,  <span class="cm-number">1.1610134</span> ]]]), <span class="cm-string">"Wrong values"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">"\033[92mAll tests passed"</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">Encoder_test</span>(<span class="cm-variable">Encoder</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 691px;"></div><div class="CodeMirror-gutters" style="display: none; height: 721px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre><span class="ansi-green-intense-fg">All tests passed
</span></pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell rendered unselected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 524px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'5'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## 5 - Decoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">The Decoder layer takes the K and V matrices generated by the Encoder and in computes the second multi-head attention layer with the Q matrix from the output (Figure 3a).</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"decoder_layer.png"</span> <span class="cm-attribute">alt</span>=<span class="cm-string">"Encoder"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"250"</span><span class="cm-tag cm-bracket">/&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">caption</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">center</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">font</span> <span class="cm-attribute">color</span>=<span class="cm-string">'purple'</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">b</span><span class="cm-tag cm-bracket">&gt;</span>Figure 3a: Transformer Decoder layer<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">font</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">center</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">caption</span><span class="cm-tag cm-bracket cm-error">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'5-1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">### 5.1 - Decoder Layer</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Again, you'll pair multi-head attention with a feed forward neural network, but this time you'll implement two multi-head attention layers. You will also use residual connections and layer normalization to help speed up training (Figure 3a).</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'ex-6'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">### Exercise 6 - DecoderLayer</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Implement `DecoderLayer()` using the `call()` method</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">1. Block 1 is a multi-head attention layer with a residual connection, dropout layer, and look-ahead mask.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">2. Block 2 will take into account the output of the Encoder, so the multi-head attention layer will receive K and V from the encoder, and Q from the Block 1. You will then apply a dropout layer, layer normalization and a residual connection, just like you've done before. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">3. Finally, Block 3 is a feed forward neural network with dropout and normalization layers and a residual connection.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">**Additional Hints:**</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* The first two blocks are fairly similar to the EncoderLayer except you will return `attention_scores` when computing self-attention</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 524px;"></div><div class="CodeMirror-gutters" style="display: none; height: 539px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="5"></a></p>
<h2 id="5---Decoder">5 - Decoder<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#5---Decoder"></a></h2>
<p>The Decoder layer takes the K and V matrices generated by the Encoder and in computes the second multi-head attention layer with the Q matrix from the output (Figure 3a).</p>
<img src="./decoder_layer.png" alt="Encoder" width="250">
<center><font color="purple"><b>Figure 3a: Transformer Decoder layer</b></font></center>

<p><a name="5-1"></a>    </p>
<h3 id="5.1---Decoder-Layer">5.1 - Decoder Layer<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#5.1---Decoder-Layer"></a></h3>
<p>Again, you'll pair multi-head attention with a feed forward neural network, but this time you'll implement two multi-head attention layers. You will also use residual connections and layer normalization to help speed up training (Figure 3a).</p>
<p><a name="ex-6"></a>    </p>
<h3 id="Exercise-6---DecoderLayer">Exercise 6 - DecoderLayer<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Exercise-6---DecoderLayer"></a></h3>
<p>Implement <code>DecoderLayer()</code> using the <code>call()</code> method</p>
<ol>
<li>Block 1 is a multi-head attention layer with a residual connection, dropout layer, and look-ahead mask.</li>
<li>Block 2 will take into account the output of the Encoder, so the multi-head attention layer will receive K and V from the encoder, and Q from the Block 1. You will then apply a dropout layer, layer normalization and a residual connection, just like you've done before. </li>
<li>Finally, Block 3 is a feed forward neural network with dropout and normalization layers and a residual connection.</li>
</ol>
<p><strong>Additional Hints:</strong></p>
<ul>
<li>The first two blocks are fairly similar to the EncoderLayer except you will return <code>attention_scores</code> when computing self-attention</li>
</ul>
</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[202]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 498.594px; left: 189.484px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1364px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1364.2px; margin-bottom: -15px; border-right-width: 15px; min-height: 1422px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like">x</pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"><div class="CodeMirror-selected" style="position: absolute; left: 189.484px; top: 493px; width: 429.906px; height: 17px;"></div></div><div class="CodeMirror-cursors" style=""></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># GRADED FUNCTION DecoderLayer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">class</span> <span class="cm-def">DecoderLayer</span>(<span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">layers</span>.<span class="cm-property">Layer</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    The decoder layer is composed by two multi-head attention blocks, </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    one that takes the new input and uses self-attention, and the other </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    one that combines it with the output of the encoder, followed by a</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    fully connected block. </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">__init__</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">embedding_dim</span>, <span class="cm-variable">num_heads</span>, <span class="cm-variable">fully_connected_dim</span>, <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-number">1e-6</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-builtin">super</span>(<span class="cm-variable">DecoderLayer</span>, <span class="cm-variable-2">self</span>).<span class="cm-property">__init__</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">mha1</span> <span class="cm-operator">=</span> <span class="cm-variable">MultiHeadAttention</span>(<span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-variable">num_heads</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                      <span class="cm-variable">key_dim</span><span class="cm-operator">=</span><span class="cm-variable">embedding_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">mha2</span> <span class="cm-operator">=</span> <span class="cm-variable">MultiHeadAttention</span>(<span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-variable">num_heads</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                      <span class="cm-variable">key_dim</span><span class="cm-operator">=</span><span class="cm-variable">embedding_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">ffn</span> <span class="cm-operator">=</span> <span class="cm-variable">FullyConnected</span>(<span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-variable">embedding_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                  <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-variable">fully_connected_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm1</span> <span class="cm-operator">=</span> <span class="cm-variable">LayerNormalization</span>(<span class="cm-variable">epsilon</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm2</span> <span class="cm-operator">=</span> <span class="cm-variable">LayerNormalization</span>(<span class="cm-variable">epsilon</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm3</span> <span class="cm-operator">=</span> <span class="cm-variable">LayerNormalization</span>(<span class="cm-variable">epsilon</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">dropout1</span> <span class="cm-operator">=</span> <span class="cm-variable">Dropout</span>(<span class="cm-variable">dropout_rate</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">dropout2</span> <span class="cm-operator">=</span> <span class="cm-variable">Dropout</span>(<span class="cm-variable">dropout_rate</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">dropout3</span> <span class="cm-operator">=</span> <span class="cm-variable">Dropout</span>(<span class="cm-variable">dropout_rate</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">call</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">x</span>, <span class="cm-variable">enc_output</span>, <span class="cm-variable">training</span>, <span class="cm-variable">look_ahead_mask</span>, <span class="cm-variable">padding_mask</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Forward pass for the Decoder Layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            training -- Boolean, set to true to activate</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                        the training mode for dropout layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            look_ahead_mask -- Boolean mask for the target_input</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            padding_mask -- Boolean mask for the second multihead attention layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            out3 -- Tensor of shape (batch_size, target_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            attn_weights_block1 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            attn_weights_block2 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># enc_output.shape == (batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># BLOCK 1</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># calculate self-attention and return attention scores as attn_weights_block1 (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">attn1</span>, <span class="cm-variable">attn_weights_block1</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">mha1</span>(<span class="cm-variable">x</span>, <span class="cm-variable">x</span>, <span class="cm-variable">x</span>, <span class="cm-variable">look_ahead_mask</span>, <span class="cm-variable">return_attention_scores</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)  <span class="cm-comment"># (batch_size, target_seq_len, d_model)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply dropout layer on the attention output (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">attn1</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">dropout1</span>(<span class="cm-variable">attn1</span>, <span class="cm-variable">training</span><span class="cm-operator">=</span><span class="cm-variable">training</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply layer normalization to the sum of the attention output and the input (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">out1</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm1</span>(<span class="cm-variable">attn1</span> <span class="cm-operator">+</span> <span class="cm-variable">x</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># BLOCK 2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># calculate self-attention using the Q from the first block and K and V from the encoder output.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># Return attention scores as attn_weights_block2 (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">attn2</span>, <span class="cm-variable">attn_weights_block2</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">mha2</span>(<span class="cm-variable">out1</span>, <span class="cm-variable">enc_output</span>, <span class="cm-variable">enc_output</span>, <span class="cm-variable">padding_mask</span>, <span class="cm-variable">return_attention_scores</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)  <span class="cm-comment"># (batch_size, target_seq_len, d_model)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply dropout layer on the attention output (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">attn2</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">dropout2</span>(<span class="cm-variable">attn2</span>, <span class="cm-variable">training</span><span class="cm-operator">=</span><span class="cm-variable">training</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply layer normalization to the sum of the attention output and the output of the first block (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">out2</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm2</span>(<span class="cm-variable">attn2</span> <span class="cm-operator">+</span> <span class="cm-variable">out1</span>)  <span class="cm-comment"># (batch_size, target_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment">#BLOCK 3</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># pass the output of the second block through a ffn</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">ffn_output</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">ffn</span>(<span class="cm-variable">out2</span>) <span class="cm-comment"># (batch_size, target_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply a dropout layer to the ffn output</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">ffn_output</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">dropout3</span>(<span class="cm-variable">ffn_output</span>, <span class="cm-variable">training</span><span class="cm-operator">=</span><span class="cm-variable">training</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply layer normalization to the sum of the ffn output and the output of the second block</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">out3</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">layernorm3</span>(<span class="cm-variable">ffn_output</span> <span class="cm-operator">+</span> <span class="cm-variable">out2</span>) <span class="cm-comment"># (batch_size, target_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># END CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-keyword">return</span> <span class="cm-variable">out3</span>, <span class="cm-variable">attn_weights_block1</span>, <span class="cm-variable">attn_weights_block2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 1422px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1452px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[203]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1609px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1608.59px; margin-bottom: -15px; border-right-width: 15px; min-height: 827px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNIT TEST</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">DecoderLayer_test</span>(<span class="cm-variable">target</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-number">8</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">tf</span>.<span class="cm-property">random</span>.<span class="cm-property">set_seed</span>(<span class="cm-number">10</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">decoderLayerq</span> <span class="cm-operator">=</span> <span class="cm-variable">target</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-number">4</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-variable">num_heads</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-number">32</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-number">1e-6</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">encoderq_output</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>([[[<span class="cm-operator">-</span><span class="cm-number">0.40172306</span>,  <span class="cm-number">0.11519244</span>, <span class="cm-operator">-</span><span class="cm-number">1.2322885</span>,   <span class="cm-number">1.5188192</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                   [ <span class="cm-number">0.4017268</span>,   <span class="cm-number">0.33922842</span>, <span class="cm-operator">-</span><span class="cm-number">1.6836855</span>,   <span class="cm-number">0.9427304</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                   [ <span class="cm-number">0.4685002</span>,  <span class="cm-operator">-</span><span class="cm-number">1.6252842</span>,   <span class="cm-number">0.09368491</span>,  <span class="cm-number">1.063099</span>  ]]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">q</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[[<span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>], [<span class="cm-number">0</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>], [<span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>]]]).<span class="cm-property">astype</span>(<span class="cm-variable">np</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">look_ahead_mask</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>([[<span class="cm-number">1.</span>, <span class="cm-number">0.</span>, <span class="cm-number">0.</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [<span class="cm-number">1.</span>, <span class="cm-number">1.</span>, <span class="cm-number">0.</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [<span class="cm-number">1.</span>, <span class="cm-number">1.</span>, <span class="cm-number">1.</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">padding_mask</span> <span class="cm-operator">=</span> <span class="cm-keyword">None</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">out</span>, <span class="cm-variable">attn_w_b1</span>, <span class="cm-variable">attn_w_b2</span> <span class="cm-operator">=</span> <span class="cm-variable">decoderLayerq</span>(<span class="cm-variable">q</span>, <span class="cm-variable">encoderq_output</span>, <span class="cm-keyword">True</span>, <span class="cm-variable">look_ahead_mask</span>, <span class="cm-variable">padding_mask</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">attn_w_b1</span>), <span class="cm-string">"Wrong type for attn_w_b1. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">attn_w_b2</span>), <span class="cm-string">"Wrong type for attn_w_b2. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">out</span>), <span class="cm-string">"Wrong type for out. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">shape1</span> <span class="cm-operator">=</span> (<span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">num_heads</span>, <span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>], <span class="cm-variable">q</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">attn_w_b1</span>).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> <span class="cm-variable">shape1</span>, <span class="cm-string">f"Wrong shape. We expected </span>{<span class="cm-variable">shape1</span>}<span class="cm-string">"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">attn_w_b2</span>).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> <span class="cm-variable">shape1</span>, <span class="cm-string">f"Wrong shape. We expected </span>{<span class="cm-variable">shape1</span>}<span class="cm-string">"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">out</span>).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> <span class="cm-variable">q</span>.<span class="cm-property">shape</span>, <span class="cm-string">f"Wrong shape. We expected </span>{<span class="cm-variable">q</span>.<span class="cm-property">shape</span>}<span class="cm-string">"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">attn_w_b1</span>[<span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>], [<span class="cm-number">0.5271505</span>,  <span class="cm-number">0.47284946</span>, <span class="cm-number">0.</span>], <span class="cm-variable">atol</span><span class="cm-operator">=</span><span class="cm-number">1e-2</span>), <span class="cm-string">"Wrong values in attn_w_b1. Check the call to self.mha1"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">attn_w_b2</span>[<span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>], [<span class="cm-number">0.33365652</span>, <span class="cm-number">0.32598493</span>, <span class="cm-number">0.34035856</span>]),  <span class="cm-string">"Wrong values in attn_w_b2. Check the call to self.mha2"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">out</span>[<span class="cm-number">0</span>, <span class="cm-number">0</span>], [<span class="cm-number">0.04726627</span>, <span class="cm-operator">-</span><span class="cm-number">1.6235218</span>, <span class="cm-number">1.0327158</span>, <span class="cm-number">0.54353976</span>]), <span class="cm-string">"Wrong values in out"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># Now let's try a example with padding mask</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">padding_mask</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">out</span>, <span class="cm-variable">attn_w_b1</span>, <span class="cm-variable">attn_w_b2</span> <span class="cm-operator">=</span> <span class="cm-variable">decoderLayerq</span>(<span class="cm-variable">q</span>, <span class="cm-variable">encoderq_output</span>, <span class="cm-keyword">True</span>, <span class="cm-variable">look_ahead_mask</span>, <span class="cm-variable">padding_mask</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">out</span>[<span class="cm-number">0</span>, <span class="cm-number">0</span>], [<span class="cm-number">0.17891586</span>, <span class="cm-operator">-</span><span class="cm-number">1.6581949</span>, <span class="cm-number">0.9888787</span>, <span class="cm-number">0.49040037</span>]), <span class="cm-string">"Wrong values in out when we mask the last word. Are you passing the padding_mask to the inner functions?"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">"\033[92mAll tests passed"</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">DecoderLayer_test</span>(<span class="cm-variable">DecoderLayer</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 827px;"></div><div class="CodeMirror-gutters" style="display: none; height: 857px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre><span class="ansi-green-intense-fg">All tests passed
</span></pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell rendered unselected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 437px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'5-2'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### 5.2 - Full Decoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">You're almost there! Time to use your Decoder layer to build a full Transformer Decoder (Figure 3b). You will embedd your output and add positional encodings. You will then feed your encoded embeddings to a stack of Decoder layers. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"decoder.png"</span> <span class="cm-attribute">alt</span>=<span class="cm-string">"Encoder"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"300"</span><span class="cm-tag cm-bracket">/&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">caption</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">center</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">font</span> <span class="cm-attribute">color</span>=<span class="cm-string">'purple'</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">b</span><span class="cm-tag cm-bracket">&gt;</span>Figure 3b: Transformer Decoder<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">font</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">center</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">caption</span><span class="cm-tag cm-bracket cm-error">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'ex-7'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span> &nbsp; &nbsp; </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">### Exercise 7 - Decoder</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Implement `Decoder()` using the `call()` method to embed your output, add positional encoding, and implement multiple decoder layers</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">In this exercise, you will initialize your Decoder with an Embedding layer, positional encoding, and multiple DecoderLayers. Your `call()` method will perform the following steps: </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">1. Pass your generated output through the Embedding layer.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">2. Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type `tf.float32` before computing the square root.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">3. Add the position encoding: self.pos_encoding `[:, :seq_len, :]` to your embedding.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">4. Pass the encoded embedding through a dropout layer, remembering to use the `training` parameter to set the model training mode. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">5. Pass the output of the dropout layer through the stack of Decoding layers using a for loop.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 437px;"></div><div class="CodeMirror-gutters" style="display: none; height: 452px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="5-2"></a> </p>
<h3 id="5.2---Full-Decoder">5.2 - Full Decoder<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#5.2---Full-Decoder"></a></h3>
<p>You're almost there! Time to use your Decoder layer to build a full Transformer Decoder (Figure 3b). You will embedd your output and add positional encodings. You will then feed your encoded embeddings to a stack of Decoder layers. </p>
<img src="./decoder.png" alt="Encoder" width="300">
<center><font color="purple"><b>Figure 3b: Transformer Decoder</b></font></center>

<p><a name="ex-7"></a>     </p>
<h3 id="Exercise-7---Decoder">Exercise 7 - Decoder<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Exercise-7---Decoder"></a></h3>
<p>Implement <code>Decoder()</code> using the <code>call()</code> method to embed your output, add positional encoding, and implement multiple decoder layers</p>
<p>In this exercise, you will initialize your Decoder with an Embedding layer, positional encoding, and multiple DecoderLayers. Your <code>call()</code> method will perform the following steps: </p>
<ol>
<li>Pass your generated output through the Embedding layer.</li>
<li>Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type <code>tf.float32</code> before computing the square root.</li>
<li>Add the position encoding: self.pos_encoding <code>[:, :seq_len, :]</code> to your embedding.</li>
<li>Pass the encoded embedding through a dropout layer, remembering to use the <code>training</code> parameter to set the model training mode. </li>
<li>Pass the output of the dropout layer through the stack of Decoding layers using a for loop.</li>
</ol>
</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[208]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 685.594px; left: 282.156px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 985px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 984.734px; margin-bottom: -15px; border-right-width: 15px; min-height: 1269px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors" style=""><div class="CodeMirror-cursor" style="left: 282.156px; top: 680px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># GRADED FUNCTION Decoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">class</span> <span class="cm-def">Decoder</span>(<span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">layers</span>.<span class="cm-property">Layer</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    The entire Encoder is starts by passing the target input to an embedding layer </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    and using positional encoding to then pass the output through a stack of</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    decoder Layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">__init__</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">num_layers</span>, <span class="cm-variable">embedding_dim</span>, <span class="cm-variable">num_heads</span>, <span class="cm-variable">fully_connected_dim</span>, <span class="cm-variable">target_vocab_size</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">               <span class="cm-variable">maximum_position_encoding</span>, <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-number">1e-6</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-builtin">super</span>(<span class="cm-variable">Decoder</span>, <span class="cm-variable-2">self</span>).<span class="cm-property">__init__</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span> <span class="cm-operator">=</span> <span class="cm-variable">embedding_dim</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">num_layers</span> <span class="cm-operator">=</span> <span class="cm-variable">num_layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">embedding</span> <span class="cm-operator">=</span> <span class="cm-variable">Embedding</span>(<span class="cm-variable">target_vocab_size</span>, <span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">pos_encoding</span> <span class="cm-operator">=</span> <span class="cm-variable">positional_encoding</span>(<span class="cm-variable">maximum_position_encoding</span>, <span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">dec_layers</span> <span class="cm-operator">=</span> [<span class="cm-variable">DecoderLayer</span>(<span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                        <span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-variable">num_heads</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                        <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-variable">fully_connected_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                        <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-variable">dropout_rate</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                                        <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>) </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                           <span class="cm-keyword">for</span> <span class="cm-variable">_</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-variable-2">self</span>.<span class="cm-property">num_layers</span>)]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">dropout</span> <span class="cm-operator">=</span> <span class="cm-variable">Dropout</span>(<span class="cm-variable">dropout_rate</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">call</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">x</span>, <span class="cm-variable">enc_output</span>, <span class="cm-variable">training</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">           <span class="cm-variable">look_ahead_mask</span>, <span class="cm-variable">padding_mask</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Forward  pass for the Decoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            training -- Boolean, set to true to activate</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                        the training mode for dropout layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            look_ahead_mask -- Boolean mask for the target_input</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            padding_mask -- Boolean mask for the second multihead attention layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            x -- Tensor of shape </span><span class="cm-string CodeMirror-matchingbracket">(</span><span class="cm-string">batch_size, target_seq_len, embedding_dim</span><span class="cm-string CodeMirror-matchingbracket">)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            attention_weights - Dictionary of tensors containing all the attention weights</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">seq_len</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">x</span>)[<span class="cm-number">1</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">attention_weights</span> <span class="cm-operator">=</span> {}</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># create word embeddings </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">embedding</span>(<span class="cm-variable">x</span>)  <span class="cm-comment"># (batch_size, target_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># scale embeddings by multiplying by the square root of their dimension</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">x</span> <span class="cm-operator">*=</span> <span class="cm-variable">tf</span>.<span class="cm-property">math</span>.<span class="cm-property">sqrt</span>( <span class="cm-variable">tf</span>.<span class="cm-property">cast</span>(<span class="cm-variable-2">self</span>.<span class="cm-property">embedding_dim</span>, <span class="cm-variable">dtype</span><span class="cm-operator">=</span><span class="cm-variable">tf</span>.<span class="cm-property">float32</span>) )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># calculate positional encodings and add to word embedding</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">x</span> <span class="cm-operator">+=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">pos_encoding</span>[:, :<span class="cm-variable">seq_len</span>, :]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># apply a dropout layer to x</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">dropout</span>(<span class="cm-variable">x</span>, <span class="cm-variable">training</span><span class="cm-operator">=</span><span class="cm-variable">training</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># use a for loop to pass x through a stack of decoder layers and update attention_weights (~4 lines total)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-variable-2">self</span>.<span class="cm-property">num_layers</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">            <span class="cm-comment"># pass x and the encoder output through a stack of decoder layers and save the attention weights</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">            <span class="cm-comment"># of block 1 and 2 (~1 line)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">            <span class="cm-variable">x</span>, <span class="cm-variable">block1</span>, <span class="cm-variable">block2</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">dec_layers</span>[<span class="cm-variable">i</span>](<span class="cm-variable">x</span>, <span class="cm-variable">enc_output</span>, <span class="cm-variable">training</span>, <span class="cm-variable">look_ahead_mask</span>, <span class="cm-variable">padding_mask</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">            <span class="cm-comment">#update attention_weights dictionary with the attention weights of block 1 and block 2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">            <span class="cm-variable">attention_weights</span>[<span class="cm-string">'decoder_layer{}_block1_self_att'</span>.<span class="cm-property">format</span>(<span class="cm-variable">i</span><span class="cm-operator">+</span><span class="cm-number">1</span>)] <span class="cm-operator">=</span> <span class="cm-variable">block1</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">            <span class="cm-variable">attention_weights</span>[<span class="cm-string">'decoder_layer{}_block2_decenc_att'</span>.<span class="cm-property">format</span>(<span class="cm-variable">i</span><span class="cm-operator">+</span><span class="cm-number">1</span>)] <span class="cm-operator">=</span> <span class="cm-variable">block2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># END CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># x.shape == (batch_size, target_seq_len, embedding_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-keyword">return</span> <span class="cm-variable">x</span>, <span class="cm-variable">attention_weights</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 1269px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1299px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[209]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1069px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1069.22px; margin-bottom: -15px; border-right-width: 15px; min-height: 861px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNIT TEST</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">Decoder_test</span>(<span class="cm-variable">target</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">tf</span>.<span class="cm-property">random</span>.<span class="cm-property">set_seed</span>(<span class="cm-number">10</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">num_layers</span><span class="cm-operator">=</span><span class="cm-number">7</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-number">4</span> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-number">3</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-number">8</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">target_vocab_size</span><span class="cm-operator">=</span><span class="cm-number">33</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">maximum_position_encoding</span><span class="cm-operator">=</span><span class="cm-number">6</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">x</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">3</span>, <span class="cm-number">2</span>, <span class="cm-number">1</span>], [<span class="cm-number">2</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">encoderq_output</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>([[[<span class="cm-operator">-</span><span class="cm-number">0.40172306</span>,  <span class="cm-number">0.11519244</span>, <span class="cm-operator">-</span><span class="cm-number">1.2322885</span>,   <span class="cm-number">1.5188192</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [ <span class="cm-number">0.4017268</span>,   <span class="cm-number">0.33922842</span>, <span class="cm-operator">-</span><span class="cm-number">1.6836855</span>,   <span class="cm-number">0.9427304</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [ <span class="cm-number">0.4685002</span>,  <span class="cm-operator">-</span><span class="cm-number">1.6252842</span>,   <span class="cm-number">0.09368491</span>,  <span class="cm-number">1.063099</span>  ]],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        [[<span class="cm-operator">-</span><span class="cm-number">0.3489219</span>,   <span class="cm-number">0.31335592</span>, <span class="cm-operator">-</span><span class="cm-number">1.3568854</span>,   <span class="cm-number">1.3924513</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [<span class="cm-operator">-</span><span class="cm-number">0.08761203</span>, <span class="cm-operator">-</span><span class="cm-number">0.1680029</span>,  <span class="cm-operator">-</span><span class="cm-number">1.2742313</span>,   <span class="cm-number">1.5298463</span> ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                         [ <span class="cm-number">0.2627198</span>,  <span class="cm-operator">-</span><span class="cm-number">1.6140151</span>,   <span class="cm-number">0.2212624</span> ,  <span class="cm-number">1.130033</span>  ]]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">look_ahead_mask</span> <span class="cm-operator">=</span> <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>([[<span class="cm-number">1.</span>, <span class="cm-number">0.</span>, <span class="cm-number">0.</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [<span class="cm-number">1.</span>, <span class="cm-number">1.</span>, <span class="cm-number">0.</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [<span class="cm-number">1.</span>, <span class="cm-number">1.</span>, <span class="cm-number">1.</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">decoderk</span> <span class="cm-operator">=</span> <span class="cm-variable">Decoder</span>(<span class="cm-variable">num_layers</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                    <span class="cm-variable">embedding_dim</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                    <span class="cm-variable">num_heads</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                    <span class="cm-variable">fully_connected_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                    <span class="cm-variable">target_vocab_size</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                    <span class="cm-variable">maximum_position_encoding</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">outd</span>, <span class="cm-variable">att_weights</span> <span class="cm-operator">=</span> <span class="cm-variable">decoderk</span>(<span class="cm-variable">x</span>, <span class="cm-variable">encoderq_output</span>, <span class="cm-keyword">False</span>, <span class="cm-variable">look_ahead_mask</span>, <span class="cm-keyword">None</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">outd</span>), <span class="cm-string">"Wrong type for outd. It must be a dict"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">outd</span>), <span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">encoderq_output</span>)), <span class="cm-string">f"Wrong shape. We expected </span>{ <span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">encoderq_output</span>)}<span class="cm-string">"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-variable">outd</span>[<span class="cm-number">1</span>, <span class="cm-number">1</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">outd</span>[<span class="cm-number">1</span>, <span class="cm-number">1</span>], [<span class="cm-operator">-</span><span class="cm-number">0.2715261</span>, <span class="cm-operator">-</span><span class="cm-number">0.5606001</span>, <span class="cm-operator">-</span><span class="cm-number">0.861783</span>, <span class="cm-number">1.69390933</span>]), <span class="cm-string">"Wrong values in outd"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">keys</span> <span class="cm-operator">=</span> <span class="cm-builtin">list</span>(<span class="cm-variable">att_weights</span>.<span class="cm-property">keys</span>())</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">type</span>(<span class="cm-variable">att_weights</span>) <span class="cm-operator">==</span> <span class="cm-builtin">dict</span>, <span class="cm-string">"Wrong type for att_weights[0]. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">len</span>(<span class="cm-variable">keys</span>) <span class="cm-operator">==</span> <span class="cm-number">2</span> <span class="cm-operator">*</span> <span class="cm-variable">num_layers</span>, <span class="cm-string">f"Wrong length for attention weights. It must be 2 x num_layers = </span>{<span class="cm-number">2</span><span class="cm-operator">*</span><span class="cm-variable">num_layers</span>}<span class="cm-string">"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">att_weights</span>[<span class="cm-variable">keys</span>[<span class="cm-number">0</span>]]), <span class="cm-string">f"Wrong type for att_weights[</span>{<span class="cm-variable">keys</span>[<span class="cm-number">0</span>]}<span class="cm-string">]. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">shape1</span> <span class="cm-operator">=</span> (<span class="cm-variable">x</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">num_heads</span>, <span class="cm-variable">x</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>], <span class="cm-variable">x</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">att_weights</span>[<span class="cm-variable">keys</span>[<span class="cm-number">1</span>]]).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> <span class="cm-variable">shape1</span>, <span class="cm-string">f"Wrong shape. We expected </span>{<span class="cm-variable">shape1</span>}<span class="cm-string">"</span> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">att_weights</span>[<span class="cm-variable">keys</span>[<span class="cm-number">0</span>]][<span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>], [<span class="cm-number">0.52145624</span>, <span class="cm-number">0.47854376</span>, <span class="cm-number">0.</span>]), <span class="cm-string">f"Wrong values in att_weights[</span>{<span class="cm-variable">keys</span>[<span class="cm-number">0</span>]}<span class="cm-string">]"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">"\033[92mAll tests passed"</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">Decoder_test</span>(<span class="cm-variable">Decoder</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 861px;"></div><div class="CodeMirror-gutters" style="display: none; height: 891px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>tf.Tensor([-0.2715261 -0.5606001 -0.861783   1.6939093], shape=(4,), dtype=float32)
<span class="ansi-green-intense-fg">All tests passed
</span></pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell rendered unselected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 507px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'6'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## 6 - Transformer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Phew! This has been quite the assignment, and now you've made it to your last exercise of the Deep Learning Specialization. Congratulations! You've done all the hard work, now it's time to put it all together.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line">&nbsp;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"transformer.png"</span> <span class="cm-attribute">alt</span>=<span class="cm-string">"Transformer"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"550"</span><span class="cm-tag cm-bracket">/&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">caption</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">center</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">font</span> <span class="cm-attribute">color</span>=<span class="cm-string">'purple'</span><span class="cm-tag cm-bracket">&gt;&lt;</span><span class="cm-tag">b</span><span class="cm-tag cm-bracket">&gt;</span>Figure 4: Transformer<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">font</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">center</span><span class="cm-tag cm-bracket cm-error">&gt;</span><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag cm-error">caption</span><span class="cm-tag cm-bracket cm-error">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">The flow of data through the Transformer Architecture is as follows:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* First your input passes through an Encoder, which is just repeated Encoder layers that you implemented:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  - embedding and positional encoding of your input</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  - multi-head attention on your input</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  - feed forward neural network to help detect features</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* Then the predicted output passes through a Decoder, consisting of the decoder layers that you implemented:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  - embedding and positional encoding of the output</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  - multi-head attention on your generated output</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  - multi-head attention with the Q from the first multi-head attention layer and the K and V from the Encoder</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  - a feed forward neural network to help detect features</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">* Finally, after the Nth Decoder layer, two dense layers and a softmax are applied to generate prediction for the next output in your sequence.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'ex-8'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">### Exercise 8 - Transformer</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Implement `Transformer()` using the `call()` method</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">1. Pass the input through the Encoder with the appropiate mask.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">2. Pass the encoder output and the target through the Decoder with the appropiate mask.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">3. Apply a linear transformation and a softmax to get a prediction.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 507px;"></div><div class="CodeMirror-gutters" style="display: none; height: 522px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a name="6"></a> </p>
<h2 id="6---Transformer">6 - Transformer<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#6---Transformer"></a></h2>
<p>Phew! This has been quite the assignment, and now you've made it to your last exercise of the Deep Learning Specialization. Congratulations! You've done all the hard work, now it's time to put it all together.  </p>
<img src="./transformer.png" alt="Transformer" width="550">
<center><font color="purple"><b>Figure 4: Transformer</b></font></center>

<p>The flow of data through the Transformer Architecture is as follows:</p>
<ul>
<li>First your input passes through an Encoder, which is just repeated Encoder layers that you implemented:<ul>
<li>embedding and positional encoding of your input</li>
<li>multi-head attention on your input</li>
<li>feed forward neural network to help detect features</li>
</ul>
</li>
<li>Then the predicted output passes through a Decoder, consisting of the decoder layers that you implemented:<ul>
<li>embedding and positional encoding of the output</li>
<li>multi-head attention on your generated output</li>
<li>multi-head attention with the Q from the first multi-head attention layer and the K and V from the Encoder</li>
<li>a feed forward neural network to help detect features</li>
</ul>
</li>
<li>Finally, after the Nth Decoder layer, two dense layers and a softmax are applied to generate prediction for the next output in your sequence.</li>
</ul>
<p><a name="ex-8"></a> </p>
<h3 id="Exercise-8---Transformer">Exercise 8 - Transformer<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Exercise-8---Transformer"></a></h3>
<p>Implement <code>Transformer()</code> using the <code>call()</code> method</p>
<ol>
<li>Pass the input through the Encoder with the appropiate mask.</li>
<li>Pass the encoder output and the target through the Decoder with the appropiate mask.</li>
<li>Apply a linear transformation and a softmax to get a prediction.</li>
</ol>
</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[214]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 855.594px; left: 96.7188px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1069px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1" draggable="false"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1069.12px; margin-bottom: -15px; border-right-width: 15px; min-height: 1099px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors" style=""><div class="CodeMirror-cursor" style="left: 96.7188px; top: 850px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># GRADED FUNCTION Transformer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">class</span> <span class="cm-def">Transformer</span>(<span class="cm-variable">tf</span>.<span class="cm-property">keras</span>.<span class="cm-property">Model</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    Complete transformer with an Encoder and a Decoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">__init__</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">num_layers</span>, <span class="cm-variable">embedding_dim</span>, <span class="cm-variable">num_heads</span>, <span class="cm-variable">fully_connected_dim</span>, <span class="cm-variable">input_vocab_size</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">               <span class="cm-variable">target_vocab_size</span>, <span class="cm-variable">max_positional_encoding_input</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">               <span class="cm-variable">max_positional_encoding_target</span>, <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-number">1e-6</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-builtin">super</span>(<span class="cm-variable">Transformer</span>, <span class="cm-variable-2">self</span>).<span class="cm-property">__init__</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">encoder</span> <span class="cm-operator">=</span> <span class="cm-variable">Encoder</span>(<span class="cm-variable">num_layers</span><span class="cm-operator">=</span><span class="cm-variable">num_layers</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-variable">embedding_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-variable">num_heads</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-variable">fully_connected_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">input_vocab_size</span><span class="cm-operator">=</span><span class="cm-variable">input_vocab_size</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">maximum_position_encoding</span><span class="cm-operator">=</span><span class="cm-variable">max_positional_encoding_input</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-variable">dropout_rate</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">decoder</span> <span class="cm-operator">=</span> <span class="cm-variable">Decoder</span>(<span class="cm-variable">num_layers</span><span class="cm-operator">=</span><span class="cm-variable">num_layers</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">embedding_dim</span><span class="cm-operator">=</span><span class="cm-variable">embedding_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">num_heads</span><span class="cm-operator">=</span><span class="cm-variable">num_heads</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">fully_connected_dim</span><span class="cm-operator">=</span><span class="cm-variable">fully_connected_dim</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">target_vocab_size</span><span class="cm-operator">=</span><span class="cm-variable">target_vocab_size</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">maximum_position_encoding</span><span class="cm-operator">=</span><span class="cm-variable">max_positional_encoding_target</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">dropout_rate</span><span class="cm-operator">=</span><span class="cm-variable">dropout_rate</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                               <span class="cm-variable">layernorm_eps</span><span class="cm-operator">=</span><span class="cm-variable">layernorm_eps</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable-2">self</span>.<span class="cm-property">final_layer</span> <span class="cm-operator">=</span> <span class="cm-variable">Dense</span>(<span class="cm-variable">target_vocab_size</span>, <span class="cm-variable">activation</span><span class="cm-operator">=</span><span class="cm-string">'softmax'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">def</span> <span class="cm-def">call</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">input_sentence</span>, <span class="cm-variable">output_sentence</span>, <span class="cm-variable">training</span>, <span class="cm-variable">enc_padding_mask</span>, <span class="cm-variable">look_ahead_mask</span>, <span class="cm-variable">dec_padding_mask</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Forward pass for the entire Transformer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Arguments:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            input_sentence -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                              An array of the indexes of the words in the input sentence</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            output_sentence -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                              An array of the indexes of the words in the output sentence</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            training -- Boolean, set to true to activate</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                        the training mode for dropout layers</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            enc_padding_mask -- Boolean mask to ensure that the padding is not </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                    treated as part of the input</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            look_ahead_mask -- Boolean mask for the target_input</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            padding_mask -- Boolean mask for the second multihead attention layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        Returns:</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            final_output -- Describe me</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">            attention_weights - Dictionary of tensors containing all the attention weights for the decoder</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-string">        """</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># call self.encoder with the appropriate arguments to get the encoder output</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">enc_output</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">encoder</span>(<span class="cm-variable">input_sentence</span>, <span class="cm-variable">training</span>, <span class="cm-variable">enc_padding_mask</span>) <span class="cm-comment"># (batch_size, inp_seq_len, fully_connected_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># call self.decoder with the appropriate arguments to get the decoder output</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">dec_output</span>, <span class="cm-variable">attention_weights</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">decoder</span>(<span class="cm-variable">output_sentence</span>, <span class="cm-variable">enc_output</span>, <span class="cm-variable">training</span>, <span class="cm-variable">look_ahead_mask</span>, <span class="cm-variable">dec_padding_mask</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># pass decoder output through a linear layer and softmax (~2 lines)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">final_output</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">final_layer</span>(<span class="cm-variable">dec_output</span>)  <span class="cm-comment"># (batch_size, tar_seq_len, target_vocab_size)</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-comment"># START CODE HERE</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-keyword">return</span> <span class="cm-variable">final_output</span>, <span class="cm-variable">attention_weights</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 1099px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1129px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell code_cell rendered unselected" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[215]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1052px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1052.36px; margin-bottom: -15px; border-right-width: 15px; min-height: 1150px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># UNIT TEST</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">Transformer_test</span>(<span class="cm-variable">target</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">tf</span>.<span class="cm-property">random</span>.<span class="cm-property">set_seed</span>(<span class="cm-number">10</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">num_layers</span> <span class="cm-operator">=</span> <span class="cm-number">6</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">embedding_dim</span> <span class="cm-operator">=</span> <span class="cm-number">4</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">num_heads</span> <span class="cm-operator">=</span> <span class="cm-number">4</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">fully_connected_dim</span> <span class="cm-operator">=</span> <span class="cm-number">8</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">input_vocab_size</span> <span class="cm-operator">=</span> <span class="cm-number">30</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">target_vocab_size</span> <span class="cm-operator">=</span> <span class="cm-number">35</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">max_positional_encoding_input</span> <span class="cm-operator">=</span> <span class="cm-number">5</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">max_positional_encoding_target</span> <span class="cm-operator">=</span> <span class="cm-number">6</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">trans</span> <span class="cm-operator">=</span> <span class="cm-variable">Transformer</span>(<span class="cm-variable">num_layers</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        <span class="cm-variable">embedding_dim</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        <span class="cm-variable">num_heads</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        <span class="cm-variable">fully_connected_dim</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        <span class="cm-variable">input_vocab_size</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        <span class="cm-variable">target_vocab_size</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        <span class="cm-variable">max_positional_encoding_input</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        <span class="cm-variable">max_positional_encoding_target</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-comment"># 0 is the padding value</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">sentence_lang_a</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">2</span>, <span class="cm-number">1</span>, <span class="cm-number">4</span>, <span class="cm-number">3</span>, <span class="cm-number">0</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">sentence_lang_b</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">3</span>, <span class="cm-number">2</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">0</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">enc_padding_mask</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">dec_padding_mask</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([[<span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">1</span>, <span class="cm-number">0</span>, <span class="cm-number">0</span>]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">look_ahead_mask</span> <span class="cm-operator">=</span> <span class="cm-variable">create_look_ahead_mask</span>(<span class="cm-variable">sentence_lang_a</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">translation</span>, <span class="cm-variable">weights</span> <span class="cm-operator">=</span> <span class="cm-variable">trans</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">sentence_lang_a</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">sentence_lang_b</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-keyword">True</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">enc_padding_mask</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">look_ahead_mask</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        <span class="cm-variable">dec_padding_mask</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">translation</span>), <span class="cm-string">"Wrong type for translation. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">shape1</span> <span class="cm-operator">=</span> (<span class="cm-variable">sentence_lang_a</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">max_positional_encoding_input</span>, <span class="cm-variable">target_vocab_size</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">translation</span>).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> <span class="cm-variable">shape1</span>, <span class="cm-string">f"Wrong shape. We expected </span>{<span class="cm-variable">shape1</span>}<span class="cm-string">"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">        </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-variable">translation</span>[<span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">0</span>:<span class="cm-number">8</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">translation</span>[<span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">0</span>:<span class="cm-number">8</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                       [<span class="cm-number">0.02586828</span>, <span class="cm-number">0.01676807</span>, <span class="cm-number">0.0179477</span>,  <span class="cm-number">0.03098963</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">                        <span class="cm-number">0.0493824</span>,  <span class="cm-number">0.01899733</span>, <span class="cm-number">0.01486511</span>, <span class="cm-number">0.03177376</span>]), <span class="cm-string">"Wrong values in outd"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">keys</span> <span class="cm-operator">=</span> <span class="cm-builtin">list</span>(<span class="cm-variable">weights</span>.<span class="cm-property">keys</span>())</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">type</span>(<span class="cm-variable">weights</span>) <span class="cm-operator">==</span> <span class="cm-builtin">dict</span>, <span class="cm-string">"Wrong type for weights. It must be a dict"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">len</span>(<span class="cm-variable">keys</span>) <span class="cm-operator">==</span> <span class="cm-number">2</span> <span class="cm-operator">*</span> <span class="cm-variable">num_layers</span>, <span class="cm-string">f"Wrong length for attention weights. It must be 2 x num_layers = </span>{<span class="cm-number">2</span><span class="cm-operator">*</span><span class="cm-variable">num_layers</span>}<span class="cm-string">"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">tf</span>.<span class="cm-property">is_tensor</span>(<span class="cm-variable">weights</span>[<span class="cm-variable">keys</span>[<span class="cm-number">0</span>]]), <span class="cm-string">f"Wrong type for att_weights[</span>{<span class="cm-variable">keys</span>[<span class="cm-number">0</span>]}<span class="cm-string">]. Output must be a tensor"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-variable">shape1</span> <span class="cm-operator">=</span> (<span class="cm-variable">sentence_lang_a</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">num_heads</span>, <span class="cm-variable">sentence_lang_a</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>], <span class="cm-variable">sentence_lang_a</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-builtin">tuple</span>(<span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">weights</span>[<span class="cm-variable">keys</span>[<span class="cm-number">1</span>]]).<span class="cm-property">numpy</span>()) <span class="cm-operator">==</span> <span class="cm-variable">shape1</span>, <span class="cm-string">f"Wrong shape. We expected </span>{<span class="cm-variable">shape1</span>}<span class="cm-string">"</span> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-keyword">assert</span> <span class="cm-variable">np</span>.<span class="cm-property">allclose</span>(<span class="cm-variable">weights</span>[<span class="cm-variable">keys</span>[<span class="cm-number">0</span>]][<span class="cm-number">0</span>, <span class="cm-number">0</span>, <span class="cm-number">1</span>], [<span class="cm-number">0.4992985</span>, <span class="cm-number">0.5007015</span>, <span class="cm-number">0.</span>, <span class="cm-number">0.</span>, <span class="cm-number">0.</span>]), <span class="cm-string">f"Wrong values in weights[</span>{<span class="cm-variable">keys</span>[<span class="cm-number">0</span>]}<span class="cm-string">]"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-variable">translation</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">"\033[92mAll tests passed"</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">Transformer_test</span>(<span class="cm-variable">Transformer</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 1150px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1180px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide"></div><div class="output"><div class="output_area"><div class="run_this_cell"></div><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>tf.Tensor(
[0.02586828 0.01676807 0.0179477  0.03098963 0.0493824  0.01899733
 0.01486511 0.03177376], shape=(8,), dtype=float32)
tf.Tensor(
[[[0.02586828 0.01676807 0.0179477  0.03098963 0.0493824  0.01899733
   0.01486511 0.03177376 0.03243609 0.02338723 0.02092016 0.01713314
   0.05744648 0.03582673 0.0154452  0.02603196 0.02624245 0.01647334
   0.02294341 0.02181753 0.03743191 0.05357634 0.03481594 0.03577657
   0.04215186 0.02031728 0.01368301 0.02017247 0.02384152 0.01970596
   0.06035862 0.02273986 0.03377706 0.03638371 0.02257188]
  [0.02393227 0.014579   0.01949223 0.03498874 0.05414951 0.01835898
   0.01537037 0.03034705 0.03999431 0.02241655 0.02109957 0.01442902
   0.05772994 0.04052659 0.01712424 0.0236183  0.02788414 0.01693854
   0.02192983 0.02085504 0.03675031 0.0468783  0.03662626 0.0379294
   0.04097787 0.02101205 0.01257117 0.02208543 0.0199324  0.02124745
   0.05422943 0.02287661 0.03123808 0.03639582 0.02348528]
  [0.01775791 0.01125783 0.02768005 0.04569191 0.06237247 0.01958838
   0.02067218 0.02782333 0.06739043 0.02434975 0.01873966 0.00987601
   0.04986631 0.04684163 0.024254   0.0200397  0.03458056 0.02164877
   0.02257152 0.02094928 0.03705452 0.02732111 0.04460061 0.03800217
   0.03917715 0.01786998 0.01200611 0.03022649 0.01037748 0.02515079
   0.03023976 0.0223966  0.01926969 0.02881455 0.02354135]
  [0.0221957  0.01125063 0.02556201 0.0456985  0.04863955 0.01592564
   0.01790347 0.02077776 0.06195756 0.01496467 0.03225955 0.01067349
   0.03975893 0.05925581 0.02974375 0.01484673 0.02899775 0.01905675
   0.01602102 0.01657841 0.02287792 0.02433724 0.02902286 0.04402341
   0.02364319 0.04286519 0.01186208 0.02986895 0.01733945 0.03378475
   0.03369806 0.02698487 0.03228527 0.04094689 0.03439218]
  [0.01852532 0.01105384 0.02628067 0.04560156 0.06232229 0.01857477
   0.01926565 0.02713534 0.06592415 0.02249521 0.01999617 0.00986887
   0.05111727 0.04900984 0.02372086 0.01934031 0.0333998  0.02040149
   0.02129637 0.02002193 0.03542398 0.02881057 0.04239221 0.039527
   0.03771079 0.01996372 0.0115078  0.02923474 0.01138785 0.02550565
   0.03320907 0.02277214 0.02147113 0.03118695 0.02454468]]], shape=(1, 5, 35), dtype=float32)
<span class="ansi-green-intense-fg">All tests passed
</span></pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell rendered selected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 150px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Conclusion</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">You've come to the end of the graded portion of the assignment. By now, you've: </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* Create positional encodings to capture sequential relationships in data</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* Calculate scaled dot-product self-attention with word embeddings</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* Implement masked multi-head attention</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">* Build and train a Transformer model</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 150px;"></div><div class="CodeMirror-gutters" style="display: none; height: 165px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Conclusion">Conclusion<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Conclusion"></a></h2>
<p>You've come to the end of the graded portion of the assignment. By now, you've: </p>
<ul>
<li>Create positional encodings to capture sequential relationships in data</li>
<li>Calculate scaled dot-product self-attention with word embeddings</li>
<li>Implement masked multi-head attention</li>
<li>Build and train a Transformer model</li>
</ul>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 198px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">font</span> <span class="cm-attribute">color</span>=<span class="cm-string">'blue'</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">b</span><span class="cm-tag cm-bracket">&gt;</span>What you should remember<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">b</span><span class="cm-tag cm-bracket">&gt;</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">- The combination of self-attention and convolutional network layers allows of parallization of training and *faster training*.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">- Self-attention is calculated using the generated query Q, key K, and value V matrices.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">- Adding positional encoding to word embeddings is an effective way of include sequence information in self-attention calculations. </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">- Multi-head attention can help detect multiple features in your sentence.</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">- Masking stops the model from 'looking ahead' during training, or weighting zeroes too much when processing cropped sentences. </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 198px;"></div><div class="CodeMirror-gutters" style="display: none; height: 213px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><font color="blue">
    <b>What you should remember</b>:

<ul>
<li>The combination of self-attention and convolutional network layers allows of parallization of training and <em>faster training</em>.</li>
<li>Self-attention is calculated using the generated query Q, key K, and value V matrices.</li>
<li>Adding positional encoding to word embeddings is an effective way of include sequence information in self-attention calculations. </li>
<li>Multi-head attention can help detect multiple features in your sentence.</li>
<li>Masking stops the model from 'looking ahead' during training, or weighting zeroes too much when processing cropped sentences. </li>
</ul>
</font></div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit Markup Text here"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 290px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 16.5px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation" style=""><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Now that you have completed the Transformer assignment, make sure you check out the ungraded labs to apply the Transformer model to practical use cases such as Name Entity Recogntion (NER) and Question Answering (QA).<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line">&nbsp;</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-1"># Congratulations on finishing the Deep Learning Specialization!!!!!! </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">This was the last graded assignment of the specialization. It is now time to celebrate all your hard work and dedication! </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">name</span>=<span class="cm-string">'7'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## 7 - References</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">The Transformer algorithm was due to Vaswani et al. (2017). </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable-2">- Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin (2017). </span><span class="cm-link cm-variable-2">[Attention Is All You Need]</span><span class="cm-string cm-url cm-variable-2">(https://arxiv.org/abs/1706.03762)</span><span class="cm-variable-2"> </span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 290px;"></div><div class="CodeMirror-gutters" style="display: none; height: 305px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>Now that you have completed the Transformer assignment, make sure you check out the ungraded labs to apply the Transformer model to practical use cases such as Name Entity Recogntion (NER) and Question Answering (QA).  </p>
<h1 id="Congratulations-on-finishing-the-Deep-Learning-Specialization!!!!!!-">Congratulations on finishing the Deep Learning Specialization!!!!!! <a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#Congratulations-on-finishing-the-Deep-Learning-Specialization!!!!!!-%F0%9F%8E%89"></a></h1>
<p>This was the last graded assignment of the specialization. It is now time to celebrate all your hard work and dedication! </p>
<p><a name="7"></a> </p>
<h2 id="7---References">7 - References<a class="anchor-link" href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#7---References"></a></h2>
<p>The Transformer algorithm was due to Vaswani et al. (2017). </p>
<ul>
<li>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin (2017). <a href="https://arxiv.org/abs/1706.03762" target="_blank">Attention Is All You Need</a> </li>
</ul>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt_container"><div class="prompt input_prompt"><bdi>In</bdi>&nbsp;[&nbsp;]:</div><div class="run_this_cell" title="Run this cell"><i class="fa-step-forward fa"></i></div></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area" aria-label="Edit code here"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" tabindex="-1" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" tabindex="-1" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 7px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre class="CodeMirror-line-like"><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code" role="presentation"><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text=""></span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output"></div><div class="output"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div></div><div class="end_space"></div></div>
        <div id="tooltip" class="ipython_tooltip" style="display:none"><div class="tooltipbuttons"><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="button" class="ui-button"><span class="ui-icon ui-icon-close">Close</span></a><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="button" class="ui-button" id="expanbutton" title="Grow the tooltip vertically (press shift-tab twice)"><span class="ui-icon ui-icon-plus">Expand</span></a><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="button" class="ui-button" title="show the current docstring in pager (press shift-tab 4 times)"><span class="ui-icon ui-icon-arrowstop-l-n">Open in Pager</span></a><a href="https://biwnsxwo.labs.coursera.org/notebooks/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb#" role="button" class="ui-button" title="Tooltip will linger for 10 seconds while you type" style="display: none;"><span class="ui-icon ui-icon-clock">Close</span></a></div><div class="pretooltiparrow"></div><div class="tooltiptext smalltooltip"></div></div>
    </div>
</div>



</div>



<div id="pager" class="ui-resizable">
    <div id="pager-contents">
        <div id="pager-container" class="container"></div>
    </div>
    <div id="pager-button-area"><a role="button" title="Open the pager in an external window" class="ui-button"><span class="ui-icon ui-icon-extlink"></span></a><a role="button" title="Close the pager" class="ui-button"><span class="ui-icon ui-icon-close"></span></a></div>
<div class="ui-resizable-handle ui-resizable-n" style="z-index: 90;"></div></div>






<script type="text/javascript">
    sys_info = {"notebook_version": "6.0.3", "notebook_path": "/opt/conda/lib/python3.7/site-packages/notebook", "commit_source": "", "commit_hash": "", "sys_version": "3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20) \n[GCC 7.3.0]", "sys_executable": "/opt/conda/bin/python", "sys_platform": "linux", "platform": "Linux-5.4.0-1048-aws-x86_64-with-debian-buster-sid", "os_name": "posix", "default_encoding": "UTF-8"};
</script>

<script src="./encoding.js" charset="utf-8"></script>

<script src="./main.min.js" type="text/javascript" charset="utf-8"></script>



<script type="text/javascript">
  function _remove_token_from_url() {
    if (window.location.search.length <= 1) {
      return;
    }
    var search_parameters = window.location.search.slice(1).split('&');
    for (var i = 0; i < search_parameters.length; i++) {
      if (search_parameters[i].split('=')[0] === 'token') {
        // remote token from search parameters
        search_parameters.splice(i, 1);
        var new_search = '';
        if (search_parameters.length) {
          new_search = '?' + search_parameters.join('&');
        }
        var new_url = window.location.origin + 
                      window.location.pathname + 
                      new_search + 
                      window.location.hash;
        window.history.replaceState({}, "", new_url);
        return;
      }
    }
  }
  _remove_token_from_url();
</script>
<script>
        var historyWrapper = function(functionType) {
          var whichFunc = history[functionType];
          return function() {
            var response = whichFunc.apply(this, arguments);
            var eventRes = new Event(functionType);
            eventRes.arguments = arguments;
            window.dispatchEvent(eventRes);
            return response;
          };
        };
        history.pushState = historyWrapper("pushState");
        history.replaceState = historyWrapper("replaceState");
        ["pushState", "replaceState", "popstate","hashchange"].forEach( function(eventType) {
          window.addEventListener(eventType, function() {
            window.parent.postMessage({'innerFrameUrl': window.location.href, 'fromInnerFrame': true}, "https://www.coursera.org");
          });
        });
        </script>
<script>window.parent.postMessage({'innerFrameUrl': window.location.href, 'fromInnerFrame': true}, "https://www.coursera.org");</script>
<script>require(['base/js/namespace'],function(Jupyter){Jupyter._target='_self';});</script>
<style>#ipython_notebook img{display:inline;background:none;width:inherit; padding-left:0;}</style>

<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; min-width: 0px; max-width: none; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: STIXMathJax_Symbols, sans-serif;"></div></div></body></html>